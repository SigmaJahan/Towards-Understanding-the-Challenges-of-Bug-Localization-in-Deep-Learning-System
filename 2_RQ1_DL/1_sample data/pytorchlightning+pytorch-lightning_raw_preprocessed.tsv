id	bug_id	summary	description	report_time	report_timestamp	status	commit	commit_timestamp	files
0	1092	tqdm fails in notebook for versions tqdm&lt; 4.41.0	bug tqdm notebook method version training fails notebook lower version tqdm current requirement enforce reproduce train model tqdm colab notebook expected behavior attributeerror tqdm notebook object attribute reset	2020-03-08 15:46:05	1583682365	resolved fixed	36274bed49cf40c0d9bdabb3058674879badf1e4	1584624198	requirements.txt                                                                    
1	1114	ReduceLROnPlateau scheduler type check	bug incorrect type check scheduler class reducelronplateau pytorch lightning pytorch lightning trainer trainer py line bc01b9a isinstance scheduler optim lr scheduler reducelronplateau believe check isinstance scheduler optim lr scheduler reducelronplateau must look like isinstance scheduler scheduler optim lr scheduler reducelronplateau reproduce steps reproduce behavior create scheduler type optim lr scheduler reducelronplateau configure optimizers method lightningmodule class return optimizer scheduler method place list return optimizer scheduler execute trainer fit module put break point pytorch lightning pytorch lightning trainer trainer py line bc01b9a scheduler reduce plateau make sure condition never true	2020-03-10 22:15:58	1583878558	resolved fixed	384e124490f7a629dc677fc5b658b69afade0a04	1584383710	CHANGELOG.md pytorch_lightning\trainer\trainer.py tests\models\__init__.py tests\models\mixins.py tests\trainer\test_optimizers.py                                                            
2	1116	Wandb logger doesn't upload saved model checkpoint for final epoch	bug training model tpu using wandb logger checkpoint last epoch trained get uploaded wandb reproduce colab notebook	2020-03-11 02:47:18	1583894838	resolved fixed	a707d4bea1a78a98265fd1ea5b7a7a6cadc37fb9	1585608306	CHANGELOG.md pytorch_lightning\loggers\wandb.py tests\loggers\test_wandb.py                                                                
3	1119	Checkpoint fails in single node multi-GPU mode using  DDP	bug checkpoint fails single node multi gpu mode using ddp reproduce python pl example basic example gpu template py distributed backend ddp gpus epoch l home xz anaconda3 envs x lib python3 multiprocessing semaphore tracker py userwarning semaphore tracker appear leaked semaphore clean shutdown len cache traceback recent call last file gpu template py line main hyperparams file gpu template py line main trainer fit model file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer trainer py line fit mp spawn self ddp train nprocs self num gpus args model file home xz anaconda3 envs x lib python3 site package torch multiprocessing spawn py line spawn spawn context join file home xz anaconda3 envs x lib python3 site package torch multiprocessing spawn py line join raise exception msg exception process terminated following error traceback recent call last file home xz anaconda3 envs x lib python3 site package torch multiprocessing spawn py line wrap fn args file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer training loop py line run training epoch self call checkpoint callback file home xz anaconda3 envs x lib python3 site package pytorch lightning trainer training loop py line call checkpoint callback self checkpoint callback validation end self self get model file home xz anaconda3 envs x lib python3 site package pytorch lightning callback model checkpoint py line validation end self check save filepath current epoch file home xz anaconda3 envs x lib python3 site package pytorch lightning callback model checkpoint py line check save self del model delpath file home xz anaconda3 envs x lib python3 site package pytorch lightning callback model checkpoint py line del model o remove filepath filenotfounderror errno file directory home xz pytorch lightning pl example basic example lightning log version checkpoint epoch ckpt	2020-03-11 13:02:06	1583931726	resolved fixed	b4d4e489bf413ebf3288d29c5905d2292ce18d58	1584024600	pytorch_lightning\callbacks\model_checkpoint.py                                                                    
4	1131	Better message when DataLoader is wrong	verge bug improvement bug validation dataloader returning irrelevant staff accidentally length probably edge case combination error getting validation sanity check quite cryptic traceback recent call last file unet waveprop py line trainer fit model file mnt rds home code pytorch lightning pytorch lightning trainer trainer py line fit self run pretrain routine model file mnt rds home code pytorch lightning pytorch lightning trainer trainer py line run pretrain routine false file mnt rds home code pytorch lightning pytorch lightning trainer evaluation loop py line evaluate eval result model validation epoch end output file unet waveprop py line validation epoch end avg loss torch stack x val loss x output mean runtimeerror stack expects non empty tensorlist go code pytorch lightning hour understand happening maybe informative message would make sense one thing would check dataloader size think could take stab pr	2020-03-12 23:01:45	1584054105	resolved fixed	2ccc7456ca421afcdfba0c4482635c99e2593f70	1585608233	CHANGELOG.md pytorch_lightning\trainer\data_loading.py tests\base\__init__.py tests\base\mixins.py tests\trainer\test_dataloaders.py                                                            
5	1139	Can't cast Trainer automatically generated args to their required types	questions help question sure bug put like question problem want add trainer argument custom argumentparser object call add argparse args trainer classmethod method cast trainer argument required type force cast argument like trainer args update accumulate grad batch int trainer args accumulate grad batch train percent check float trainer args train percent check val percent check float trainer args val percent check val check interval int trainer args val check interval track grad norm int trainer args track grad norm max epoch int trainer args max epoch precision int trainer args precision gradient clip val float trainer args gradient clip val pas updated argument trainer trainer pytorch lightning trainer trainer args find central place trainer handle automatically generated argument type tried tried pas argument trainer without handling type instance cast accumulate grad batch integer type exception raised typeerror gradient accumulation support int dict type environment os linux packaging pip version	2020-03-13 12:22:58	1584102178	resolved fixed	ced662fc2790058f5a55ca20244b31003c970ee5	1585076127	CHANGELOG.md pl_examples\full_examples\semantic_segmentation\models\unet\model.py pl_examples\full_examples\semantic_segmentation\models\unet\parts.py pl_examples\full_examples\semantic_segmentation\semseg.py pytorch_lightning\trainer\trainer.py tests\trainer\test_trainer.py tests\trainer\test_trainer_cli.py                                                        
6	1143	`use_amp` is broken in 0.7.0	see use amp deprecated since trainer still accepts argument believe still bug issue hook deal specifically check however trainer set proposed solution use amp passed set precision raise deprecation warning	2020-03-13 17:21:41	1584120101	resolved fixed	4ed3027309fe1882554e9b7ffe33f1aa92c88106	1586175204	CHANGELOG.md pl_examples\basic_examples\gpu_template.py pl_examples\domain_templates\imagenet.py pytorch_lightning\trainer\auto_mix_precision.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py                                                      
7	1155	No validation checks when overfit_pct is set	bug setting overfit pct value exclusive trainer validation check disabled reproduce worked minimal example reproduce bug import pytorch lightning pl import torch class dataset torch utils data dataset def init self input dim output dim super dataset self init self input dim input dim self output dim output dim def getitem self idx x torch rand self input dim torch randint self output dim return x def len self return class model pl lightningmodule def init self input dim output dim super model self init self layer torch nn linear input dim output dim self dataset dataset input dim output dim def forward self x yhat torch softmax self layer x return f nll loss logits def train dataloader self return torch utils data dataloader self dataset batch size def configure optimizers self return torch optim adam self parameter lr def training step self batch batch idx loss self forward batch return loss loss log loss loss def validation step self batch batch idx loss self forward batch return val loss loss log val loss loss name main model model trainer pl trainer overfit pct trainer fit model expected behavior validation check occur normally environment pytorch version debug build cuda used build pytorch os manjaro linux gcc version gcc cmake version could collect python version cuda available cuda runtime version gpu model configuration could collect nvidia driver version could collect cudnn version usr lib libcudnn versions relevant library pip numpy pip pytorch lightning pip torch pip torchvision conda mkl conda pytorch py3 cuda10 cudnn7 pytorch conda pytorch lightning pypi pypi conda torchvision py37 cu101 pytorch	2020-03-15 13:43:17	1584279797	resolved fixed	d735055e6fb6225ad11c566e3711888c0cb4a21e	1585075751	pytorch_lightning\trainer\__init__.py pytorch_lightning\trainer\trainer.py                                                                  
8	1156	ReduceLROnPlateau does not recognise val_loss despite progress_bar dict	bug training model get following message file c users luc miniconda3 envs pytorch lib site package pytorch lightning trainer training loop py line train raise misconfigurationexception pytorch lightning utility debugging misconfigurationexception reducelronplateau conditioned metric val loss available available metric loss ihis similar instance definitely return progress bar dict val loss key see code code sample def training step self batch batch idx z true batch pred self forward z loss val self loss function pred true return loss loss val sqrt def validation step self batch batch idx z true batch lr torch tensor self optim param group lr pred self forward z loss val self loss function pred true return val loss loss val sqrt lr lr def validation epoch end self output val loss mean torch stack x val loss x output mean lr output lr log val loss val loss mean lr lr return val loss val loss mean progress bar log log log expected behavior val loss value picked progress bar environment pytorch version e g os e g linux windows installed pytorch conda pip source pip python version cuda cudnn version gpu model configuration x relevant information	2020-03-15 15:03:34	1584284614	resolved fixed	711892a0a293f7c7f951eba0907e1c0ccd2b37d8	1584624149	docs\source\optimizers.rst pytorch_lightning\core\lightning.py                                                                  
9	1161	multi-gpu ddp calls validation and testing loops too many times	using ddp multiple gpus validation test loop called entire validation dataset gpu expected behavior dataset divided appropriately across gpus using current master cloned mar ubuntu cuda python pytorch venv environment problem appears auto add sampler data loading py create distributedsampler validation test datasets	2020-03-16 18:09:55	1584382195	resolved fixed	6dfe9951e132bdc9896926557138e7a21d4cd000	1585584814	pytorch_lightning\trainer\data_loading.py                                                                    
10	1181	Additional dataloader created and discarded when training with reload_dataloaders_every_epoch	bug training reload dataloaders every epoch noticed instantiates extra dataloader training nothing run issue training chunk get loaded every epoch messing order load especially reload checkpoint would issue people generate new dataset every epoch waste computation tqdm bar also keep information first discarded dataloader screenshot number iteration whereas different size reproduce run code sample run one epoch display message every time dataloader created dataloader get instantiated first time line training loop py outside epoch loop usual time get instantiated reloading every epoch using reload dataloaders every epoch another one created start every epoch line inside loop first epoch extra one code sample import torch import pytorch lightning pl torch utils data import dataloader dataset time import sleep class minimaldataset dataset def init self index self data torch tensor index def getitem self item return self data item def len self return len self data class minimalmodule pl lightningmodule def init self super minimalmodule self init self nn torch nn linear self current index def forward self batch return self nn batch def training step self batch batch idx sleep loss self nn batch return loss loss def validation step self batch batch idx loss self nn batch return val loss loss def configure optimizers self return torch optim adam self parameter lr def train dataloader self required self current index print f initializing dataloader n self current index data loader dataloader minimaldataset self current index return data loader model minimalmodule trainer pl trainer reload dataloaders every epoch true num sanity val step val check interval max epoch trainer fit model expected behavior one dataloader created two tqdm bar show iteration dataset size second time show instead added sleep leave time observe environment pytorch version debug build cuda used build pytorch os ubuntu lts gcc version ubuntu cmake version could collect python version cuda available yes cuda runtime version could collectepoch end gpu model configuration gpu geforce rtx max q design nvidia driver version cudnn version could collect versions relevant library pip3 numpy pip3 pytorch lightning pip3 torch pip3 torchvision conda could collect additional context	2020-03-18 15:42:43	1584546163	resolved fixed	04935ea7184a50d535af96dd85a58fdc43a659b8	1585820516	CHANGELOG.md pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py                                                              
11	1201	Early stopping not working on 0.7.1	bug early stopping work anymore downgrade current dev version early stopping work code code sample def main hparams hparams early stopping yes early stopping earlystopping monitor batch mean absolute loss min delta hparams min delta patience hparams patience mode min else early stopping false model memorytest hparams trainer pl trainer val percent check early stop callback early stopping default save path src setting log dir max epoch hparams epoch trainer fit model class memorytest pl lightningmodule main testing unit experiments recurrent cells def init self hp super memorytest self init self predict col hp predict col self n datasamples hp n datasamples self dataset hp dataset self dataset rand self seq len none else self seq len hp seq len self hparams hp self learning rate hp learning rate self training loss self final loss none self model recurrentmodel hp n cell hp n layer celltype hp celltype def forward self input input len return self model input input len def training step self batch batch idx x input len batch feature self forward x input len loss f mse loss feature mean absolute loss f l1 loss feature self training loss append mean absolute loss item neptune log batch train loss loss batch mean absolute loss mean absolute loss return loss loss batch mean absolute loss mean absolute loss log neptune log def epoch end self train loss mean np mean self training loss self final loss train loss mean self training loss reset next epoch def configure optimizers self return torch optim sgd self parameter lr self learning rate pl data loader def train dataloader self train dataset dg randomdataset self predict col self n datasamples self dataset rand fix train dataset dg randomdatasetfix self predict col self n datasamples self seq len self dataset correlated train dataset dg correlateddataset self predict col self n datasamples train loader dataloader dataset train dataset batch size return train loader staticmethod def add model specific args parent parser model specific model parser argumentparser parent parent parser model parser add argument learning rate default type float model parser add argument n layer default type int model parser add argument n cell default type int model parser add argument celltype default lstm type str training specific model model parser add argument epoch default type int model parser add argument patience default type int model parser add argument min delta default type float model parser add argument early stopping default yes type str data specific model parser add argument n datasamples default type int model parser add argument seq len default type int model parser add argument dataset default rand type str model parser add argument predict col default type int return model parser expected behavior early stopping take effect	2020-03-20 22:35:06	1584743706	resolved fixed	1aba411da96ed95419d13ec1f86a0d38a232f73e	1585635866	CHANGELOG.md docs\source\early_stopping.rst pytorch_lightning\trainer\training_loop.py tests\trainer\test_callbacks.py                                                              
12	1213	Testing in dp mode uses only one of the GPUs	bug reproduce steps reproduce behavior run test without training code sample modified conference seed repo trainer trainer gpus distributed backend dp trainer test model expected behavior environment pl version pytorch version e g os e g linux ubuntu installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration relevant information additional context	2020-03-23 11:26:40	1584962800	resolved fixed	c869dd8b8f6301f3726df84535a3da4e9acf04ec	1585584867	CHANGELOG.md pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py tests\test_deprecated.py                                                              
13	122	Fix appveyor build	window support priority badge fixed today keep appveyor otherwise drop project borda	2019-08-15 14:03:39	1565877819	resolved fixed	6f1d2c45fe72d7a8a637290c2e78973deb1637e0	1565883903	appveyor.yml                                                                    
14	1223	gan.py multi-gpu running problems	running gan py example trainer ngpus cause two type error trainer ngpus distributed backend dp exception occurred attributeerror nonetype object attribute detach file home user gan py line training step self discriminator self generated imgs detach fake trainer ngpus distributed backend ddp lightling log one run creates two folder version version exception caused file opt miniconda3 envs ctln gan lib python3 site package pytorch lightning callback model checkpoint py line del model o remove filepath filenotfounderror errno file directory home user pyproj dcgan lightning log version checkpoint epoch ckpt seems subprocess try create checkpoint delete ctrated one environment version python pytorch pytorch lightning	2020-03-24 14:24:01	1585059841	resolved fixed	55fdfe384537e4d43e7397306ba001ffc3474322	1590928281	pl_examples\domain_templates\generative_adversarial_net.py                                                                    
15	1236	AdvancedProfiler error	hi others pointed profiler seem work print nothing trying advancedprofiler like pytorch lightning profiler import advancedprofiler profiler advancedprofiler output filename prof txt trainer trainer profiler profiler params give following error validation sanity check traceback recent call last file users sdumitre work style training py line main hparams file users sdumitre work style training py line main trainer fit model file users sdumitre virtual p3 lib python3 site package pytorch lightning trainer trainer py line fit self run pretrain routine model file users sdumitre virtual p3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine callback metric self process output eval result file users sdumitre virtual p3 lib python3 site package pytorch lightning trainer logging py line process output callback metric k v item valueerror one element tensor converted python scalar process finished exit code pointer env torch installed pip python gpu macos thanks great lib developing	2020-03-25 19:02:05	1585162925	resolved fixed	54507f417eaf3317a798b3303c398152a4e35a18	1585508196	pytorch_lightning\__init__.py tests\test_profiler.py                                                                  
16	1262	incorrect run on the test set with overwritten validation_end and test_epoch_end	bug override validation end test epoch end trainerevaluationloopmixin evaluate work incorrectly test set suppose override actually since newbie yet figured everything work also seems seems suppose run consider line evaluation loop py first block executed look second hence second also executed validation result recorder test result mistake problem present commit inverse problem happens override present	2020-03-27 12:38:00	1585312680	resolved fixed	ebd9fc9530242e1c9b5f3093dc62ceb4185735b0	1585920332	CHANGELOG.md pytorch_lightning\trainer\evaluation_loop.py tests\trainer\test_trainer.py                                                                
17	1264	Multiple undesired checkpoints created during single epoch	bug thanks great project sent custom modelcheckpoint trainer hoping get one checkpoint epoch trainer eventually produced lot versioned checkpoint within single epoch wasting lot disk space causing confusion example shown checkpoint gan ckpt epoch ckpt ckpt epoch v0 ckpt ckpt epoch v10 ckpt ckpt epoch v11 ckpt ckpt epoch v12 ckpt ckpt epoch v13 ckpt ckpt epoch v14 ckpt ckpt epoch v15 ckpt ckpt epoch v16 ckpt ckpt epoch v17 ckpt ckpt epoch v18 ckpt ckpt epoch v19 ckpt ckpt epoch v1 ckpt ckpt epoch v20 ckpt ckpt epoch v21 ckpt minimal code used training showed reproduce exactly checkpoint callback modelcheckpoint filepath o path join gan experiment name save top k period trainer trainer checkpoint callback checkpoint callback reproduce steps reproduce behavior clone repo git clone git checkout run script train gan mnist cd learnable ai python application image generation train gan py dataset mnist latent dim dim channel batch size max epoch see generated check point checkpoint tree checkpoint multiple checkpoint within single epoch checkpoint gan ckpt epoch ckpt ckpt epoch v0 ckpt ckpt epoch v10 ckpt ckpt epoch v11 ckpt ckpt epoch v12 ckpt ckpt epoch v13 ckpt ckpt epoch v14 ckpt ckpt epoch v15 ckpt ckpt epoch v16 ckpt ckpt epoch v17 ckpt ckpt epoch v18 ckpt ckpt epoch v19 ckpt ckpt epoch v1 ckpt ckpt epoch v20 ckpt ckpt epoch v21 ckpt expected behavior one checkpoint epoch using custom modelcheckpoint pl lightningmodule simply use val loss evaulation metric thus default checkpoint functionality trainer work environment cuda gpu tesla v100 sxm2 available true version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor x86 python version smp tue dec utc additional context related slack discussion	2020-03-27 14:14:42	1585318482	resolved fixed	09167efdb59e1be8ffe9ff7010393bff084390be	1585607822	pl_examples\multi_node_examples\multi_node_ddp_demo.py pytorch_lightning\callbacks\base.py pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\profiler\profiler.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\trainer\training_loop.py tests\base\__init__.py tests\base\mixins.py tests\base\models.py tests\test_profiler.py tests\trainer\test_trainer.py                                        
18	1290	bug(logger): wandb fails on sweep	bug using wandb sweep hyperparameters search get error wandb error attempted change value key dropout std reason ran wandb logger log hyperparams params guess problem floating point number high accuracy	2020-03-30 11:08:50	1585566530	resolved fixed	f3d139e90f9212813c4f5e6de777bdef9dfe7635	1587738564	CHANGELOG.md pytorch_lightning\loggers\wandb.py tests\loggers\test_wandb.py                                                                
19	1306	RuntimeError: Unimplemented backend XLA on TPU	bug raised line file running mnist tpu think introduced reproduce steps reproduce behavior go mnist tpus run scroll trainer see error traceback recent call last file usr local lib python3 dist package torch xla distributed xla multiprocessing py line start fn fn gindex args file usr local lib python3 dist package torch xla distributed xla multiprocessing py line start fn fn gindex args file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package torch xla distributed xla multiprocessing py line start fn fn gindex args file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss exception device tpu unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx runtimeerror unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type runtimeerror unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type runtimeerror unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss runtimeerror unimplemented backend xla traceback recent call last runtimeerror unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type runtimeerror unimplemented backend xla file usr local lib python3 dist package torch xla distributed xla multiprocessing py line start fn fn gindex args runtimeerror unimplemented backend xla file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train self run pretrain routine model file usr local lib python3 dist package pytorch lightning trainer trainer py line run pretrain routine self train file usr local lib python3 dist package pytorch lightning trainer training loop py line train self run training epoch file usr local lib python3 dist package pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file usr local lib python3 dist package pytorch lightning trainer training loop py line run training batch self batch loss value append loss file usr local lib python3 dist package pytorch lightning trainer supporting class py line append self memory type x type runtimeerror unimplemented backend xla exception traceback recent call last basic trainer us good default trainer trainer num tpu core trainer fit model frame usr local lib python3 dist package torch multiprocessing spawn py join self timeout raise exception process terminated exit code error index exitcode exception process terminated exit code environment pytorch version e g os e g linux linux installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration relevant information tpu backend	2020-03-30 17:08:20	1585588100	resolved fixed	b8ff9bc1d242a18f5e7147f34d63f43fcdd0e50a	1586219395	CHANGELOG.md pytorch_lightning\trainer\supporters.py                                                                  
20	1322	Training loop temporarily hangs after every 4 steps	porting code pytorch lightning everything seems work fine however reason every training step see temporary hanging second severely slowing overall training time missing obvious configuration trainer configuration trainer pl trainer gpus num node distributed backend ddp checkpoint callback false max epoch max step none progress bar refresh rate check val every n epoch val check interval gradient clip val log save interval num sanity val step amp level o0	2020-03-31 17:35:57	1585676157	resolved fixed	b18accc64ccd24095c11fdbd64cc924456134592	1586099236	CHANGELOG.md pytorch_lightning\trainer\data_loading.py tests\trainer\test_dataloaders.py                                                                
21	1335	Trainer DDP should invoke load_spawn_weights() only in proc_rank == 0	bug trainer ddp load spawn weight happen proc rank since process node save spawn weight actually save checkpoint reproduce steps reproduce behavior setup two node cluster set slurm nodeid node node node run script python app py node see stdout node traceback recent call last file app py line main pylint disable value parameter file app py line main trainer fit model file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning trainer trainer py line fit self load spawn weight model file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning trainer distrib data parallel py line load spawn weight loaded model original model class load checkpoint path file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning core lightning py line load checkpoint checkpoint torch load checkpoint path map location lambda storage loc storage file home ubuntu anaconda3 envs nightly pt lib python3 site package torch serialization py line load open file like f rb opened file file home ubuntu anaconda3 envs nightly pt lib python3 site package torch serialization py line open file like return open file name buffer mode file home ubuntu anaconda3 envs nightly pt lib python3 site package torch serialization py line init super open file self init open name mode filenotfounderror errno file directory home ubuntu pytorch lightning intro guide temp weight ddp end ckpt code sample app py import pathlib import pytorch lightning pl import torch torch nn import functional f torch optim import adam torch utils data import dataloader random split torchvision import datasets transforms class litmnist pl lightningmodule def init self super init self layer torch nn linear self layer torch nn linear self layer torch nn linear self train dataset none self val dataset none self test dataset none def forward self x batch size channel width height x size x x view batch size x self layer x x f relu x x self layer x x f relu x x self layer x x f log softmax x dim return x def prepare data self transform transform transforms compose transforms totensor transforms normalize download data dir pathlib path home data mnist train datasets mnist data dir train true download true transform transform mnist test datasets mnist data dir train false download true transform transform train val split mnist train mnist val random split mnist train assign use dataloaders self train dataset mnist train self val dataset mnist val self test dataset mnist test def train dataloader self return dataloader self train dataset batch size def val dataloader self return dataloader self val dataset batch size def test dataloader self return dataloader self test dataset batch size def configure optimizers self return adam self parameter lr def training step self batch batch idx x batch logits self x loss f nll loss logits add logging log loss loss return loss loss log log def validation step self batch batch idx x batch logits self x loss f nll loss logits return val loss loss def test step self batch batch idx x batch logits self x loss f nll loss logits return val loss loss def test epoch end self output avg loss torch stack pylint disable member x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def init ddp connection self proc rank int world size int none torch distributed init process group nccl rank proc rank world size world size def main model litmnist gpus num node trainer pl trainer gpus gpus num node num node distributed backend ddp max epoch trainer fit model name main main expected behavior worker node finish without error environment node cuda gpu tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 available true version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp wed jan utc additional context	2020-04-01 23:31:03	1585783863	resolved fixed	9754c5da55059dd89cf0a4fd582fe5df9449bbe5	1586182636	pytorch_lightning\trainer\distrib_data_parallel.py                                                                    
22	1366	ModelCheckpoint tries to remove already removed checkpoint in DDP mode	bug training ddp mode modelcheckpoint callback train process fails modelcheckpoint callback try remove previous checkpoint assume already deleted another process reproduce steps reproduce behavior run training ddp backend modelcheckpoint callback save top k number file home myuser miniconda3 lib python3 site package torch multiprocessing spawn py line wrap fn args file home myuser miniconda3 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file home myuser miniconda3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file home myuser miniconda3 lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file home myuser miniconda3 lib python3 site package pytorch lightning trainer training loop py line run training epoch self call checkpoint callback file home myuser miniconda3 lib python3 site package pytorch lightning trainer training loop py line call checkpoint callback self checkpoint callback validation end self self get model file home myuser miniconda3 lib python3 site package pytorch lightning callback model checkpoint py line validation end self check save filepath current epoch file home myuser miniconda3 lib python3 site package pytorch lightning callback model checkpoint py line check save self del model delpath file home myuser miniconda3 lib python3 site package pytorch lightning callback model checkpoint py line del model o remove filepath filenotfounderror errno file directory previous checkpoint name expected behavior expect modelcheckpoint callback different ddp process concurrent saving deleteng file fixed rewriting del model method modelcheckpoint callback class ddpmodelcheckpoint modelcheckpoint def del model self filepath try o remove filepath except exception pas environment pytorch version os ubuntu installed pytorch conda python version cuda cudnn version gpu model configuration pytorch lightning version	2020-04-03 16:01:47	1585929707	resolved fixed	58a467dd68b157fdba8824a437dbaf698ad88569	1587763260	CHANGELOG.md pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\loggers\__init__.py pytorch_lightning\loggers\base.py pytorch_lightning\loggers\comet.py pytorch_lightning\loggers\mlflow.py pytorch_lightning\loggers\neptune.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\loggers\test_tube.py pytorch_lightning\loggers\trains.py pytorch_lightning\loggers\wandb.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\logging.py pytorch_lightning\utilities\__init__.py pytorch_lightning\utilities\distributed.py   tests\loggers\test_base.py                                  
23	1375	Tensorboard logger error: lightning_logs directory not exists in multi-node DDP on nodes with rank != 0	bug multi node ddp train mode node except rank error appears start training caused accessing lightning log directory tensorboard logger exist moment reproduce steps reproduce behavior setup multi node cluster without slurm set environment variable node export master addr export master port export rank export slurm nodeid export world size install dependency pip install torch torchvision hydra core pytorch lightning copy app conf yaml node run script node python app py see error exception process terminated following error traceback recent call last file home ubuntu anaconda3 envs nightly pt lib python3 site package torch multiprocessing spawn py line wrap fn args file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self configure checkpoint callback file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning trainer callback config py line configure checkpoint callback f version self logger version file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning logger tensorboard py line version self version self get next version file home ubuntu anaconda3 envs nightly pt lib python3 site package pytorch lightning logger tensorboard py line get next version o listdir root dir filenotfounderror errno file directory home ubuntu pytorch lightning intro guide output lightning log code sample app py import pathlib import hydra import pytorch lightning pl import torch omegaconf import omegaconf torch nn import functional f torch optim import adam torch utils data import dataloader random split torchvision import datasets transforms class litmnist pl lightningmodule def init self super init self layer torch nn linear self layer torch nn linear self layer torch nn linear self train dataset none self val dataset none self test dataset none def forward self x batch size channel width height x size x x view batch size x self layer x x f relu x x self layer x x f relu x x self layer x x f log softmax x dim return x def prepare data self transform transform transforms compose transforms totensor transforms normalize download data dir pathlib path home data mnist train datasets mnist data dir train true download true transform transform mnist test datasets mnist data dir train false download true transform transform train val split mnist train mnist val random split mnist train assign use dataloaders self train dataset mnist train self val dataset mnist val self test dataset mnist test def train dataloader self return dataloader self train dataset batch size def val dataloader self return dataloader self val dataset batch size def test dataloader self return dataloader self test dataset batch size def configure optimizers self return adam self parameter lr def training step self batch batch idx x batch logits self x loss f nll loss logits add logging log loss loss return loss loss log log def validation step self batch batch idx x batch logits self x loss f nll loss logits return val loss loss def validation epoch end self output avg loss torch stack pylint disable member x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def test step self batch batch idx x batch logits self x loss f nll loss logits return val loss loss def test epoch end self output avg loss torch stack pylint disable member x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def init ddp connection self proc rank int world size int none torch distributed init process group nccl rank proc rank world size world size hydra main config path conf yaml def main conf omegaconf model litmnist trainer pl trainer gpus conf gpus num node conf num node distributed backend conf distributed backend max epoch trainer fit model name main main pylint disable value parameter conf yaml gpus num node distributed backend ddp expected behavior train go without error environment cuda gpu tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 tesla k80 available true version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp wed jan utc additional context	2020-04-04 16:20:54	1586017254	resolved fixed	495ffbd028ae860528c719544cf0409b41d5ef5a	1586255994	CHANGELOG.md pytorch_lightning\loggers\tensorboard.py                                                                  
24	138	val_dataloader is not optional in distributed_backend='ddp'	describe bug val dataloader function kept optional line code check self val dataloader none lead following error file misc vlgscratch4 fergusgroup ananya pyenv py3 lib python3 site package pytorch lightning model trainer py line get dataloaders dataloader self val dataloader typeerror nonetype object iterable file model trainer py line reproduce steps reproduce behavior write optional function val dataloader use following trainer configuration trainer trainer experiment exp checkpoint callback checkpoint callback distributed backend ddp gpus args gpu id amp level o2 use amp true max nb epoch args epoch progress bar true expected behavior code ignore isinstance dataloader distributedsampler dataloader self val dataloader check self val dataloader none environment pytorch cuda test tube pytorch lightning	2019-08-18 19:51:39	1566157899	resolved fixed	5b694c7e0ec5f83bf4ec93860d91a48757351265	1566241384	pytorch_lightning\models\trainer.py                                                                    
25	1388	Use isinstance() instead of type() in trainer.distrib_parts.check_gpus_data_type	bug instantiating trainer object make sense able pas subclass list ideally would something even general like collection abc sequence familiar lightning codebase change would greater likelihood breaking thing reproduce instantiate trainer gpus parameter subclass list code sample pytorch lightning import trainer class mylist list pas gpus mylist trainer gpus gpus produce traceback recent call last file line file opt anaconda miniconda3 envs ai lib python3 site package pytorch lightning trainer trainer py line init self data parallel device id parse gpu id self gpus file opt anaconda miniconda3 envs ai lib python3 site package pytorch lightning trainer distrib part py line parse gpu id check gpus data type gpus file opt anaconda miniconda3 envs ai lib python3 site package pytorch lightning trainer distrib part py line check gpus data type raise misconfigurationexception gpus must int string list ints none pytorch lightning utility debugging misconfigurationexception gpus must int string list ints none expected behavior trainer instantiated normally would list passed environment pytorch version pytorch lightning version os ubuntu installed pytorch pip python version potential fix pytorch lightning trainer distrib part py check type using isinstance instead type def check gpus data type gpus gpus none type gpus int str list gpus none isinstance gpus int str list raise misconfigurationexception gpus must int string list ints none put pr change sound good	2020-04-06 04:36:54	1586147814	resolved fixed	a22a8142ac65668781a6e6f76d3c4e55ea7c249a	1587161909	pytorch_lightning\trainer\distrib_parts.py                                                                    
26	142	AttributeError: 'xxx' object has no attribute 'tng_dataloader' continued...	issue mentioned describe bug whenever property raise attributeerror looked getattr defined original error message lost lightingmodule inherits getattr torch nn module make debugging difficult lose line number get error message misleading attribute exists look minimal example next section see mean reproduce import torch class foo torch nn module property def bar self return torch exist raises attributeerror foo bar output produced traceback recent call last file c minimal py line foo bar file c program files python37 lib site package torch nn module module py line getattr type self name name attributeerror foo object attribute bar trace say attribute exist attribute nonexistent look stack trace even worse expected behavior one would expect stack trace traceback recent call last file c minimal py line bar return torch exist raises attributeerror attributeerror module torch attribute exist think could useful add try catch pl data loader one could also make pl attribute decorator user pl data loader use document use case doc simply extend usual attribute try catch example desirable stack trace traceback recent call last file c minimal py line bar return torch exist raises attributeerror attributeerror module torch attribute exist exception direct cause following exception traceback recent call last file c minimal py line foo bar file c minimal py line bar raise runtimeerror attributeerror encountered foo bar e runtimeerror attributeerror encountered foo bar case error correctly shown line stack trace achieved replacing line try return torch exist raises attributeerror except attributeerror e raise runtimeerror attributeerror encountered foo bar e see also discussion pytorch pytorch problem seems troublesome design decision language hard get around think pl attribute good idea seem way around issue must use nn module attribute	2019-08-18 23:07:54	1566169674	resolved fixed	b31539f62e60e1ad370214e05003c214298d2431	1566562899	pytorch_lightning\root_module\decorators.py                                                                    
27	1421	run_training_batch breaks on None batch or -1 response from on_batch_start (in new 0.7.2 release)	bug run training batch supposed return tuple however two place still return tuple cause program crash saying valueerror enough value unpack expected got training loop py batch none return grad norm dic training loop py response return grad norm dic v standard return return grad norm dic log metric batch output reproduce return batch start	2020-04-09 03:35:45	1586403345	resolved fixed	b2707c9b2ebeac03f19a3939df9432ac8859d894	1586458868	CHANGELOG.md pytorch_lightning\trainer\training_io.py pytorch_lightning\trainer\training_loop.py                                                                
28	1422	Not auto add DistributedSampler for DDP training	bug even set sampler pytorch lightning add distributedsampler u reproduce reason pytorch set sampler pytorch add sampler u pytorch dataloader py sampler none give default sampler self dataset kind datasetkind iterable see note custom samplers iterabledataset sampler infiniteconstantsampler else map style shuffle sampler randomsampler dataset else sampler sequentialsampler dataset pytorch lightning check whether sampler none decide add sampler data loading py funciton auto add sampler sampler added dataloader sampler none pytorch default sampler u none pytorch lighting automatically add sampler	2020-04-09 09:22:50	1586424170	resolved fixed	21a1972921809ea04ab1e4c657e326dfecd5e352	1586436735	pytorch_lightning\trainer\data_loading.py                                                                    
29	1435	Test metrics is not being reported to TensorBoard since 0.7.2	bug reproduce steps reproduce behavior code sample please see colab expected behavior test metric reported environment colab environment cuda gpu available false version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp wed feb pst additional context regression	2020-04-09 20:06:11	1586462771	resolved fixed	1f685c2882d2bb0755a7ab0ed6819b008780948e	1586522602	CHANGELOG.md pytorch_lightning\__init__.py pytorch_lightning\trainer\evaluation_loop.py                                                                
30	1442	Failed to configure_optimizers from dictionary without lr_scheduler field presented	bug optimizer failed configured dictionary without lr sheduler field consider example module configure optimizers method def configure optimizers self config optimizer torch optim sgd params self parameter lr return config run simple trainer trainer option dict default save path tmpdir max epoch trainer trainer trainer option trainer fit model fail error unboundlocalerror local variable lr scheduler referenced assignment believe reason lr scheduler local variable determined pytorch lightning pytorch lightning trainer optimizers py lines single dictionary elif isinstance optim conf dict optimizer optim conf optimizer lr scheduler optim conf get lr scheduler lr scheduler lr scheduler self configure scheduler lr scheduler return optimizer lr scheduler think could fixed like single dictionary elif isinstance optim conf dict optimizer optim conf optimizer lr scheduler optim conf get lr scheduler lr scheduler lr scheduler self configure scheduler lr scheduler else lr scheduler return optimizer lr scheduler reproduce steps reproduce behavior create simple module configure optimizers look like run fit trainer method model see error code sample expected behavior suppose configuration optimizer without lr scheduler must valid one error must occurred environment os linux architecture processor x86 python version ubuntu smp wed apr utc pytorch lightning	2020-04-10 12:52:39	1586523159	resolved fixed	4c34d16a349bc96a717be5674606c2577fab8946	1586533386	CHANGELOG.md pytorch_lightning\trainer\optimizers.py pytorch_lightning\trainer\supporters.py pytorch_lightning\trainer\trainer.py tests\trainer\test_optimizers.py                                                            
31	1447	Test results not logged to tensorboard, since 0.7.3, this worked in 0.7.1	bug test result logged tensorboard exact code version logged flawlessly also exact code validation train result logged assumed issue test reproduce run test step model tensorboard logging logger tensorboardlogger log dir name name code sample def validation step self val batch batch idx return val loss loss def validation epoch end self output avg loss torch stack x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log work def test step self test batch batch idx return test loss loss def test epoch end self output avg loss torch stack x test loss x output mean tensorboard log mse avg loss print f test mean squared error mse avg loss work return avg test loss avg loss log tensorboard log issue might expected behavior expected behavior tensorboard log contain mse open tensorboard contain mse val loss train loss exact code used work believe change produced bug print work correct value printed assume issue return log tensorboard log environment pytorch version e g os e g linux windows x64 installed pytorch pip build command used compiling source n python version relevant information full code found	2020-04-10 16:16:14	1586535374	resolved fixed	b3fe17ddeb00fb66db08e5fc7414591662ebd440	1586910753	.github\workflows\ci-testing.yml CHANGELOG.md pytorch_lightning\loggers\base.py pytorch_lightning\loggers\comet.py pytorch_lightning\loggers\mlflow.py pytorch_lightning\loggers\neptune.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\loggers\test_tube.py pytorch_lightning\loggers\trains.py pytorch_lightning\loggers\wandb.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py tests\base\mixins.py tests\loggers\test_all.py tests\loggers\test_base.py tests\loggers\test_comet.py tests\loggers\test_mlflow.py tests\loggers\test_neptune.py tests\loggers\test_tensorboard.py   tests\loggers\test_wandb.py                            
32	1468	Mixing hparams and arguments in LightningModule.__init__() crashes load_from_checkpoint()	bug right initialize lightning module mixture namespace hparams well additional argument say dataset load checkpoint recover reproduce create lightningmodule follows class model pl lightningmodule def init self hparams train dataset val dataset self hparams hparams self train dset self val dset train dataset val dataset run training try restore checkpoint via nn model restore checkpoint train dataset none val dataset none expected behavior ideally able pas additional argument everything would work	2020-04-12 22:32:36	1586730756	resolved fixed	3c6f856f232ccd124ca90621cdda8094bae6e332	1587294220	CHANGELOG.md pytorch_lightning\core\lightning.py                                                                  
33	1476	Learning rate scheduler should step after each optimizer step	bug sure bug deliberate design decision right learning rate schedule get updated every step actually corresponds every forward pas think standard implementation would learning rate scheduler step interval correspond updated every backwards pas caused lot problem instability realize using standard learning rate warmups say step would actually warm step set accumulate grad batch	2020-04-13 17:57:32	1586800652	resolved fixed	0203938af8f69a19b7e0264f18e03d543d86e0e9	1587384232	CHANGELOG.md pytorch_lightning\trainer\training_loop.py                                                                  
34	1485	wandb logger 'global_step' affects other logger	bug wandb logger add global step metric dict appears logger e g tensorboard wandb logger adding global step metric think necessary another side effect global step also added empty dicts logged resulting strange graph like also wrote simple logger class print metric got output step global step step global step step global step step global step step val mse train mse global step step global step step global step step global step step global step step val mse train mse global step step global step step global step step global step step global step step val mse train mse global step step val mse train mse global step step global step step global step step global step step global step step val mse train mse global step step global step step global step step global step step global step step val mse train mse global step step global step step global step step global step step global step step val mse train mse global step step global step step step global step step global step also notice set max epoch expected measurement last one missing could handled issue reproduce steps reproduce behavior use training epoch end validation epoch end log metric like log loss loss see code bellow run training wandb logger one logger choice see global step graph code sample important lightningmodule methods def training step self batch batch idx calculate actual model prediction given batch calculate loss x batch hat self x print current loss training every n th iteration loss f mse loss hat return loss loss def training epoch end self output loss mean torch stack x loss x output mean item return log train mse loss mean step self current epoch def validation step self batch batch idx x batch hat self x return val loss f mse loss hat def validation epoch end self output val loss mean torch stack x val loss x output mean item return val loss val loss mean log val mse val loss mean step self current epoch training clbk terminal terminalcallback checkpoint modelcheckpoint filepath ckpts name val loss epoch prefix basicnn monitor val loss verbose false save top k save weight true earlystopping earlystopping monitor val loss patience verbose true logger wandblogger project nwp energy load name name log model true tensorboardlogger save dir tb log name name version mylogger print metric also ignored trainer trainer gpus max epoch progress bar refresh rate logger logger log save interval row log interval callback early stop callback earlystopping checkpoint callback checkpoint expected behavior global step needed wandb logger affect logger also nothing log e g training step logger log nothing environment linux arch python pytorch pytorch lightning	2020-04-14 09:02:22	1586854942	resolved fixed	152a2eb30ce82deefdb738b81fda66a9c218ed76	1588423847	CHANGELOG.md pytorch_lightning\loggers\base.py pytorch_lightning\loggers\wandb.py tests\loggers\test_wandb.py                                                              
35	1503	Do not configure python logging	bug pytorch lightning right configures python logging module generally recommended writing library make difficult user modify logging format see python doc stack overflow post would suggest deleting configuration line	2020-04-15 17:12:50	1586970770	resolved fixed	1df0d2dc97e20b9646cbe0f42060a57f99f397fc	1589256875	pytorch_lightning\__init__.py pytorch_lightning\trainer\trainer.py                                                                  
36	1506	0.7.3 breaks reusable dataloaders in DDP	bug break reusable dataloaders ddp traceback recent call last file opt conda lib python3 site package torch multiprocessing spawn py line wrap fn args file opt conda lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file opt conda lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file opt conda lib python3 site package pytorch lightning trainer training loop py line train self reset train dataloader model file opt conda lib python3 site package pytorch lightning trainer data loading py line reset train dataloader self train dataloader self auto add sampler self train dataloader train true file opt conda lib python3 site package pytorch lightning trainer data loading py line auto add sampler dataloader type dataloader dl args file main dataset py line init super init args kwargs typeerror init got unexpected keyword argument iterator code sample class repeatsampler object def init self sampler self sampler sampler def iter self true yield iter self sampler class fastdataloader torch utils data dataloader dataloader def init self args kwargs super init args kwargs object setattr self batch sampler repeatsampler self batch sampler self iterator super iter def len self return len self batch sampler sampler def iter self range len self yield next self iterator replace dataloader fastdataloader lightning snippet pytorch pytorch expected behavior dataloaders initialize correctly reused train val epoch work expected probable cause	2020-04-16 05:13:36	1587014016	resolved fixed	c71bd73acb5a89bb2a8ff44beab37fd2ceba352b	1587329937	CHANGELOG.md pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\trainer.py                                                                
37	1507	After update from 0.5.x to 0.7.3 merge_dicts #1278 sometimes breaks training	bug updated quite old lightning version newest one sometimes get typeerror merge dicts guess related mr type error deterministic meaning always occurs global step training somehow seems related val check interval well data changing value lead error datasets work also happens training step suspect training step validating reproduce steps reproduce behavior idea file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning trainer training loop py line run training epoch self log metric batch step metric grad norm dic file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning trainer logging py line log metric self logger agg log metric scalar metric step step file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning logger base py line agg log metric agg step metric log self aggregate metric metric metric step step file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning logger base py line aggregate metric agg step agg mets self finalize agg metric file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning logger base py line finalize agg metric agg mets merge dicts self metric agg self agg key funcs self agg default func file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package pytorch lightning logger base py line merge dicts agg val fn v v get k dicts v none file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package numpy core fromnumeric py line mean kwargs file home sebastian cache pypoetry virtualenvs forgerydetection ic5ox0x1 py3 lib python3 site package numpy core method py line mean ret umr sum arr axis dtype keepdims typeerror unsupported operand type dict dict sometimes also dict int expected behavior least break training maybe verbose message wrong quite hard debug structure log returning lightning change environment cuda gpu geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti available true version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor x86 python version ubuntu smp wed apr utc additional context also reason run issue multiprocessing break training traceback recent call last file home sebastian pyenv version lib python3 multiprocessing util py line run finalizers finalizer file home sebastian pyenv version lib python3 multiprocessing util py line call re self callback self args self kwargs file home sebastian pyenv version lib python3 multiprocessing util py line remove temp dir rmtree tempdir file home sebastian pyenv version lib python3 shutil py line rmtree onerror o rmdir path sys exc info file home sebastian pyenv version lib python3 shutil py line rmtree o rmdir path oserror errno directory empty tmp pymp jcqai2xr	2020-04-16 08:01:01	1587024061	resolved fixed	edb8d7a23cac91d607ab97c0adcbb815780936ac	1587677556	CHANGELOG.md pytorch_lightning\loggers\base.py                                                                  
38	1510	Memory (CPU and GPU) leaks during the 1st epoch	bug hello memory leak occurs first epoch one large epoch time day oom error come interesting precision mode leak gpu cpu switch amp optimization precision leak go cpu also checked number tensor tracked garbage collector appeared linearly increasing first epoch epoch start fall initial value begin increasing let provide plot experiment amp level o2 precision experiment amp level none precision none see case cpu leak amp case also gpu leak also clear leaky behavior stop epoch start plot epoch start saw claw num tensor plot also another observation speed tensor number increasing forward pas method def training step self batch batch idx loss self forward batch num tensor get num tensor log num tensor num tensor cpu mem usg get cpu mem loss enumerate loss log f loss loss print num tensor return loss loss log log return exactly tensor one loss log real experiment tensor took day get oom current example see reproduce crash much faster reproduce steps reproduce behavior execute code sample script argument change needed value manually script go tensorboard check plot code sample expected behavior number tensor gpu cpu memory increase training environment pytorch version os ubuntu lts python version versions relevant library pip numpy pip pytorch lightning pip torch pip torchvision additional context sorry messy flow information know structure clearly	2020-04-16 16:25:24	1587054324	resolved fixed	ae2e14e3ed45e23dbe2868017b630fa7be9e5604	1587328914	pl_examples\basic_examples\cpu_template.py pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\logging.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py pytorch_lightning\utilities\memory_utils.py tests\base\utils.py                                                    
39	1520	Bug and question about logging -- missing epoch, validation before train?	bug first clear bug trainerloggingmixin log metric epoch added metric variable line never accessed scalar metric second question implemented primitive logger stdout logging get training result first epoch end first epoch validation step consequently get training metric last epoch see code sample output make sense reproduce add following code lightning module run trainer following logger use gpu int torch cuda available print logger printlogger trainer trainer gpus use gpu max epoch logger print logger trainer fit model code sample minimal logging lightningmodule def training epoch end self output avg loss torch stack x loss x output mean avg acc torch stack x acc x output mean log dict train loss avg loss train acc avg acc return dict log log def validation epoch end self output avg loss torch stack x loss x output mean avg acc torch stack x acc x output mean log dict val loss avg loss val acc avg acc return dict log log minimal logger pytorch lightning logger import lightningloggerbase rank zero class printlogger lightningloggerbase def init self super printlogger self init property def name self return test property def experiment self return self name property def version self return rank zero def log hyperparams self params print f hyperparameters n params rank zero def log metric self metric step metric none len metric key print f step metric def save self optional code necessary save logger data go pas rank zero def finalize self status optional code need run training finish go pas expected behavior would expect see training output epoch followed validation output epoch five epoch instead see following four train output five validation one seeing validation first observed behavior val loss val acc train acc train loss val loss val acc train acc train loss val loss val acc train acc train loss val loss val acc train acc train loss val loss val acc expected behavior n number step batch per epoch n train acc train loss n val loss val acc train acc train loss val loss val acc train acc train loss val loss val acc environment cuda gpu available false version package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp tue feb utc additional context	2020-04-17 18:47:13	1587149233	resolved fixed	fe2b6666e0c3a47992860a2200ab40ae1c2ea6c7	1587678761	pytorch_lightning\trainer\logging.py tests\loggers\test_all.py                                                                  
40	1522	Performance drop when activating gradient clipping	hello experienced substantial drop computation time activating gradient clipping passing non zero value keyword argument gradient clip val initializing trainer noticed current implementation clipping gradient method pytorch lightning trainer training trick py redundant computation made first computing norm second squaring result could shortened computing sum square directly save one square root squaring operation per parameter set best jonas environment cuda gpu available false version none package numpy pytorch debug false pytorch version pytorch lightning dev tensorboard tqdm system os darwin architecture processor i386 python version darwin kernel version wed mar pst root xnu release x86 additional context trained relatively small two layered mlp mnist perhaps performance drop become apparent training larger network architecture	2020-04-17 23:15:19	1587165319	resolved fixed	e02146943d3373020b7fa6e8acc31dc18b4201e4	1587265635	pytorch_lightning\trainer\training_tricks.py                                                                    
41	1538	`num_tpu_cores=8` does not work on kaggle	bug try train model kaggle tpu num tpu core set receive error exception process terminated exit code would great worked kaggle reproduce steps reproduce behavior run notebook exception traceback recent call last basic trainer us good default tpu trainer pl trainer num tpu core trainer fit mnist model opt conda lib python3 site package pytorch lightning trainer trainer py fit self model train dataloader val dataloaders test dataloaders train xmp spawn self tpu train args model nprocs self num tpu core start method start method load weight interrupted opt conda lib python3 site package torch xla distributed xla multiprocessing py spawn fn args nprocs join daemon start method join join daemon daemon start method start method opt conda lib python3 site package torch multiprocessing spawn py start process fn args nprocs join daemon start method loop join return true raise exception context join pas opt conda lib python3 site package torch multiprocessing spawn py join self timeout raise exception process terminated exit code error index exitcode exception process terminated exit code code sample trainer pl trainer num tpu core precision expected behavior run model utilizing tpu core environment cuda gpu available false version none package numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor python version smp sat apr pdt	2020-04-20 18:04:20	1587405860	resolved fixed	831842972f7e2d25ae3a376d5584748c3054f899	1587640374	CHANGELOG.md pytorch_lightning\trainer\trainer.py                                                                  
42	154	transfer_to_batch_gpu returns null when input has primitives	describe bug passing batch batch list tensor tensor list ints returned correctly additional context fix add return item condition match	2019-08-20 16:57:39	1566320259	resolved fixed	55a804b7cfb9b2376ccaa1253a966dcaa9b6ab07	1566334766	pytorch_lightning\models\trainer.py                                                                    
43	1540	DDP on GPUs invalid ordinal	bug latest version master training ddp backend gpus let say result cuda error invalid device ordinal reproduce steps reproduce behavior run lightning module ddp backend gpu gpu index start see error info lightning gpu available true used true info lightning visible gpus warning lightning slurm nodeid node rank environment variable defined set warning lightning master addr environment variable defined set localhost warning lightning slurm nodeid node rank environment variable defined set warning lightning master addr environment variable defined set localhost thcudacheck fail file pytorch torch csrc cuda module cpp line error invalid device ordinal thcudacheck fail file pytorch torch csrc cuda module cpp line error invalid device ordinal traceback recent call last file bin run py line run config args mode file bin run py line run trainer fit system file home kevin miniconda3 lib python3 site package pytorch lightning trainer trainer py line fit mp spawn self ddp train nprocs self num process args model file home kevin miniconda3 lib python3 site package torch multiprocessing spawn py line spawn spawn context join file home kevin miniconda3 lib python3 site package torch multiprocessing spawn py line join raise exception msg exception process terminated following error traceback recent call last file home kevin miniconda3 lib python3 site package torch multiprocessing spawn py line wrap fn args file home kevin miniconda3 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train torch cuda set device self root gpu file home kevin miniconda3 lib python3 site package torch cuda init py line set device torch c cuda setdevice device runtimeerror cuda runtime error invalid device ordinal pytorch torch csrc cuda module cpp expected behavior expect error occur environment cuda gpu titan rtx titan rtx titan rtx titan rtx titan rtx titan rtx titan rtx titan rtx available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp wed apr utc additional context best guess due new refactoring ddp cpu backend setting cuda device root gpu instead using provided gpu idx parameter ddp train causing error specifically gpu using index instead index index instead index since setting cuda visible devices	2020-04-20 22:25:22	1587421522	resolved fixed	bafdeca42f746aac59b4f0c1103264d7bff556db	1587493755	pytorch_lightning\trainer\distrib_data_parallel.py                                                                    
44	1546	LightningTemplateModel is broken	bug implemented method see reproduce try run test evaluation mnist example expected behavoir crash	2020-04-21 12:02:31	1587470551	resolved fixed	210cd657dd0f83069b8c6abc7402508f354668b3	1588423297	CHANGELOG.md pl_examples\models\lightning_template.py                                                                  
45	1547	Metric aggragation is broken for LoggerCollection	bug change possible log testing metric traning using several logger reproduce say want run minst example also want add change log testing metric training define callback class testcallback callback def train end self trainer pl module note would crash pas pl module trainer test pl module pas trainer callback argument would also like use several logger track metric say mlflowlogger tensorboardlogger create instance logger pas trainer list expected behavior testing metric logged final aggregation logger loggercollection additional context opinion logic agg log metric finalize agg metric hard follow happy user could choose plain old log metric worked nicely	2020-04-21 12:25:52	1587471952	resolved fixed	458d3e210e2da10482d97a996708731b8b0fabae	1596059582	CHANGELOG.md pytorch_lightning\loggers\base.py tests\loggers\test_base.py                                                                
46	1566	Batch being moved to gpu repeatedly with multiple optimizers and single gpu training	multiple optimizers transfer batch gpu wind getting called per opt idx batch copied time via copy copy batch training forward copy batch single gpu removing copy copy gan model move pretty significant speedup	2020-04-22 21:32:23	1587591143	resolved fixed	41b6cbb3ca8a3a43e091d7f0de4d0184a8870d19	1587666500	pytorch_lightning\trainer\training_loop.py                                                                    
47	157	Recursive device conversion of tuple	bug report related describe bug passing batch batch tensor tensor tensor b tensor tensor b tensor transfer batch gpu raise error typeerror tuple object support item assignment found error caused concatenation two condition isinstance batch list isinstance batch tuple expected behavior batch batch tensor tensor tensor b tensor tensor b tensor batch cuda tensor cuda tensor cuda tensor b cuda tensor cuda tensor b cuda tensor additional context already fixed bug submit pr soon	2019-08-21 04:32:22	1566361942	resolved fixed	4a0b56755c7239e6a85b32a3d3e97cf7f9e39044	1566397371	pytorch_lightning\models\trainer.py tests\test_models.py                                                                  
48	1570	Trainer.add_argparse_args bool type	bug boolean argument added using trainer add argparse args always evaluate true caused following line add argparse args fucntion isinstance allowed type bool def allowed type x return bool distutils util strtobool x allowed type actual data type instance bool isinstance bool bool equal false bool bool equal true	2020-04-23 12:46:12	1587645972	resolved fixed	545b38ec5f1b1de7aaabec7a6cf4f2f4d7893b71	1587656658	CHANGELOG.md pytorch_lightning\trainer\trainer.py                                                                  
49	1588	Named converted to regular tuples when sent to the gpu.	bug named tuples returned dataset get converted regular tuples sent gpu happens isinstance instance named tuple tuple evaluates true distrib part py pytorch lightning pytorch lightning trainer distrib part py line isinstance batch tuple reproduce import pytorch lightning pl collection import namedtuple import torch import numpy namedtupledemoinput namedtuple demoinput x1 x2 class namedtupledemodataset def len self return def getitem self index x1 numpy random uniform x2 numpy random uniform x1 x2 numpy random normal return namedtupledemoinput x1 x2 class weightedsum torch nn module def init self super weightedsum self init self torch nn parameter torch zero self b torch nn parameter torch zero def forward self x1 x2 return self x1 self b x2 class namedtupledemo pl lightningmodule def init self super namedtupledemo self init self model weightedsum def forward self x1 x2 return self model x1 x2 def train dataloader self return torch utils data dataloader namedtupledemodataset batch size def training step self batch batch index yhat self forward batch x1 batch x2 return loss torch nn functional mse loss batch yhat def configure optimizers self return torch optim adam self parameter lr name main module namedtupledemo pl trainer max epoch gpus fit module print f float module model b float module model b traceback recent call last file demo py line pl trainer max epoch gpus fit module file home n repos pytorch lightning pytorch lightning trainer trainer py line fit self single gpu train model file home n repos pytorch lightning pytorch lightning trainer distrib part py line single gpu train self run pretrain routine model file home n repos pytorch lightning pytorch lightning trainer trainer py line run pretrain routine self train file home n repos pytorch lightning pytorch lightning trainer training loop py line train self run training epoch file home n repos pytorch lightning pytorch lightning trainer training loop py line run training epoch output self run training batch batch batch idx file home n repos pytorch lightning pytorch lightning trainer training loop py line run training batch loss batch output optimizer closure file home n repos pytorch lightning pytorch lightning trainer training loop py line optimizer closure output dict self training forward split batch batch idx opt idx self hiddens file home n repos pytorch lightning pytorch lightning trainer training loop py line training forward output self model training step args file demo py line training step yhat self forward batch x1 batch x2 attributeerror tuple object attribute x1 expected behavior namedtuples returned dataset keep original field environment cuda gpu geforce rtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor python version smp preempt sun apr	2020-04-24 03:46:31	1587699991	resolved fixed	3eac6cfd4fbbc4d13f4e93f6d90f8ee5302c421e	1588248290	pytorch_lightning\trainer\distrib_parts.py tests\models\test_cpu.py                                                                  
50	1620	horovod cicd tests are failing on ubuntu 18.04 python 3.6 latest	bug failed job see two error runtimeerror failed determine nccl support built run verbose detail importerror opt hostedtoolcache python x64 lib python3 site package horovod torch mpi lib v2 cpython x86 linux gnu undefined symbol ztin3c1021autogradmetainterfacee hunch caused horovod compilation issue another thing note test passing ubuntu python minimal tgaddair maybe idea reproduce run cicd test suite	2020-04-26 17:06:09	1587920769	resolved fixed	813e37916d9b17224be3d6c4d1672876bfb88a54	1587995338	.github\workflows\ci-testing.yml                                                                    
51	1628	Bug in DDP, but not DP modes.	pytorch pytorch lightning version dp everything work ddp fails file home vladimir anaconda3 envs solaris lib python3 multiprocessing popen fork py line init self launch process obj file home vladimir anaconda3 envs solaris lib python3 multiprocessing popen spawn posix py line launch reduction dump process obj fp file home vladimir anaconda3 envs solaris lib python3 multiprocessing reduction py line dump forkingpickler file protocol dump obj pickle picklingerror pickle object torch c variablefunctions	2020-04-27 00:24:51	1587947091	resolved fixed	9604d7bf8994615431af9d86c8de154677237b75	1587995780	pytorch_lightning\callbacks\model_checkpoint.py                                                                    
52	1665	Trainer add args doesn't add default root dir	bug using parser trainer add argparse args parser supposed put trainer argument argparse default value though currently add default root dir get error namespace object attribute default root dir add default save path deprecated reproduce code sample import argparse pytorch lightning import trainer parser argparse argumentparser description demo parser trainer add argparse args parser args parser parse args print args default root dir similar unit test could also made already environment cuda gpu geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti geforce rtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp tue oct utc	2020-04-29 15:59:49	1588175989	resolved fixed	9059d21042a5f18fcb18a1792a901e8e62a3b61a	1589288006	CHANGELOG.md pytorch_lightning\trainer\trainer.py                                                                  
53	1683	NeptuneLogger doesn't work with distributed_backend='ddp'	bug using neptunelogger distributed backend ddp running single node two gpus find error like traceback recent call last file pl py line main file pl py line main trainer fit model file home hirune anaconda3 envs panda lib python3 site package pytorch lightning trainer trainer py line fit mp spawn self ddp train nprocs self num process args model file home hirune anaconda3 envs panda lib python3 site package torch multiprocessing spawn py line spawn return start process fn args nprocs join daemon start method spawn file home hirune anaconda3 envs panda lib python3 site package torch multiprocessing spawn py line start process context join file home hirune anaconda3 envs panda lib python3 site package torch multiprocessing spawn py line join raise exception msg exception process terminated following error traceback recent call last file home hirune anaconda3 envs panda lib python3 site package torch multiprocessing spawn py line wrap fn args file home hirune anaconda3 envs panda lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file home hirune anaconda3 envs panda lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self configure checkpoint callback file home hirune anaconda3 envs panda lib python3 site package pytorch lightning trainer callback config py line configure checkpoint callback self logger name file home hirune anaconda3 envs panda lib python3 site package pytorch lightning logger neptune py line name return self experiment name file home hirune anaconda3 envs panda lib python3 site package pytorch lightning logger neptune py line experiment self kwargs file home hirune anaconda3 envs panda lib python3 site package neptune init py line create experiment raise uninitialized neptune exception uninitialized must initialize neptune client first information please visit found similar error commetlogger reproduce steps reproduce behavior run following code machine two gpus code slightly modified version page code sample import o import torch torch nn import functional f torch utils data import dataloader torchvision datasets import mnist torchvision import transforms import pytorch lightning pl max epochs lr batchsize checkpoints dir model checkpoint class coolsystem pl lightningmodule def init self super coolsystem self init best model self l1 torch nn linear def forward self x return torch relu self l1 x view x size def training step self batch batch idx required x batch hat self forward x loss f cross entropy hat tensorboard log train loss loss return loss loss log tensorboard log def validation step self batch batch idx optional x batch hat self forward x return val loss f cross entropy hat def validation end self output optional avg loss torch stack x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def test step self batch batch idx optional x batch hat self forward x return test loss f cross entropy hat def test end self output optional avg loss torch stack x test loss x output mean tensorboard log test loss avg loss return avg test loss avg loss log tensorboard log def configure optimizers self required return multiple optimizers learning rate scheduler lbfgs automatically supported need closure function return torch optim adam self parameter lr lr pl data loader def train dataloader self required return dataloader mnist o getcwd train true download true transform transforms totensor batch size batchsize pl data loader def val dataloader self optional return dataloader mnist o getcwd train true download true transform transforms totensor batch size batchsize pl data loader def test dataloader self optional return dataloader mnist o getcwd train false download true transform transforms totensor batch size batchsize pytorch lightning logger neptune import neptunelogger def main neptune logger neptunelogger api key anonymous project name shared pytorch lightning integration close fit false experiment name default optional params max epoch max epochs batch size batchsize lr lr optional tag pytorch lightning mlp optional model checkpoint pl callback modelcheckpoint filepath checkpoints dir pytorch lightning import trainer model coolsystem trainer trainer max epoch max epochs logger neptune logger checkpoint callback model checkpoint gpus distributed backend ddp trainer fit model trainer test model get prediction external test import numpy np model freeze test loader dataloader mnist o getcwd train false download true transform transforms totensor batch size true pred x enumerate test loader hat model forward x argmax axis cpu detach numpy cpu detach numpy true append pred append hat len test loader break true np hstack true pred np hstack pred log additional metric sklearn metric import accuracy score accuracy accuracy score true pred neptune logger experiment log metric test accuracy accuracy log chart scikitplot metric import plot confusion matrix import matplotlib pyplot plt fig ax plt subplots figsize plot confusion matrix true pred ax ax neptune logger experiment log image confusion matrix fig save checkpoint folder neptune logger experiment log artifact checkpoints dir stop experiment neptune logger experiment stop name main main expected behavior environment cuda gpu geforce gtx titan x geforce gtx titan x available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp fri jan utc additional context	2020-05-01 03:39:30	1588304370	resolved fixed	0cb676746568b6ca3c1ef9d9d2879b913f183179	1589131158	pytorch_lightning\loggers\neptune.py tests\loggers\test_neptune.py                                                                  
54	1687	name 'IProgress' is not defined	name iprogress defined running jupyter notebook	2020-05-01 09:48:04	1588326484	resolved fixed	1a54ed6ad9f1faf8ac58bbded4b71e4dd18246d6	1593550775	CHANGELOG.md pytorch_lightning\callbacks\progress.py pytorch_lightning\trainer\lr_finder.py                                                                
55	1697	[Examples] The UNet model has some bugs	bug unet model definition bug pertaining bilinear interpolation code sample pytorch lightning pl example model unet py lines range num layer layer append feat feat bilinear feat code seems typo bilinear flag passed function instead passed append method list pytorch lightning pl example model unet py lines bilinear self upsample nn upsample scale factor mode bilinear align corner true else self upsample nn convtranspose2d ch ch kernel size stride number channel input pass either one layer different bilinear number channel remains whereas decrease half convtranspose2d used give error network forward method wanted directly use model application sure issue solved maybe use convolution reduce channel half	2020-05-01 23:14:20	1588374860	resolved fixed	cf2d32d0a6c757aad39c36b621a646ed3a24619a	1589438205	pl_examples\domain_templates\semantic_segmentation.py pl_examples\models\unet.py                                                                  
56	1721	instable GitHub action cache	bug issue gh action caching randomly failing using horovod reproduce comment	2020-05-03 21:50:02	1588542602	resolved fixed	281a73ccf7a22cdf004755f1f7b4aead40b12d84	1588590791	.github\workflows\ci-testing.yml                                                                    
57	1751	Early Stopping behavior	hi thanks great library using following bug report template sure indeed bug simply understand early stopping implemented code look follows early stop callback earlystopping monitor val acc min delta patience verbose true mode self mode trainer trainer early stop callback early stop callback auto select gpus true max epoch terminate nan true show progress bar true fast dev run false gpus understand model perform early stopping least epoch passed without improvement validation accuracy however case early stopping happened epoch said sure actually bug choice perhaps early stopping implemented batch level indeed bug work reproducible example thank	2020-05-07 06:12:51	1588831971	resolved fixed	3af4994d5a84bc80738b50983b4b42c3eb946433	1590534366	CHANGELOG.md pytorch_lightning\trainer\training_loop.py                                                                  
58	1829	Allow boolean flags to work without passing True	tried fix still broken fails adding args argparse automatically auto lr find instead auto lr find true great	2020-05-14 01:52:04	1589421124	resolved fixed	bee0392c372936567b2bbe6e7ed5828cb3078354	1589493371	pytorch_lightning\trainer\trainer.py tests\trainer\test_trainer_cli.py                                                                  
59	1850	lr_find doesn't return the correct suggestion if some losses are nan	bug lr finder return correct suggestion loss nan returned loss one corresponding nan value big case reproduce depends dataset please see code sample code sample believe caused numpy related code pytorch lightning pytorch lightning trainer lr finder py line b84b024 min grad np gradient np array loss argmin example loss print np gradient example loss argmin example loss float nan print np gradient example loss argmin output expected behavior return correct suggested loss environment cuda gpu available false version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor python version smp debian additional context na	2020-05-16 05:36:55	1589607415	resolved fixed	ac76dfcf62a672c84f843f2e3158e4c6262776da	1589870359	CHANGELOG.md pytorch_lightning\trainer\lr_finder.py tests\trainer\test_lr_finder.py                                                                
60	1857	Can not use Trainer.test() if train and val dataloaders are not defined	bug model define train dataloader val dataloader use trainer test model test dataloaders test dl configuration check fail misconfigurationexception code sample model model train dataloader val dataloader defined test dl dataloader trainer pl trainer trainer test model test dataloaders test dl expected behavior expect testing loop execute	2020-05-16 23:37:00	1589672220	resolved fixed	1a797bdad5df6d4e7ccc586ddeb93dccb2a9648a	1589747420	tests\trainer\test_checks.py                                                                    
61	1878	prepare_data called multiple times per node for slurm and elastic training	bug slurm elastic training create training process per node outside lightning context mean fit function call prepare data assumption called proc broken get called process issue computational reason e g downloading whole dataset training stability data preparation process deterministic see calling code pytorch lightning pytorch lightning trainer trainer py line model prepare data reproduce steps reproduce behavior add print statement prepare data train lightning model either slurm elastic training see called multiple time expected behavior expected prepare data called per node	2020-05-18 23:00:34	1589842834	resolved fixed	5fd01b0e68a6087908ac0bcefd4edaeddfb0e248	1592064014	pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\core\lightning.py pytorch_lightning\trainer\__init__.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\logging.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\trainer\training_loop.py                                                
62	1889	trainer.scale_batch_size() throws exception due to LRScheduler	bug tried finding biggest possible batch size training pl raise misconfigurationexception saying lrscheduler reducelronplateau conditioned metric available validation epoch end available metric loss val loss assume lrscheduler requires metric training loop work neccessary reproduce steps reproduce behavior model metric exists validation epoch end lrscheduler monitor metric use trainer scale batch size see error file c programdata anaconda3 envs ml lib site package pytorch lightning trainer training loop py line update learning rate raise misconfigurationexception pytorch lightning utility exception misconfigurationexception reducelronplateau conditioned metric meaniou available available metric loss train loss condition set using monitor key lr scheduler dict code sample trainer pl trainer gpus hparams gpus new batch size trainer scale batch size net mode binsearch init val model def configure optimizers self opt optim adam self parameter lr self hparams learning rate scheduler scheduler optim lr scheduler reducelronplateau opt mode max factor patience monitor meaniou default val loss return opt scheduler def validation epoch end self output avg loss torch stack x val loss x output mean iou class mean iou self iou metric value mean iou torch tensor mean iou self iou metric reset log val loss avg loss meaniou mean iou return meaniou mean iou log log progress bar val loss avg loss meaniou mean iou expected behavior exception maximum batch size model environment cuda gpu geforce rtx super available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os windows architecture windowspe processor amd64 family model stepping authenticamd python version additional context	2020-05-19 10:28:37	1589884117	resolved fixed	3459a546672303204a4ae6efcc2613a90f003903	1589908586	pytorch_lightning\trainer\training_loop.py                                                                    
63	189	Logging of GPU memory utilization can significantly slow down training	training using gpus pytorch lightning automatically log gpu memory utilization training useful feature severely impact performance dependent speed nvidia smi call particular cluster university scale hpc cluster based ibm lsf lead performance decrease almost fold training gpu v cpu describe bug logging gpu memory severe impact training performance remove gpu memory logging commenting line pytorch lightning model trainer py see expected behavior logging gpu memory utilization impede performance running nvidia smi call background least possible deactivate case performance issue arise desktop please complete following information os ubuntu linux nvidia geforce gtx	2019-09-03 15:48:23	1567525703	resolved fixed	dac41030d48acbfecdf7c083b8e7b00f3fd9be06	1567608226	docs\Trainer\Logging.md pytorch_lightning\models\trainer.py                                                                  
64	1898	batch size finder does not recognize flag and seems to download often	auto scale batch size flag requires string also work set true ie support case auto scale batch size seems trigger data downloads frequently files already downloaded verified files already downloaded verified files already downloaded verified files already downloaded verified files already downloaded verified files already downloaded verified batch size succeeded trying batch size files already downloaded verified	2020-05-20 04:02:38	1589947358	resolved fixed	a34eb9e169622fe91fdf4d98560b65b2f2b5c8d0	1590407036	CHANGELOG.md pytorch_lightning\trainer\trainer.py tests\trainer\test_lr_finder.py tests\trainer\test_trainer_tricks.py                                                              
65	1899	Incorrect number of batches when multiple test loaders are used and test_percent_check is specified	bug multiple test dataloaders test percent check specified estimated total batch incorrect progress bar show properly example specify two dataloaders batch test percent check expected total batch actually batch run line num batch global number batch assigned self num test batch pytorch lightning pytorch lightning trainer data loading py line num batch int num batch percent check evaluation loop max batch regarded number batch one data loader pytorch lightning pytorch lightning trainer evaluation loop py line batch idx max batch reproduce steps reproduce behavior return multiple dataloaders test dataloaders specify test percent check run trainer test observe expected batch num loader run progress bar also fails show progress expected batch exceeds specified total step expected behavior run correct number batch environment cuda gpu available false version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor python version smp debian	2020-05-20 06:25:58	1589955958	resolved fixed	e085e93dd303e80af2e9a5fe4aa392055c831114	1592925684	CHANGELOG.md pytorch_lightning\trainer\__init__.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\base\model_test_dataloaders.py tests\base\model_test_epoch_ends.py tests\base\model_utilities.py tests\base\model_valid_dataloaders.py tests\base\model_valid_epoch_ends.py tests\test_deprecated.py tests\trainer\test_dataloaders.py                                            
66	1916	Trainer.parse_argparser does not yield sensible default for default_root_dir	bug using trainer parse argparser return true default root dir however string expected reproduce steps reproduce behavior pytorch lightning import trainer argparse import argumentparser namespace parser argumentparser add help false parser trainer add argparse args parent parser parser args trainer parse argparser parser args namespace accumulate grad batch amp level o1 auto lr find false auto scale batch size false auto select gpus false benchmark false check val every n epoch checkpoint callback true default root dir true deterministic false distributed backend true early stop callback false fast dev run false gpus gradient clip val log gpu memory true log save interval logger true max epoch max step true min epoch min step true num node num process num sanity val step overfit pct precision print nan grad false process position profiler true progress bar callback true progress bar refresh rate reload dataloaders every epoch false replace sampler ddp true resume checkpoint true row log interval terminate nan false test percent check tpu core true track grad norm train percent check truncated bptt step true val check interval val percent check weight save path true weight summary full	2020-05-21 03:19:41	1590031181	resolved fixed	b3ebfec863df8513f42e7211a29f857139e8ede4	1594293030	pytorch_lightning\trainer\trainer.py tests\trainer\test_trainer_cli.py                                                                  
67	1937	"TODO list for ""replace Hparams by init args"" PR"	todo follow work module argument rework doc make clear multiple way args passed example class litmodel lightningmodule def init self arg1 arg2 trainer add argparse args parser litmodel add model specific args parser litmodel parser parse args fail work since list argument constructor fixed size fix two way add kwargs init signature catch unnecessary args good design work split parser separate model args trainer args doc make clear type save checkpoint nn module example name module argument maybe misleading believe args saved old code left commented including test mentioned yukw777 test model checkpointing changed thoroughly test correct args loaded test test case positional args bugfix fix super called called local var added e g class litmodel lightningmodule def init self arg1 arg2 local var super init module argument contains local var litmodel load checkpoint fails typeerror init got unexpected argument local var obviously want local var argument checkpoint bugfix python forced call instance self currently hardcoded lead class litmodel lightningmodule def init obj arg1 arg2 obj arg1 arg1 super init module argument contain litmodel applies conventional naming args kwargs test make sure lrfinder still work expected passing suggested learning rate argument fixed enhancement festeh want add support dataclasses bugfix example broken problem mentioned test multiple inheritance error warn self auto collect argument called somewhere init specific use case currently working feel free add additional bullet point missed	2020-05-24 23:28:26	1590362906	resolved fixed	4234992302608e1999c00b4faffac591fb537a34	1591274150	CHANGELOG.md pytorch_lightning\core\lightning.py tests\models\test_hparams.py                                                                
68	195	Non plain-tensor batches	hello trying use lightning train graph neural network built torch geometric package using gpu error get try fit model miniconda3 envs pyg lib python3 site package torch geometric nn conv gcn conv py forward self x edge index edge weight def forward self x edge index edge weight none x torch matmul x self weight self cached self cached result none runtimeerror expected object backend cpu got backend cuda argument mat2 investigated code lightning probable cause found transfer batch gpu cause error current behavior function considers batch either plain simple collection object list dict tuple problem torch geometric us custom aggregate type doc implement method implement believe would nice could make code flexible process case similar case general correctly believe best solution replace isinstance batch torch tensor condition batch object either cuda method implemented solve problem general	2019-09-04 13:13:13	1567602793	resolved fixed	34b824a9d3d0fdd377da675e0398c66ab5e16e7b	1567681986	pytorch_lightning\models\trainer.py                                                                    
69	2027	Support DictConfig	need add dictconfig support omegaconf borda auto hparam save	2020-05-31 12:33:44	1590928424	resolved fixed	d2967d9305b42c9260f821f2b7fb43fbf19ca1aa	1591615174	CHANGELOG.md docs\source\hyperparameters.rst pytorch_lightning\core\lightning.py pytorch_lightning\core\saving.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\utilities\__init__.py pytorch_lightning\utilities\parsing.py tests\base\model_template.py tests\loggers\test_trains.py tests\models\test_cpu.py tests\models\test_hparams.py tests\models\test_restore.py tests\requirements-devel.txt tests\trainer\test_trainer.py                                        
70	2058	Hydra MLFlow Clash	bug using mlflow logger hydra parameter passed lightningmodule dictconfig condition logger base py met pytorch lightning pytorch lightning logger base py line isinstance input dict dict reproduce use hydra mlflow together traceback recent call last file home siavash kronikare kwae2 kwae model pl train segmentation model py line main file home siavash anaconda3 envs kwae lib python3 site package hydra main py line decorated main strict strict file home siavash anaconda3 envs kwae lib python3 site package hydra internal utils py line run hydra override args override file home siavash anaconda3 envs kwae lib python3 site package hydra internal hydra py line run job subdir key none file home siavash anaconda3 envs kwae lib python3 site package hydra plugins common utils py line run job ret return value task function task cfg file home siavash kronikare kwae2 kwae model pl train segmentation model py line main trainer fit wound seg pl file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning trainer trainer py line fit self single gpu train model file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning trainer distrib part py line single gpu train self run pretrain routine model file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self logger log hyperparams ref model hparams file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning logger base py line log hyperparams logger log hyperparams params logger self logger iterable file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning logger base py line logger log hyperparams params logger self logger iterable file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning utility distributed py line wrapped fn return fn args kwargs file home siavash anaconda3 envs kwae lib python3 site package pytorch lightning logger mlflow py line log hyperparams self experiment log param self run id k v file home siavash anaconda3 envs kwae lib python3 site package mlflow tracking client py line log param self tracking client log param run id key value file home siavash anaconda3 envs kwae lib python3 site package mlflow tracking tracking service client py line log param validate param name key file home siavash anaconda3 envs kwae lib python3 site package mlflow utils validation py line validate param name invalid parameter value mlflow exception mlflowexception invalid parameter name names may treated file certain case must resolve name treated name would resolve expected behavior check whether instance dict dictconfig given line	2020-06-03 08:16:37	1591172197	resolved fixed	44385bb582467acaa35cd4da553b2343a7860598	1592925644	pytorch_lightning\loggers\base.py                                                                    
71	2092	[ddp] New ddp implementation doesn't work in notebooks / using scripts	using spawn spin subprocesses ddp problem everything need picklable work well num worker dataloaders spawn fit model train model subprocess original model updated limitation lightning pytorch python result removed spawn instead call script hood approach solves problem assumes call model like python train py support way calling script decide support ddp jupyter notebook	2020-06-05 20:33:09	1591389189	resolved fixed	3260e59b2723a0f5d666c6779486717aa3a9373d	1591653325	docs\source\multi_gpu.rst pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\trainer.py                                                              
72	2131	wandLogger().name is None in DDP mode	remove line everything work ddp mode issue	2020-06-09 15:01:43	1591714903	resolved fixed	145670f893f43ff70866668cf087d82fe51a22a6	1593554956	pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\loggers\base.py pytorch_lightning\loggers\comet.py pytorch_lightning\loggers\mlflow.py pytorch_lightning\loggers\neptune.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\loggers\test_tube.py pytorch_lightning\loggers\wandb.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\trainer.py tests\loggers\test_all.py tests\models\test_horovod.py                                              
73	2143	Fix checkpoint warning for floats	added warning saving checkpoint reason native python float supported think actually quite common especially library e g scipy involved computing metric say checkpoint saved actually checkpoint still saved check actually change saving logic besides giving warning	2020-06-11 02:44:58	1591843498	resolved fixed	97e62b38cfa0c9ce14050b603ec3e735ba760a71	1601864329	pytorch_lightning\core\step_result.py tests\trainer\logging\test_eval_loop_logging_1_0.py                                                                  
74	2167	The docker image tagged with Pytorch 1.5 and Python 3.8, has Pytorch 1.4 installed and is running Python 3.7	bug docker image tagged pytorch eg torch installed seen via pip list also running python instead python tag indicates reproduce steps reproduce behavior pull docker image docker pull pytorchlightning pytorch lightning py3 torch1 run container docker run rm init pytorchlightning pytorch lightning py3 torch1 check version python pytorch containeruser c5c87a61b71c python version python containeruser pip list grep torch pytorch lightning torch expected behavior since tag docker image py3 torch1 expect see running python pytorch environment n	2020-06-13 00:54:14	1592009654	resolved fixed	2f739f5977640bb8580b82a11f322f81f1b90d09	1593222368	.github\workflows\docker-builds.yml                                                                    
75	2180	Global Gradient calculation is turned off during validation step.	error occurs validation step tradition calculation turned runtime either specifically enable restart runtime	2020-06-14 09:57:52	1592128672	resolved fixed	25c7465591371f8fe4b4244ccc996706f4136cea	1592405578	pytorch_lightning\trainer\training_loop.py                                                                    
76	2188	[hparams] save_hyperparameters doesn't save kwargs	questions help use hyperparemeters like doc class litmnist lightningmodule def init self layer dim learning rate kwargs super init call save layer dim learning rate checkpoint self save hyperparameters model checkpoint save args kwargs kwargs important args num frame img size img std must used creating dataloader tedious writes init explicitly make code clean hide kwargs use hparams ok recommended use hparams good idea deal problem	2020-06-15 03:10:15	1592190615	resolved fixed	6ae9a97b09fd8e3239219c2882c6f3cc31a2ccf8	1592536105	pytorch_lightning\core\lightning.py pytorch_lightning\core\saving.py tests\models\test_hparams.py                                                                
77	2205	[metrics] Accuracy Metric: Tensors must be CUDA and dense	try new accuracy metric throw error traceback recent call last file main py line main hparams file main py line main trainer fit model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer trainer py line fit self ddp train task model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine false file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer evaluation loop py line evaluate output self evaluation forward model batch batch idx dataloader idx test mode file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer evaluation loop py line evaluation forward output model args file mnt lustre maxiao1 anaconda3 lib python3 site package torch nn module module py line call result self forward input kwargs file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning override data parallel py line forward output self module validation step input kwargs file mnt lustre maxiao1 pvm model baseline py line validation step acc self accuracy label hat label file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning metric metric py line call return apply collection self orig call args kwargs torch tensor file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning metric converter py line new func return func apply result dec args dec kwargs file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning utility apply func py line apply collection return function data args kwargs file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning metric converter py line sync ddp available async op false file mnt lustre maxiao1 anaconda3 lib python3 site package torch distributed distributed c10d py line reduce work default pg allreduce tensor opts runtimeerror tensors must cuda dense code pred pred view pred shape label label view valid index torch label select valid part calculate pred pred valid index contiguous label label valid index contiguous loss self loss fn pred label label hat torch argmax pred dim type label acc self accuracy label hat label also question tensormetric default reduce op sum automatically calculate average acc	2020-06-16 02:29:09	1592274549	resolved fixed	17d87731062691f4510c75f12f2ce63b5dde0a43	1598439689	CHANGELOG.md pytorch_lightning\core\step_result.py pytorch_lightning\metrics\converters.py pytorch_lightning\metrics\functional\classification.py pytorch_lightning\metrics\metric.py tests\base\model_train_steps.py tests\metrics\test_classification.py tests\metrics\test_converters.py tests\metrics\test_metrics.py tests\metrics\test_sklearn.py                                                  
78	224	set_epoch for DistributedSampler	describe bug pytorch example suggests use set epoch function distributedsampler class epoch start could find function call lightning trainer module line seen distributedsampler class code set epoch function required set seed function call confirm function called distributedsampler training dataset point lightning trainer module	2019-09-15 19:54:42	1568577282	resolved fixed	c0f3b6b035f955fc371dec412d3816712f3fc1dd	1568643660	pytorch_lightning\trainer\trainer.py                                                                    
79	2254	"Single node DDP: ""Default process group is not initialized"""	bug unable start single node ddp training reproduce going run gpu template method running template result error python pl example basic example gpu template gpus distributed backend ddp spawn python pl example basic example gpu template gpus distributed backend ddp gpu available true used true tpu available false using tpu core cuda visible devices traceback recent call last file opt conda lib python3 runpy py line run module main main mod spec file opt conda lib python3 runpy py line run code exec code run globals file opt conda lib python3 site package pl example basic example gpu template py line main hyperparams file opt conda lib python3 site package pl example basic example gpu template py line main trainer fit model file opt conda lib python3 site package pytorch lightning trainer trainer py line fit self barrier fit prepare data file opt conda lib python3 site package pytorch lightning trainer trainer py line barrier torch distrib barrier file opt conda lib python3 site package torch distributed distributed c10d py line barrier check default pg file opt conda lib python3 site package torch distributed distributed c10d py line check default pg default process group initialized assertionerror default process group initialized	2020-06-19 02:37:22	1592534242	resolved fixed	57d5f6e74a3bcd8f5c73211ba3a4e2480fcc1114	1592541740	docs\source\trainer.rst pytorch_lightning\core\hooks.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py                                                          
80	2281	RuntimeError: OrderedDict mutated during iteration	bug getting runtimeerror ordereddict mutated iteration seems like using lightningmodule object modelsummary trainer cause error reproduce pytorch lightning core memory import modelsummary model cifarnet pl module would work modelsummary model mode full trainer trainer fast dev run true gpus trainer fit model steps reproduce behavior view model summary using modelsummary class call trainer fit object stacktrace runtimeerror traceback recent call last checking error trainer trainer fast dev run true gpus trainer fit model frame usr local lib python3 dist package pytorch lightning trainer trainer py fit self model train dataloader val dataloaders elif self single gpu self single gpu train model elif self use tpu pragma cover usr local lib python3 dist package pytorch lightning trainer distrib part py single gpu train self model self reinit scheduler property self optimizers self lr scheduler self run pretrain routine model def tpu train self tpu core idx model usr local lib python3 dist package pytorch lightning trainer trainer py run pretrain routine self model core training loop self train def test usr local lib python3 dist package pytorch lightning trainer training loop py train self run tng epoch self run training epoch self max step self max step self global step usr local lib python3 dist package pytorch lightning trainer training loop py run training epoch self run train step output self run training batch batch batch idx batch result grad norm dic batch step metric batch output output usr local lib python3 dist package pytorch lightning trainer training loop py run training batch self batch batch idx calculate loss loss batch output optimizer closure check loss model weight nan usr local lib python3 dist package pytorch lightning trainer training loop py optimizer closure opt idx self hiddens else output dict self training forward split batch batch idx opt idx self hiddens format reduce output accordingly usr local lib python3 dist package pytorch lightning trainer training loop py training forward self batch batch idx opt idx hiddens batch self transfer batch gpu batch gpu id args batch output self model training step args tpu support training step self batch batch idx def training step self batch batch idx x batch hat self x return loss f cross entropy hat usr local lib python3 dist package torch nn module module py call self input kwargs result self slow forward input kwargs else result self forward input kwargs hook self forward hook value hook result hook self input result forward self x def forward self x return self model x def prepare data self usr local lib python3 dist package torch nn module module py call self input kwargs else result self forward input kwargs hook self forward hook value hook result hook self input result hook result none runtimeerror ordereddict mutated iteration expected behavior able use object class environment cuda gpu tesla t4 available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp wed feb pst	2020-06-19 20:22:20	1592598140	resolved fixed	f972ab3a828eae1847a793da0b2c25c6074647a4	1592653127	CHANGELOG.md pytorch_lightning\core\memory.py tests\core\test_memory.py                                                                
81	2286	example_input_array dtype	currently assumed example input array dtype equal model dtype necessarily correct e g input vector int pytorch lightning pytorch lightning core memory py line input apply collection input torch tensor lambda x x type model dtype	2020-06-19 21:38:11	1592602691	resolved fixed	6bfcfa8671c4bf54b34290171f191db65fa27d8c	1593947842	CHANGELOG.md pytorch_lightning\core\memory.py tests\core\test_memory.py                                                                
82	2299	DDP Bug with Model Checkpoint parsing	bug script work cpu single gpu dp need ddp bit training also even single machine ddp faster modelcheckpoint code def setup model checkpoint config kwargs config model checkpoint kwargs metric kwargs pop metric val loss isinstance metric str metric metric fp checkpoint epoch metric metric fp fp str metric fp return modelcheckpoint filepath fp kwargs case would generate checkpoint checkpoint epoch val loss auc example although even tried checkpoint issue issue following file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line fit file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line fit file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line fit self ddp train task model self ddp train task model self ddp train task model file home user miniconda envs py36 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train file home user miniconda envs py36 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train file home user miniconda envs py36 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model self run pretrain routine model file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self run pretrain routine model file home user miniconda envs py36 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self configure checkpoint callback self configure checkpoint callback file home user miniconda envs py36 lib python3 site package pytorch lightning trainer callback config py line configure checkpoint callback file home user miniconda envs py36 lib python3 site package pytorch lightning trainer callback config py line configure checkpoint callback self configure checkpoint callback file home user miniconda envs py36 lib python3 site package pytorch lightning trainer callback config py line configure checkpoint callback checkpoint checkpoint file home user miniconda envs py36 lib python3 posixpath py line join file home user miniconda envs py36 lib python3 posixpath py line join checkpoint genericpath check arg type join p file home user miniconda envs py36 lib python3 genericpath py line check arg type file home user miniconda envs py36 lib python3 posixpath py line join genericpath check arg type join p file home user miniconda envs py36 lib python3 genericpath py line check arg type funcname class name none genericpath check arg type join p typeerror join argument must str byte nonetype file home user miniconda envs py36 lib python3 genericpath py line check arg type funcname class name none typeerror join argument must str byte nonetype funcname class name none typeerror join argument must str byte nonetype environment pytorch version e g os e g linux linux installed pytorch conda pip source conda build command used compiling source python version cuda cudnn version gpu model configuration x v100 relevant information pytorch lightning additional context	2020-06-20 14:15:24	1592662524	resolved fixed	90f641af0d509645ecd679d00f1213f68d4a44ad	1593284902	pl_examples\models\lightning_template.py pytorch_lightning\trainer\callback_config.py                                                                  
83	2311	overfit_batches doesn't work	try use overfit batch trainer trainer gpus num gpus max epoch config epoch overfit batch logger logger code fails trainer fit module file home andriy miniconda3 envs patchy disc model lib python3 site package pytorch lightning trainer trainer py line fit self single gpu train model file home andriy miniconda3 envs patchy disc model lib python3 site package pytorch lightning trainer distrib part py line single gpu train self run pretrain routine model file home andriy miniconda3 envs patchy disc model lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self reset val dataloader ref model file home andriy miniconda3 envs patchy disc model lib python3 site package pytorch lightning trainer data loading py line reset val dataloader self reset eval dataloader model val file home andriy miniconda3 envs patchy disc model lib python3 site package pytorch lightning trainer data loading py line reset eval dataloader f requested check limit eval batch mode dataloader pytorch lightning utility exception misconfigurationexception requested check val dataloader please increase limit val batch try least limit val batch p also tried setting limit val batch error	2020-06-21 23:44:11	1592783051	resolved fixed	e6c7548b306055e41552e23d57f0057e7f441256	1600556458	CHANGELOG.md pytorch_lightning\trainer\data_loading.py                                                                  
84	2314	Breaking compatibility with custom datatypes implementing `.to`	feature bring back compatibility custom datatypes collection implementing transferring data motivation using pytorch lightning together pytorch geometric pytorch geometric implement several custom datatypes dataloaders really useful geometric deep learning everything worked well pytorch lightning custom datatypes implement method transferring data different device however recent update longer possible scour documentation able implement fix using transfer batch device batch device opinion pretty batch look like data pytorch geometric batch object id tensor e dictionary type implement method pitch make possible class implementing method transferred automatically part batch could transferred automatically output warning letting user know custom transfer function batch might required implement method custom datatypes batch add note introduction guide custom datatypes handling custom datatypes alternatives change intentional behavior trying call method desired think definitely documentation obvious place additional context	2020-06-22 12:59:13	1592830753	resolved fixed	aab9e77d2d4ac601a08ca6365dd846a88b83517f	1592970062	CHANGELOG.md pytorch_lightning\core\hooks.py pytorch_lightning\utilities\apply_func.py tests\models\test_gpu.py                                                              
85	2315	Bug in average_precision Metric	bug hi everyone encountered bug using average precision metric pytorch lightning metric functional classification yield incorrect result negative one seems missing parenthesis code work corrected return torch sum recall recall precision order reproduce negative result import torch import pytorch lightning metric functional classification torch manual seed truth torch rand pred torch rand average precision pred truth find issue topic yet needed submit pr thanks	2020-06-22 13:25:26	1592832326	resolved fixed	92f122e0df7e233f3a8b7873c7294155afbbf852	1592911260	CHANGELOG.md pytorch_lightning\metrics\functional\classification.py tests\metrics\functional\test_classification.py                                                                
86	2330	`use_amp` and multiple optimizers bug	bug faced issue tried use mixed precision two head model two pair optimizer scheduler without use amp everything work fine enabled get typeerror cosineannealinglr object subscriptable investigation ended def reinit scheduler property self optimizers list scheduler list reinitialize optimizer step property added scheduler scheduler scheduler optimizer optimizers scheduler scheduler scheduler place scheduler optimizer optimizer obviously next optimizer get scheduler actual non dict object reassigned first iteration reproduce steps reproduce behavior build lightningmodule configure optimizers method output list two optimizers two scheduler case something like def configure optimizers self opt adam params self head params opt adam params self head params sch cosineannealinglr optimizer opt sch cosineannealinglr optimizer opt return opt opt sch sch build trainer object use amp true call trainer fit model see error environment cuda gpu geforce gtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp thu jun utc	2020-06-23 14:44:48	1592923488	resolved fixed	c275e1fc91df4d351799b633e9df08e010094bfe	1593091301	pytorch_lightning\trainer\optimizers.py                                                                    
87	2333	AttributeError: 'LightningDataParallel' object has no attribute 'teardown'	bug reproduce steps reproduce behavior trainer pytorch lightning trainer gpus distributed backend dp model basemodel load checkpoint trainer test model traceback recent call last file run kitti py line trainer test model file opt conda lib python3 site package pytorch lightning trainer trainer py line test self model teardown test file opt conda lib python3 site package torch nn module module py line getattr type self name name attributeerror lightningdataparallel object attribute teardown code sample expected behavior environment cuda gpu geforce gtx ti geforce gtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp thu jun utc additional context missing something attributeerror bug side	2020-06-23 20:59:22	1592945962	resolved fixed	d22181714ac3f201ea7a35b7fd06d85db82c0465	1593097817	pytorch_lightning\trainer\trainer.py                                                                    
88	2334	LightningModule.load_from_checkpoint not working with .ckpt from 0.7.6	bug trying use old experiment ckpt generated modelcheckpoint monitor val loss mode min result error trying load reproduce steps reproduce behavior train something save checkpoint checkpoint callback try load checkpoint trying load ckpts mnist ckpt pl version typeerror traceback recent call last selected ckpt glob o path join ckpts ckpt print f trying load selected ckpt pl version pl version litclassifier load checkpoint selected ckpt frame usr local lib python3 dist package pytorch lightning core saving py load checkpoint cl checkpoint path map location hparams file tag csv args kwargs checkpoint cl checkpoint hyper params key update kwargs model cl load model state checkpoint args kwargs return model usr local lib python3 dist package pytorch lightning core saving py load model state cl checkpoint args kwargs cl checkpoint hyper params type checkpoint model args checkpoint cl checkpoint hyper params type model args args name checkpoint get cl checkpoint hyper params name typeerror str object callable colab notebook reproducing issue maybe related change hparams recently happened local enviroment google colab enviroment able load checkpoint downgrading without problem expected behavior able use old ckpts environment pytorch version e g os e g linux ubuntu installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration relevant information also happened colab enviroment	2020-06-23 21:05:29	1592946329	resolved fixed	861a73be12ef17214bb0ed49aabc9f48a80fde16	1593379233	CHANGELOG.md pytorch_lightning\core\saving.py tests\models\test_hparams.py                                                                
89	2359	Problem with loading checkpoint of a model with embeddings	bug unable load checkpoint model embeddings code sample model arch class model pl lightningmodule def init self emb szs super init get base self enc nn sequential list child nn flatten nc list child feature self head nn sequential nn linear nc mish nn batchnorm1d nn dropout nn linear self embs nn modulelist nn embedding c c emb szs def forward self xb x cat x cont x1 e x cat e enumerate self embs x1 torch cat x1 x img self enc xb x torch cat x1 x cont unsqueeze x torch cat x x img return self head x checkpoint callback modelcheckpoint filepath o path join o getcwd model dir save top k true verbose true monitor val loss mode min prefix trainer trainer max epoch early stop callback early stopping gpus gradient clip val weight save path o getcwd checkpoint callback checkpoint callback num sanity val step training loop problem call trainer test runtime error arrises runtimeerror error loading state dict model unexpected key state dict embs weight embs weight embs weight embs weight expected behavior documentation used best checkpoint test loading checkpoint fails environment cuda gpu tesla p100 pcie available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp sat jun pdt	2020-06-25 11:45:38	1593085538	resolved fixed	51711c265a9e234f2b4164f1a2fab73373707d61	1593290283	.github\PULL_REQUEST_TEMPLATE.md CHANGELOG.md pytorch_lightning\core\saving.py pytorch_lightning\trainer\training_io.py tests\base\model_template.py tests\models\test_hparams.py tests\test_deprecated.py tests\trainer\test_lr_finder.py tests\trainer\test_optimizers.py                                                    
90	2371	hparams are not logged in tensorboard	bug using latest version pl problem launch experiment everything logged correctly tensorboard except hparams tried launch cpu template fresh virtual environement work however launch pytorch example logging hparams tensorboard worked reproduce succeeded reproduce using official mnist collab skipping simplest example excuting directly lightningmodule environment pytorch version e g os e g linux ubuntu installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration geforce gtx relevant information	2020-06-26 10:44:44	1593168284	resolved fixed	11069c87845ea9a14e6fe807094313a67f9946dc	1594139096	pytorch_lightning\core\decorators.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\base\deterministic_model.py tests\base\develop_pipelines.py tests\base\develop_utils.py tests\callbacks\test_early_stopping.py tests\loggers\test_all.py tests\loggers\test_base.py tests\loggers\test_tensorboard.py tests\models\test_amp.py tests\models\test_cpu.py tests\models\test_gpu.py tests\models\test_horovod.py tests\models\test_restore.py tests\models\test_test_loop.py tests\models\test_tpu.py tests\test_deprecated.py tests\trainer\test_dataloaders.py tests\trainer\test_trainer_steps.py tests\trainer\test_trainer_tricks.py                  
91	2372	training_epoch_end's outputs doesn't have 'loss' key	pytorch lightning build master traceback recent call last file main py line main hparams file main py line main trainer fit model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer trainer py line fit self ddp train task model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer training loop py line run training epoch self run training epoch end epoch output file mnt lustre maxiao1 anaconda3 lib python3 site package pytorch lightning trainer training loop py line run training epoch end epoch output model training epoch end epoch output file mnt lustre maxiao1 pvm model baseline py line training epoch end avg loss torch stack x loss x output mean file mnt lustre maxiao1 pvm model baseline py line avg loss torch stack x loss x output mean keyerror loss code def training step self batch batch idx return loss loss train acc acc def training epoch end self output avg loss torch stack x loss x output mean avg acc torch stack x train acc x output mean log loss avg loss train acc avg acc progress bar train loss avg loss train acc avg acc result log log progress bar progress bar return result	2020-06-26 13:35:38	1593178538	resolved fixed	a42a0e16ddd75dd7199ecefe4d10c2941c17ba76	1593525829	pytorch_lightning\trainer\training_loop.py tests\base\deterministic_model.py tests\trainer\test_trainer_steps.py                                                                
92	241	In Multi GPU DDP, pytorch-lightning creates several tfevents files	describe bug right pytorch lightning seems create several tfevent file multi gpu ddp way e g gpus rw rw r sam sam sep event tfevents google2 compute82 rw rw r sam sam sep event tfevents google2 compute82 rw rw r sam sam sep event tfevents google2 compute82 suppose first one created main process next created ddp process one per gpu unfortunately actual event logged last created one confuses tensorboard cf tensorflow tensorboard restart tensorboard want see new data clear concise description bug reproduce launch training multi gpu ddp expected behavior one tfevent file created master gpu	2019-09-21 16:05:45	1569081945	resolved fixed	614cb3c03bd0894238b3197f3b7f904656f284f4	1570029040	docs\Trainer\Logging.md pytorch_lightning\logging\mlflow_logger.py pytorch_lightning\logging\test_tube_logger.py pytorch_lightning\trainer\trainer.py tests\test_logging.py                                                            
93	2411	0.8.2 calls backward on '_GeneratorContextManager'	bug call backward generatorcontextmanager crash training work correctly training step return loss loss log learn rate self lr traceback recent call last file opt conda lib python3 site package torch multiprocessing spawn py line wrap fn args file opt conda lib python3 site package pytorch lightning trainer distrib data parallel py line ddp train self run pretrain routine model file opt conda lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file opt conda lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file opt conda lib python3 site package pytorch lightning trainer training loop py line run training epoch batch output self run training batch batch batch idx file opt conda lib python3 site package pytorch lightning trainer training loop py line run training batch self hiddens file opt conda lib python3 site package pytorch lightning trainer training loop py line optimizer closure model ref backward self closure loss optimizer opt idx file opt conda lib python3 site package pytorch lightning core hook py line backward loss backward attributeerror generatorcontextmanager object attribute backward expected behavior backward called loss training run correctly	2020-06-29 08:16:57	1593418617	resolved fixed	e8bb4165b76496089d24c74891f2167350e594be	1593543099	pytorch_lightning\trainer\training_loop.py                                                                    
94	2429	Batched iterative dataloading disables validation	bug setting batch size parameter torch utils data dataloader number greater prevents validation step validation epoch end called reproduce steps reproduce behavior run python main py b observe exception raised validation step run python main py changing b observe model train successfully code sample import pytorch lightning pl import torch import torch nn nn import torch nn functional f torch utils data import dataloader iterabledataset class dataset iterabledataset def init self super init def iter self range yield torch randn def len self return class model pl lightningmodule def init self super init self fst nn linear self snd nn linear def forward self x x self fst x x f relu x x self snd x return x def training step self batch batchidx x self forward batch return loss f mse loss x batch def validation step self batch batchidx raise notimplementederror x self forward batch return val loss f mse loss x batch def validation epoch end self output return val loss torch mean torch stack x val loss x output def configure optimizers self return torch optim adamw self parameter name main trainer pl trainer num sanity val step net model dataset dataset b trainer fit net train dataloader dataloader dataset batch size b val dataloaders dataloader dataset batch size b python main py b fail gpu available true used false tpu available false using tpu core name type params fst linear snd linear home constantin virtualenvs tensor lib64 python3 site package pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs home constantin virtualenvs tensor lib64 python3 site package pytorch lightning utility distributed py userwarning dataloader val dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs epoch loss v num expected behavior python main py b gpu available true used false tpu available false using tpu core name type params fst linear snd linear home constantin virtualenvs tensor lib64 python3 site package pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs home constantin virtualenvs tensor lib64 python3 site package pytorch lightning utility distributed py userwarning dataloader val dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs epoch traceback recent call last loss v num file main py line trainer fit net train dataloader dataloader dataset batch size b val dataloaders dataloader dataset batch size b file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer trainer py line fit self run pretrain routine model file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer training loop py line train self run training epoch file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer training loop py line run training epoch self run evaluation test mode self testing file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer evaluation loop py line run evaluation eval result self evaluate self model dataloaders max batch test mode file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer evaluation loop py line evaluate output self evaluation forward model batch batch idx dataloader idx test mode file home constantin virtualenvs tensor lib64 python3 site package pytorch lightning trainer evaluation loop py line evaluation forward output model validation step args file main py line validation step raise notimplementederror notimplementederror exception ignored traceback recent call last file home constantin virtualenvs tensor lib64 python3 site package tqdm std py line del file home constantin virtualenvs tensor lib64 python3 site package tqdm std py line close file home constantin virtualenvs tensor lib64 python3 site package tqdm std py line display file home constantin virtualenvs tensor lib64 python3 site package tqdm std py line repr file home constantin virtualenvs tensor lib64 python3 site package tqdm std py line format dict typeerror nonetype object iterable environment collecting environment information pytorch version cu101 debug build cuda used build pytorch os gentoo base system release gcc version gentoo p1 cmake version version python version cuda available yes cuda runtime version gpu model configuration gpu geforce gt nvidia driver version cudnn version opt cuda target x86 linux lib libcudnn versions relevant library pip3 numpy pip3 pytorch lightning pip3 torch cu101 pip3 torchvision cu101 conda could collect additional context basically reopen issue fixed changing batch size dataset size	2020-06-30 13:58:35	1593525515	resolved fixed	927f305f7e556828b5cdd45e3977c67f3c54b8fc	1593604399	CHANGELOG.md pytorch_lightning\trainer\data_loading.py requirements\base.txt tests\trainer\test_dataloaders.py                                                              
95	2436	Fix horovod tests that try to access filepath on global rank &gt; 0	bug skip two test namely test horovod cpu test horovod cpu implicit problem since run ddp test try access trainer internal variable checkpoint path get nonetype error trying o join none path reproduce steps reproduce behavior run two test test horovod cpu test horovod cpu implicit	2020-06-30 21:54:06	1593554046	resolved fixed	78db847e42457ce3dcd89a2a5eccc8e79f60e731	1594148047	tests\base\develop_pipelines.py tests\models\data\horovod\train_default_model.py tests\models\test_horovod.py                                                                
96	2438	`validation_epoch_end` and `test_epoch_end` can't return nothing	bug validation epoch end test epoch end return nothing presented option documentation error occurs happy work pr fix reproduce steps reproduce behavior overwrite test epoch end remove return validation epoch end file conda envs ppi env lib python3 site package pytorch lightning trainer logging py line process output k v output item attributeerror nonetype object attribute item code sample import o import torch torch nn import functional f torch utils data import dataloader torchvision datasets import mnist torchvision import transforms pytorch lightning core lightning import lightningmodule pytorch lightning import trainer seed everything class litmodel lightningmodule def init self super init self l1 torch nn linear def forward self x return torch relu self l1 x view x size def training step self batch batch idx x batch hat self x loss f cross entropy hat tensorboard log train loss loss return loss loss log tensorboard log def configure optimizers self return torch optim adam self parameter lr def train dataloader self dataset mnist o getcwd train true download true transform transforms totensor loader dataloader dataset batch size num worker shuffle true return loader def validation step self batch batch idx x batch hat self x return val loss f cross entropy hat def validation epoch end self output avg loss torch stack x val loss x output mean tensorboard log val loss avg loss return val loss avg loss log tensorboard log def val dataloader self todo real train val split dataset mnist o getcwd train false download true transform transforms totensor loader dataloader dataset batch size num worker return loader def main seed everything model litmodel basic trainer us good default trainer trainer fast dev run true trainer fit model name main main expected behavior check nothing returned carry environment cuda gpu available false version none packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os darwin architecture processor i386 python version darwin kernel version wed mar pst root xnu release x86 additional context	2020-07-01 00:46:26	1593564386	resolved fixed	325852c6df93f749bb843bff1a3cdba41698722c	1593603480	docs\source\bolts.rst docs\source\callbacks.rst docs\source\conf.py docs\source\hooks.rst docs\source\index.rst pytorch_lightning\core\lightning.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py                                                      
97	2442	validation_epoch_end needs to return CUDA tensors	bug sure expected behaviour upgrading latest version caused validation epoch end break appears cuda tensor expected metric tensor device agnostic using sklearn roc auc score yet got around testing pl new metric feel free close expected behaviour reproduce validation epoch end uncommenting avg loss device allows run dev version pl run ddp precision using apex amp def validation epoch end self output avg loss torch stack x val loss x output mean pred torch cat x pred squeeze x output cpu numpy true torch cat x true squeeze x output cpu numpy metric torch tensor roc auc score true pred avg loss device tensorboard log loss validation avg loss auc metric return val loss avg loss log tensorboard log auc metric error message seen comment code sample expected behavior environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py pytorch version e g os e g linux ubuntu installed pytorch conda pip source build command used compiling source python version cuda cudnn version gpu model configuration dual gpu ddp relevant information apex amp additional context	2020-07-01 06:56:52	1593586612	resolved fixed	a5538af3558cf544dffd92b1b8bab3a5793f0ba0	1595359137	CHANGELOG.md pytorch_lightning\core\lightning.py pytorch_lightning\metrics\metric.py pytorch_lightning\utilities\device_dtype_mixin.py tests\utilities\test_dtype_device_mixin.py                                                            
98	2444	self.hparam silently removes params that are not serializable	bug following approach found hyperparameters doc step passed dict parameter printing show content passed however function hparams gone might related param value yaml serializable therefore automatically removed removed params criterion torch nn bceloss optimizer partial optim adam lr reproduce steps reproduce behavior run following script functools import partial import torch import torch optim optim torch utils data import dataset import pytorch lightning pl pytorch lightning import trainer partial give params except data hparams criterion torch nn bceloss f cross entropy loss function optimizer partial optim adam lr lr learning rate filter layer class emptydataset dataset def init self transform none pas def len self return def getitem self idx return input np array output nothing class litlake pl lightningmodule def init self hparams dict transforms dict none super init self hparams hparams print self hparams n self hparams def forward self x pas def training step self batch batch idx lightning call inside training loop data training dataloader passed batch forward pas x batch hat self x loss self hparams criterion hat tensorboard log train loss loss return loss loss log tensorboard log def configure optimizers self print self hparams n self hparams optimizer self hparams optimizer self parameter scheduler optim lr scheduler cosineannealinglr optimizer max return optimizer scheduler def train dataloader self return dataloader emptydataset batch size num worker model litlake hparams hparams basic trainer us good default trainer trainer gpus num node trainer fit model keyerror optimizer see error script output click self hparams criterion bceloss filter layer optimizer functools partial lr gpu available true used false tpu available false using tpu core self hparams filter layer traceback recent call last file lightning hparams bug py line trainer fit model keyerror optimizer file home user anaconda3 envs onseilake lib python3 site package pytorch lightning trainer trainer py line fit self optimizers self lr scheduler self optimizer frequency self init optimizers model file home user anaconda3 envs onseilake lib python3 site package pytorch lightning trainer optimizers py line init optimizers optim conf model configure optimizers file lightning hparams bug py line configure optimizers optimizer self hparams optimizer self parameter keyerror optimizer code sample expected behavior either self hparams keeping non serializable parameter give problem loading throw error explaining param value acceptable approach instead silently removing environment pytorch version e g os e g linux ubuntu installed pytorch conda pip source conda build command used compiling source python version cuda cudnn version gpu model configuration geforce gtx ti relevant information additional context bug reproduced borda	2020-07-01 08:42:24	1593592944	resolved fixed	d5254ff9dfb67fba388de224a320f3a562561a80	1598598463	pytorch_lightning\utilities\__init__.py pytorch_lightning\utilities\parsing.py tests\models\test_hparams.py                                                                
99	2456	multi-gpu training triggers CUDA out of memory error	hi running issue going single multi gpu training specifically switch line pl trainer gpus precision distributed backend ddp pl trainer gpus precision distributed backend ddp get dreaded cuda memory error reason parallelism cause gpu receive data	2020-07-01 21:45:01	1593639901	resolved fixed	afdfba1dc6061c5e1ee6eaf215500d6a56e95482	1593687858	pytorch_lightning\trainer\evaluation_loop.py                                                                    
100	2458	Wandb Flatten Dict	wandb logger flatten dictionary parameter logging every logger bellow pattern code params self convert params params params self flatten dict params bug wandb logger flatten parameter resulting dictionary logged wandb searchable causing loss feature wandb reproduce run cpu template wandb logger log nested dictionary expected behavior solution call params self flatten dict params wandb logger environment cuda gpu available false version none packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os darwin architecture processor i386 python version darwin kernel version wed mar pst root xnu release x86	2020-07-02 01:43:12	1593654192	resolved fixed	899cd74044505eb308e624f15a4cb65c57973bbb	1594187125	CHANGELOG.md pytorch_lightning\loggers\wandb.py tests\loggers\test_wandb.py                                                                
101	2472	DDP breaks when `python` does not refer to the correct interpreter	bug using ddp distributed backend program break python refers python2 exist reproduce steps reproduce behavior make sure python command link python3 ubuntu run trainer fit distributed backed ddp additional context problem lie pytorch lightning pytorch lightning trainer distrib data parallel py line command python command python command hardcoded many system python symlink python2 exist	2020-07-02 16:27:39	1593707259	resolved fixed	fc61c200c085f78fa2af4850aa8dc8e832fb80d0	1593797010	CHANGELOG.md pytorch_lightning\trainer\distrib_data_parallel.py                                                                  
102	2476	Model and Input not on same GPU when training with native AMP and DP	bug training distributed backend dp precision result error input output model gpu reproduce pytorch lightning import trainer seed everything pl example model lightning template import lightningtemplatemodel seed everything def main model lightningtemplatemodel var args model lightningtemplatemodel trainer trainer gpus num node distributed backend dp precision trainer fit model name main main run example code result following error traceback recent call last file debug pytorch lightning py line main file debug pytorch lightning py line main trainer fit model file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning trainer trainer py line fit self dp train model file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning trainer distrib part py line dp train self run pretrain routine model file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning trainer trainer py line run pretrain routine false file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning trainer evaluation loop py line evaluate output self evaluation forward model batch batch idx dataloader idx test mode file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning trainer evaluation loop py line evaluation forward output model args file home ubuntu anaconda3 envs trfm lib python3 site package torch nn module module py line call impl result self forward input kwargs file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning override data parallel py line forward output self parallel apply replica input kwargs file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning override data parallel py line parallel apply return parallel apply replica input kwargs self device id len replica file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning override data parallel py line parallel apply raise output file home ubuntu anaconda3 envs trfm lib python3 site package pytorch lightning override data parallel py line worker output module validation step input kwargs file home ubuntu anaconda3 envs trfm lib python3 site package pl example model lightning template py line validation step val loss f cross entropy hat file home ubuntu anaconda3 envs trfm lib python3 site package torch nn functional py line cross entropy return nll loss log softmax input target weight none ignore index none reduction file home ubuntu anaconda3 envs trfm lib python3 site package torch nn functional py line nll loss ret torch c nn nll loss input target weight reduction get enum reduction ignore index runtimeerror assertion thctensor checkgpu state input target output total weight failed weight gradient input tensor located different gpus please move single one opt conda conda bld pytorch work aten src thcunn generic classnllcriterion cu expected behavior model train successfully gpus native pytorch amp environment cuda gpu tesla v100 sxm2 tesla v100 sxm2 tesla v100 sxm2 tesla v100 sxm2 available true version packages numpy pytorch debug false pytorch version dev20200702 pytorch lightning dev tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp mon jun utc additional context seems issue native amp apex amp	2020-07-02 23:51:29	1593733889	resolved fixed	031274c25dedc92e383d2715e283a55a2b102d29	1600834786	pl_examples\README.md pl_examples\__init__.py pl_examples\basic_examples\README.md pl_examples\basic_examples\autoencoder.py     pl_examples\basic_examples\image_classifier.py pl_examples\basic_examples\mnist.py     pl_examples\basic_examples\submit_ddp2_job.sh pl_examples\basic_examples\submit_ddp_job.sh pl_examples\domain_templates\semantic_segmentation.py pl_examples\domain_templates\unet.py     pytorch_lightning\accelerators\dp_backend.py pytorch_lightning\overrides\data_parallel.py pytorch_lightning\utilities\warning_utils.py tests\base\develop_utils.py tests\examples\__init__.py tests\examples\test_examples.py                          
103	2479	init_slurm_connection causing hostname errors	problem update function support checking master addr master port already o environ running weird error code add host master addr crash code pytorch lightning pytorch lightning core lightning py line def init slurm connection self none solution prefer pull request check put def init slurm connection self none sets environment variable necessary pytorch distributed communication based slurm environment master port o environ use slurm job id port number guarantee unique port across job grid search try use last number job id id default port o environ slurm job id default port default port port range default port int default port except exception default port user gave port number use one instead try default port o environ master port except exception o environ master port str default port figure root node addr master addr o environ try root node o environ slurm nodelist split except exception root node root node self trainer resolve root node address root node o environ master addr root node	2020-07-03 00:34:47	1593736487	resolved fixed	c6df63a58817b6414f8a3ae28edd9e6552be3914	1601861433	pytorch_lightning\trainer\__init__.py                                                                    
104	2480	For versions &gt;0.8.2 learning rate is zero for last epoch (potentially a logging bug)	bug version changed behavior either learning rate scheduler wandblogger logger using linear warmup decay scheduler however learning rate graph produced learningratelogger shown ever since version period learning rate zero corresponds last epoch training see graph raise another issue first epoch appears take twice many step second third epoch specified max epoch training epoch take amount time seems like logging issue note graph model training stopped early last epoch slightly shorter second last issue issue learning rate twice long epoch exist version graph look issue could caused logger might actually occur logged correctly looked changelog guessing bug caused changed epoch indexing instead also may relying fact epoch indexing started somewhere code believe case reproduce reproducing problem may difficult since provide script data used used wandblogger logger learningratelogger callback trained warmup step accumulate grad batch set provide additional code sample information may need code sample def lr lambda func current step num warmup step num training step current step num warmup step return float current step float max num warmup step return max float num training step current step float max num training step num warmup step total int len self train dataloader object self hparams max epoch self hparams accumulate grad batch lr lambda partial lr lambda func num warmup step self hparams warmup step self hparams accumulate grad batch num training step total scheduler lambdalr optimizer lr lambda scheduler dict scheduler scheduler interval step return optimizer scheduler dict expected behavior learning rate warmup decay version greater way version le epoch number step graph highlight expected behavior different model directly comparable shape expected since captured model trained pytorch lightning version environment cuda gpu tesla p100 pcie available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp wed feb pst	2020-07-03 04:08:46	1593749326	resolved fixed	992a7e2a414d052754f3579e173620baf740308a	1594293067	pytorch_lightning\trainer\training_tricks.py tests\trainer\test_lr_finder.py tests\trainer\test_trainer.py                                                                
105	2484	Trainer.scale_batch_size requires model.batch_size instead of model.hparams.batch_size	bug trainer scale batch size work model batch size property work model hparams batch size even though documentation point reverse reproduce hyperparameters available model hparams like suggested documentation hyperparameters option mean available fully compatible documented example code since code also us instead however put model trainer scale batch size get following error pytorch lightning utility exception misconfigurationexception field batch size found model hparams example code class litmodel pl lightningmodule def init self hparams super init self hparams args model litmodel args trainer trainer trainer scale batch size model expected behavior either work error message linked documentation example docstrings change e would prefer second option think work model batch size model hparams batch size environment pytorch lightning	2020-07-03 09:48:35	1593769715	resolved fixed	7b917de94642f63eedaffde79fb973705d2288dd	1597878115	CHANGELOG.md pytorch_lightning\trainer\training_tricks.py tests\trainer\test_trainer_tricks.py                                                                
106	249	UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars	describe bug sure bug show warning beginning training home adrian research envs research lib python3 site package torch nn parallel function py userwarning asked gather along dimension input tensor scalar instead unsqueeze return vector reproduce minimal mnist example doc problem trained multiple gpus attached python script import o import torch torch nn import functional f torch utils data import dataloader torchvision datasets import mnist import torchvision transforms transforms import pytorch lightning pl class coolmodel pl lightningmodule def init self super coolmodel self init best model self l1 torch nn linear def forward self x return torch relu self l1 x view x size def training step self batch batch nb required x batch hat self forward x return loss f cross entropy hat def validation step self batch batch nb optional x batch hat self forward x return val loss f cross entropy hat def validation end self output optional avg loss torch stack x val loss x output mean return avg val loss avg loss def test step self batch batch nb optional x batch hat self forward x return test loss f cross entropy hat def test end self output optional avg loss torch stack x test loss x output mean return avg test loss avg loss def configure optimizers self required return torch optim adam self parameter lr pl data loader def tng dataloader self return dataloader mnist o getcwd train true download true transform transforms totensor batch size pl data loader def val dataloader self optional also return list val dataloaders return dataloader mnist o getcwd train true download true transform transforms totensor batch size pl data loader def test dataloader self optional also return list test dataloaders return dataloader mnist o getcwd train false download true transform transforms totensor batch size name main pytorch lightning import trainer trainer trainer gpus distributed backend dp model coolmodel trainer fit model expected behavior scalar involved forward pas warning make sense shown desktop please complete following information os ubuntu version latest pip install	2019-09-25 13:11:17	1569417077	resolved fixed	8b2a2aeda3066fe30cc496a58368a523ef90ad9b	1569518454	pytorch_lightning\trainer\ignored_warnings.py pytorch_lightning\trainer\trainer.py                                                                  
107	2495	`precision=16` displaying wrong loss in progress bar	bug training gpu using native amp setting precision loss displayed progress bar crazy large number stopping example bellow middle epoch give loss train precision loss true value loss tensor ok add print statement training loop display normal value code sample import torch torch nn import functional f torch import nn pytorch lightning core lightning import lightningmodule pytorch lightning import trainer torch utils data import dataloader random split torchvision datasets import mnist import o torchvision import datasets transforms class litmnist lightningmodule def init self super init self layer torch nn linear self layer torch nn linear self layer torch nn linear def forward self x batch size channel width height x size x x view batch size x self layer x x torch relu x x self layer x x torch relu x x self layer x x torch log softmax x dim return x def train dataloader self transform transforms compose transforms totensor transforms normalize mnist train mnist o getcwd train true download false transform transform return dataloader mnist train batch size def configure optimizers self return torch optim adam self parameter lr def training step self batch batch idx x batch logits self x loss f nll loss logits add logging log loss loss return loss loss log log model litmnist trainer trainer gpus precision trainer fit model environment pytorch version v1 dev20200704 nightly os e g linux ubuntu installed pytorch conda pip source conda python version cuda cudnn version installed conda pytorch chanel gpu model configuration rtx super	2020-07-04 12:30:29	1593865829	resolved fixed	9924c76faa7789294811a27c392ba6b33e07f3f1	1593917569	pl_examples\models\lightning_template.py pytorch_lightning\core\hooks.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\training_loop.py tests\base\deterministic_model.py tests\trainer\test_trainer_steps.py                                                          
108	2498	TPU hangs when using only a train loop (ie: no val loop)	think somehow related checkpointing easiest way debug get colab	2020-07-04 14:25:36	1593872736	resolved fixed	0fe933e23d026fce6fd065f87e66c2637693e963	1595891229	.circleci\config.yml .github\workflows\ci-testing.yml .github\workflows\tpu-testing.yml CHANGELOG.md docs\source\new-project.rst pytorch_lightning\__init__.py pytorch_lightning\accelerator_backends\ddp_spawn_backend.py pytorch_lightning\accelerator_backends\gpu_backend.py pytorch_lightning\accelerator_backends\tpu_backend.py pytorch_lightning\core\__init__.py pytorch_lightning\core\decorators.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\base\datasets.py tests\base\develop_utils.py tests\base\test_datasets.py tests\models\test_grad_norm.py tests\models\test_tpu.py tests\trainer\test_trainer.py tests\trainer\test_trainer_test_loop.py                        
109	2531	IndexError with multiple validation loaders and fast_dev_run	bug indexerror using multiple validation datasets fast dev run true reproduce steps reproduce behavior use multiple val dataloaders use fast dev run true code sample traceback traceback recent call last file home luca repositories set operation src run experiment py line trainer fit model file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer trainer py line fit self single gpu train model file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer distrib part py line single gpu train self run pretrain routine model file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer training loop py line run training epoch self run evaluation test mode false file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer evaluation loop py line run evaluation eval result self evaluate self model dataloaders max batch test mode file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package pytorch lightning trainer evaluation loop py line evaluate dl max batch max batch dataloader idx indexerror list index range exception ignored traceback recent call last file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package tqdm std py line del file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package tqdm std py line close file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package tqdm std py line display file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package tqdm std py line repr file home luca cache pypoetry virtualenvs set operation gbjoltq2 py3 lib python3 site package tqdm std py line format dict typeerror unpack non iterable nonetype object process finished exit code reason fast dev run true max batch set pytorch lightning pytorch lightning trainer evaluation loop py lines afdfba1 self fast dev run max batch thus later pas test remains stuck pytorch lightning pytorch lightning trainer evaluation loop py lines afdfba1 isinstance max batch int max batch max batch len dataloaders loop iterates dataloaders causing indexerror line second iteration pytorch lightning pytorch lightning trainer evaluation loop py lines afdfba1 dataloader idx dataloader enumerate dataloaders dl output tpu wrap parallelloader self use tpu device xm xla device self tpu id dataloader xla pl parallelloader dataloader device dataloader dataloader per device loader device dataloader max num batch dl max batch max batch dataloader idx possible solution let fast dev run true use validation loader modify evaluation loop use first val loader environment cuda gpu available false version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp wed feb pst	2020-07-06 17:15:51	1594055751	resolved fixed	84c507c4df5f5c336deb19ce7f70fa02329f39f6	1595887015	CHANGELOG.md pytorch_lightning\callbacks\progress.py pytorch_lightning\trainer\__init__.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py pytorch_lightning\utilities\debugging.py tests\callbacks\test_progress_bar.py tests\models\test_grad_norm.py tests\trainer\test_dataloaders.py                                                  
110	2532	TypeError with multiple validation loaders and overfit_batches	bug typeerror using multiple validation datasets overfit batch reproduce steps reproduce behavior use multiple val dataloaders use overfit batch e g overfit batch code sample traceback typeerror traceback recent call last trainer pl trainer overfit batch trainer fit model frame usr local lib python3 dist package pytorch lightning trainer trainer py fit self model train dataloader val dataloaders self optimizers self lr scheduler self optimizer frequency self init optimizers model self run pretrain routine model callback usr local lib python3 dist package pytorch lightning trainer trainer py run pretrain routine self model self val dataloaders max batch false allow return eval usr local lib python3 dist package pytorch lightning trainer evaluation loop py evaluate self model dataloaders max batch test mode output self evaluation forward model batch batch idx dataloader idx test mode else output self evaluation forward model batch batch idx dataloader idx test mode dp ddp2 might still want something batch part usr local lib python3 dist package pytorch lightning trainer evaluation loop py evaluation forward self model batch batch idx dataloader idx test mode output model test step args else output model validation step args return output typeerror validation step missing required positional argument dataloader idx expected behavior codebase working multiple validation loader continue work even using overfit batch possible solution check multiple val dataloaders case call validation step dataloader idx repeat train loader match number val dataloaders add possibility overfit train validate test normally already possible limit train batch would doc change multiple val dataloaders use limit train batch instead overfit batch reason using multiple validation loader validation step take dataloader idx however later set overfit batch something line executed use train loader instead validation loader pytorch lightning pytorch lightning trainer data loading py lines a91b06e use training loader val test overfitting self overfit batch dataloaders self request dataloader getattr model train dataloader else dataloaders self request dataloader getattr model f mode dataloader one validation loader thus validation step function dataloader idx parameter break environment cuda gpu available false version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp wed feb pst	2020-07-06 18:01:39	1594058499	resolved fixed	d787208e768085b608198f3e0313e2be28d4cbfe	1601868302	pytorch_lightning\trainer\data_loading.py tests\trainer\flags\test_overfit_batches.py                                                                  
111	2539	TPU fp16 requires apex installed	tried use precision tpu pytorch lightning trying find amp unnecessary backtrace gpu available false used false tpu available true using tpu core traceback recent call last file bert ner light fp16 debug py line trainer pl trainer tpu core precision file anaconda3 envs torch xla lib python3 site package pytorch lightning trainer trainer py line init self init amp file anaconda3 envs torch xla lib python3 site package pytorch lightning trainer auto mix precision py line init amp set use amp true apex installed modulenotfounderror set use amp true apex installed install apex first using guide rerun use amp true run use bit precision reproduce steps reproduce behavior build whatever trainer tpu use fp16 code sample import pytorch lightning pl trainer pl trainer tpu core precision expected behavior nothing error environment pytorch version e g os e g linux linux installed pytorch conda pip source conda build command used compiling source python version cuda cudnn version gpu model configuration relevant information actually directly use pytorch xla docker google cloud additional context	2020-07-07 11:30:39	1594121439	resolved fixed	e068af9ea8c86df8ed5eb20e57a36fbb38c70462	1594344491	pytorch_lightning\core\memory.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\trainer\training_loop.py                                                          
112	2551	TrainerEvaluationLoopMixin activates model.train() at the end	bug according example fine tuning important set frozen sub module eval mode sensitive training mode batchnorm dropout change state however end trainerevaluationloopmixin evaluate following code enable train mode model train first validation run model completely training mode freezing partially undone layer like batchnorm dropout	2020-07-08 10:57:09	1594205829	resolved fixed	f58c7604093fc37c765ac88e46aaf52b403332fe	1601866955	pytorch_lightning\core\hooks.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py tests\trainer\model_hooks\__init__.py tests\trainer\model_hooks\test_model_hooks.py                                                            
113	2555	apex amp state dict	bug pytorch lightning pytorch lightning trainer training io py line self use amp native amp avalaible native amp scaling state checkpoint seems native amp support scalar state dict saved non native amp amp state dict saved	2020-07-08 21:13:02	1594242782	resolved fixed	bef27c58eda4c4425c8aa750d38e16522bfcbe39	1596649430	pytorch_lightning\trainer\training_io.py                                                                    
114	2574	horovod mode increase lr	really bug horovod mode learning rate automatically increased hvd size behavior different ddp may confuse user	2020-07-10 04:36:46	1594355806	resolved fixed	1369012bc71f257dcf7423ec65146d055ddc1cc7	1595520897	CHANGELOG.md pytorch_lightning\trainer\distrib_parts.py tests\models\test_horovod.py                                                                
115	2600	Trainer flag overfit_batches does not overwrite train dataloaders shuffle flag	bug setting trainer flag overfit batch e g overwrite shuffle flag set training dataloader even though warning read userwarning requested overfit enabled training dataloader shuffling turning reproduce steps reproduce behavior create lightning module method train dataloader flag shuffle true def train dataloader self loading dataloader dataset prostatex train true batch transforms gpu transforms sample transforms self get transformation dataloader loading dataloader dataset batch size self hparams tr batch size batch transforms batch transforms shuffle true sample transforms sample transforms gpu transforms gpu transforms pseudo batch dim true num worker self hparams num worker return dataloader use rising dataloader bug also occur pytorch dataloaders though create main py mymodel model model3d cfg trainer pl trainer gpus precision overfit batch trainer fit mymodel run main py find model converge set shuffle false creating dataloader train dataloader see model converges epoch log sample loaded dataloader check epoch code sample expected behavior either model also converges shuffle true since warning say got overwritten assuming model converges shuffle false least warning read user change shuffle false environment cuda gpu geforce gtx ti available true version packages numpy pytorch debug false pytorch version dev20200705 cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp fri jun utc additional context	2020-07-13 13:26:48	1594646808	resolved fixed	b5dc6998ae80b026bb6adc4040980a153390307a	1600160847	CHANGELOG.md pytorch_lightning\trainer\data_loading.py tests\trainer\test_trainer_tricks.py                                                                
116	2622	set_epoch isn't called for TPU training	bug line call training tpus unless using false	2020-07-16 18:35:39	1594924539	resolved fixed	2cc60c625ed6593aea01d237fa047ad1863dc79c	1596807090	pytorch_lightning\trainer\training_loop.py                                                                    
117	2635	Loss value in the progress bar is wrong when `accumulate_grad_batches &gt; 1`	bug loss value reported progress bar correct loss value accumulate grad batch value wrong accumulate grad batch happening loss divided running loss loss fix either remove first line division accumulate grad batch replace mean sum second line reproduce train model accumulate grad batch note loss value reported progress bar train model accumulate grad batch half batch size loss value progress bar half value step expected behaviour loss step environment pytorch lightning v0	2020-07-17 19:38:29	1595014709	resolved fixed	c047676fae8cdbfe77189c218cfde73d863acc91	1595968186	pytorch_lightning\trainer\training_loop.py                                                                    
118	2636	nan metric breaking ModelCheckpoint	bug comparing number float nan false python result non loss metric score nan initially training callback checkpoint score expected behavior ignore nan metric score orthogonal grad weight become nan environment pytorch version e g os e g linux linux installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration tesla v100 additional context previous issue addressed completely	2020-07-17 20:49:57	1595018997	resolved fixed	6ac0958166c66ed599c96737b587232b7a33d89e	1601897772	pytorch_lightning\callbacks\model_checkpoint.py tests\checkpointing\test_model_checkpoint.py                                                                  
119	2637	to() got an unexpected keyword argument 'non_blocking' for DGLGraph	bug reproduce use dgl library make gnn batch dglgraph problem training test got typeerror got unexpected keyword argument non blocking function keyword argument non blocking code sample expected behavior environment os linux cuda python version pytorch version dgl version pytorch lightning version additional context file src main py line run params file src main py line run trainer test model file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer trainer py line test result self test given model model test dataloaders file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer trainer py line test given model result self fit model file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer trainer py line fit result self single gpu train model file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer distrib part py line single gpu train result self run pretrain routine model file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer trainer py line run pretrain routine result self run evaluation test mode true file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer evaluation loop py line run evaluation eval result self evaluate self model dataloaders max batch test mode file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer evaluation loop py line evaluate output self evaluation forward model batch batch idx dataloader idx test mode file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer evaluation loop py line evaluation forward batch self transfer batch gpu batch root gpu file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer distrib part py line transfer batch gpu return self transfer batch device batch device file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning trainer distrib part py line transfer batch device return model transfer batch device batch device file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning core hook py line transfer batch device return move data device batch device file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning utility apply func py line move data device return apply collection batch dtype transferabledatatype batch function batch file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning utility apply func py line apply collection k v data item file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning utility apply func py line k v data item file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning utility apply func py line apply collection return function data args kwargs file home jiangyize miniconda3 envs galixir lib python3 site package pytorch lightning utility apply func py line batch return data device non blocking true typeerror got unexpected keyword argument non blocking	2020-07-18 09:57:26	1595066246	resolved fixed	69d241c82e10cf40e5787fb39bb808687d693b57	1597188517	CHANGELOG.md pytorch_lightning\core\hooks.py pytorch_lightning\utilities\apply_func.py tests\models\test_gpu.py                                                              
120	2653	Checkpoints cannot be loaded in non-pl env	feature add option save state dict modelcheckpoint callback bug pl checkpoint loaded non pl envs motivation able move trained model weight pytorch environment additional context currently torch load pl generated checkpoint environment without pl pickling error current use case load checkpoint training environment save state dict weight see reply info	2020-07-21 01:30:04	1595295004	resolved fixed	65e6687c54937db0f9bdbdb089ac9d288457d6f8	1599053802	pytorch_lightning\trainer\training_io.py                                                                    
121	2669	--gpus flag with add_argparse_args bug	bug using parser trainer add argparse args parser args parser parse args trainer trainer argparse args args user provide gpus flag code allocates memory gpu report gpu available true used true use gpu issue discovered bolt pytorchlightning pytorch lightning bolt pytorchlightning pytorch lightning bolt reproduce steps reproduce behavior use following method create trainer object parser trainer add argparse args parser args parser parse args trainer trainer argparse args args pas gpus flag expected behavior gpus flag provided script call lightning report gpu available true used false warning allocate memory gpu way user set gpus flag missed	2020-07-22 09:29:05	1595410145	resolved fixed	6780214b27e6ebace9cf38b6f5701224204e28ad	1595579165	pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\trainer.py                                                                  
122	2678	training_epoch_end seems to fail when returning nothing	trying log weight histogram tensorboard end training epoch following code def training epoch end self output self log hists line documentation need display anything return anything however function run get following error file venv lib python3 site package pytorch lightning trainer training loop py line run training epoch self run training epoch end epoch output file venv lib python3 site package pytorch lightning trainer training loop py line run training epoch end processed output self process output epoch output file venv lib python3 site package pytorch lightning trainer logging py line process output k v output item attributeerror nonetype object attribute item exception ignored traceback recent call last file venv lib python3 site package tqdm std py line del file venv lib python3 site package tqdm std py line close file venv lib python3 site package tqdm std py line display file venv lib python3 site package tqdm std py line repr file venv lib python3 site package tqdm std py line format dict typeerror nonetype object iterable fix found return dictionary according expected typed return follows def training epoch end self output self log hists return dummy torch tensor seems like bandaid rather true fix since need return anything better way log histogram tensorboard something different function	2020-07-23 12:44:45	1595508285	resolved fixed	b014223f72ee457285fa3eb336d1d4039cedb651	1601897626	pytorch_lightning\trainer\training_loop.py tests\trainer\data_flow\test_train_loop_flow_scalar_1_0.py                                                                  
123	2680	Checkpoint saving order	last model save action saving top k model best model best score could changed swapping order allows resuming training last checkpoint last checkpoint latest information best model path score	2020-07-23 19:39:33	1595533173	resolved fixed	f798cffd02a0b6cbdc3033c981501c1a0c4677bd	1596880963	CHANGELOG.md pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\training_io.py tests\callbacks\test_model_checkpoint.py                                                              
124	2688	Training on GPU failed with Torchtext when using include_lengths=True in torchtext.data.Field	bug issue raise pytorch lightning utility apply func py assumes attribute batch trochtext tensors however torchtext data field configured include length tensor include length true field tuple bugfix prepared pr submitted soon reproduce steps reproduce behavior use torchtext field include length true gpu machine fit model training work cpu fails gpu typeerror unpack non iterable nonetype object full error message traceback recent call last file debug torchtext py line trainer fit model file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer trainer py line fit result self single gpu train model file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer distrib part py line single gpu train result self run pretrain routine model file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer training loop py line run training epoch batch output self run training batch batch batch idx file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer training loop py line run training batch self hiddens file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer training loop py line optimizer closure hiddens file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer training loop py line training forward batch self transfer batch gpu batch gpu id file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer distrib part py line transfer batch gpu return self transfer batch device batch device file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning trainer distrib part py line transfer batch device return model transfer batch device batch device file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning core hook py line transfer batch device return move data device batch device file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning utility apply func py line move data device return apply collection batch dtype transferabledatatype batch function batch file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning utility apply func py line apply collection return function data args kwargs file home1 thschaaf miniconda3 envs p37 lib python3 site package pytorch lightning utility apply func py line batch device field getattr data field device non blocking true attributeerror tuple object attribute exception ignored traceback recent call last file home1 thschaaf miniconda3 envs p37 lib python3 site package tqdm std py line del file home1 thschaaf miniconda3 envs p37 lib python3 site package tqdm std py line close file home1 thschaaf miniconda3 envs p37 lib python3 site package tqdm std py line display file home1 thschaaf miniconda3 envs p37 lib python3 site package tqdm std py line repr file home1 thschaaf miniconda3 envs p37 lib python3 site package tqdm std py line format dict typeerror unpack non iterable nonetype object code sample import torch torch import nn tensor import pytorch lightning pl pytorch lightning import trainer seed everything torchtext import data seed everything def get debug data loader text field data field sequential true pad first false init token eos token include length true example1 data example example fromdict text b c c text text text field example2 data example example fromdict text b c text text text field example3 data example example fromdict text c b text text text field dataset data dataset example1 example2 example3 text text field text field build vocab dataset iterator data iterator dataset batch size sort key none device none batch size fn none train true repeat false shuffle none sort none sort within batch none return iterator text field class debugmodel pl lightningmodule def init self super debugmodel self init setup data loader self debug data loader self text field get debug data loader self learning rate self hid dim pad idx self text field vocab stoi self criterion nn crossentropyloss ignore index pad idx self input dim len self text field vocab self enc emb dim keep small debugging self embedding nn embedding self input dim self enc emb dim self rnn nn gru self enc emb dim self hid dim bidirectional false self nn linear self hid dim self embedding num embeddings self output dim len self text field vocab def configure optimizers self return torch optim adam self parameter lr self learning rate def forward self input seq length embedded tensor self embedding input seq packed embedded tensor torch nn utils rnn pack padded sequence embedded length batch first false enforce sorted false packed output hidden self rnn packed embedded sent len batch size emb dim output length torch nn utils rnn pad packed sequence packed output output sent len batch size hid dim n direction hidden n layer n direction batch size hid dim output output squeeze prediction self output return prediction staticmethod def parse batch batch source batch text source length batch text return source source length def training step self batch batch nb x self parse batch batch target target length x output self forward target target length loss self criterion output view output shape target view prefix train tensorboard log f prefix loss loss item result loss loss log tensorboard log return result def train dataloader self return self debug data loader model debugmodel cuda device cnt torch cuda device count cuda device cnt use num cuda device else use num cuda device none trainer trainer fast dev run false max step none gradient clip val weight summary full gpus use num cuda device show progress bar true trainer fit model expected behavior raise error environment cuda gpu titan x pascal available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp tue mar utc additional context	2020-07-24 19:28:26	1595618906	resolved fixed	a6719f09f0a383034f4285d65cba880208a03ae4	1596196388	CHANGELOG.md pytorch_lightning\utilities\apply_func.py tests\utilities\test_apply_func_torchtext.py                                                                
125	2691	Subprocess launched in ddp have the wrong cwd when using hydra.	bug details comment talked omry issue send fix soon reproduce please see comment posted expected behavior cwd subprocesses parent relative path work	2020-07-24 20:00:08	1595620808	resolved fixed	b7f613ba6da32941bc86e9188629b572b10db4ad	1595968408	pytorch_lightning\trainer\distrib_data_parallel.py                                                                    
126	272	Trainer track_grad_norm always results in 0	describe bug trainer flag track grad norm allows u log gradient norm tensorboard flag checked run tng epoch function training step validation step however training step run tng batch call model optimizer step default implementation call optimizer zero grad result tracked gradient norm always zero moreover optional run evaluation call validatin step result call model zero grad assume also result zero gradient norm reproduce steps reproduce behavior train model track grad norm flag set true tensorboard logging enabled go tensorboard check gradient norm expected behavior gradient norm always zero desktop please complete following information os windows version	2019-10-01 08:19:47	1569917987	resolved fixed	41236c7bbbe2a22714c19b625bdf557854d747e8	1570029068	pytorch_lightning\trainer\trainer.py                                                                    
127	2724	Issues with Confusion Matrix normalization and DDP computation	bug started using confusionmatrix metric compute normalized confusion matrix within mult gpu ddp environment however found following issue normalization divisor computed correctly row wise manner however division applied column wise normalization protect divide zero data particular row usual case well designed validation set possible large number unbalanced class limit val batch small debugging way specify number class confusion matrix critical performing ddp reduction possible automatic computation number class could produce different answer process encountered possibility using large number unbalanced class one ddp process see true data declaration last class causing number class one le process bug sometimes cause entire training process hang needed manually kill ddp process computing normalized confusion matrix ddp reduction sum reduction need happen prior normalization reproduce mean reproduce issue attached two python script change extension txt would upload github script confusion matrix py expose first two issue normalization within single process script confusion matrix ddp py expose final two issue computing metric within model trained using ddp two gpus script create class problem sample unevenly divided among class true confusion matrix computed within script printed standard along confusion matrix computed pytorch lightning confusion matrix py txt confusion matrix ddp py txt steps reproduce behavior download script rename remove txt extension confusion matrix py machine least gpu compare true test confusion matrix confusion matrix ddp py machine least gpus computes unnormalized confusion matrix compare true test confusion matrix warning may hang process require manually kill process confusion matrix ddp py normalize machine least gpus computes normalized confusion matrix compare true test confusion matrix warning may hang process require manually kill process expected behavior computed confusion matrix identical true confusion matrix printed within script provided environment pytorch version e g py3 cuda10 cudnn7 os e g linux centos installed pytorch conda pip source conda build command used compiling source na python version cuda cudnn version conda cudatoolkit hfd86e86 gpu model configuration geforce gtx geforce gtx solution forked pytorch lightning created fix issue willing turn pull request solution first two issue require major change third issue required addition new argument confusionmatrix number class optional final argument api backwards compatible fourth issue involved required modifying confusionmatrix derive metric rather tensormetric us internal class drive tensormetric manner forward delegate computation unnormalized confusion matrix ddp reduction internal class performing normalization ddp reduction complete incrementally fixed issue easier understanding issues issue issue e3e0743 validate solution confusion matrix py machine least gpu compare true test confusion matrix confusion matrix ddp py set num class machine least gpus compare true test confusion matrix confusion matrix ddp py set num class normalize machine least gpus compare true test confusion matrix note addition set num class ddp script	2020-07-27 14:32:27	1595860347	resolved fixed	a552d4a2d5056705c68f2eed570a83ee3160b3bc	1600070751	pytorch_lightning\metrics\functional\classification.py tests\metrics\functional\test_classification.py tests\metrics\test_classification.py                                                                
128	2742	[DataModule] `prepare_data()` and `setup()` not called	bug seems using datamodule separate training logic data loading five method called last three actually used witch problematic since datasets used data loader assigned reproduce steps reproduce behavior run code sample import torch pytorch lightning import lightningdatamodule pytorch lightning core lightning import lightningmodule pytorch lightning trainer import trainer torch nn import l1loss linear torch optim import sgd torch utils data import dataloader class mydatamodule lightningdatamodule def init self super init def prepare data self print prepare data called train dataloader def setup self stage print setup called train dataloader self train dataset whatever def train dataloader self print train dataloader return dataloader self train dataset class mylightningmodule lightningmodule def init self super init self layer linear self loss function l1loss def forward self x return self layer x def configure optimizers self return sgd self parameter lr def training step self batch batch idx print even get raise notimplementederror data module mydatamodule model mylightningmodule trainer trainer gpus trainer fit model data module give attributeerror mydatamodule object attribute train dataset expected behavior entering train dataloader prepare data setup already executed thus train dataset attribute exist additional context imho come environment cuda gpu geforce rtx ti geforce rtx ti available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp tue dec utc	2020-07-28 15:54:40	1595951680	resolved fixed	036bcea4992865e8a82a5939f0d374530e17b778	1596327477	docs\source\datamodules.rst pytorch_lightning\accelerator_backends\cpu_backend.py pytorch_lightning\accelerator_backends\ddp_spawn_backend.py pytorch_lightning\accelerator_backends\dp_backend.py pytorch_lightning\accelerator_backends\gpu_backend.py pytorch_lightning\accelerator_backends\tpu_backend.py pytorch_lightning\core\datamodule.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\trainer.py tests\base\datamodules.py tests\core\test_datamodules.py                                              
129	2769	Bug in `LightningModule.load_from_checkpoint`	suppose class model lightningmodule lightningmodule subclass parameter take params argparse namespace without default value along keyword argument might take default argument loading checkpoint model model params params kwargs save checkpoint model model load checkpoint params params kwargs behavior arises params passed positional argument throw error typeerror init got multiple value argument params come fact line pytorch lightning core saving py model cl cl args cl kwargs inspected cl args params params cl kwargs course params params stem fact line saving py args name kwargs case class take extra argument filter possible cl kwargs update model args elif args name args name cl init args name cl kwargs update args name model args else cl args model args cl args else clause getting called model args contains copy kwargs honest unclear exactly model args supposed clear block need checking stick copy item cl kwargs cl args something silly like replacing else clause typing import sequence elif isinstance model args sequence cl args tuple model args cl args fix problem said unclear exactly model args used sure better solution	2020-07-30 22:03:12	1596146592	resolved fixed	cea5f1f53876399dfaa0d37accdc527af7ca39af	1601916263	pytorch_lightning\core\saving.py tests\base\model_template.py tests\models\test_hparams.py tests\models\test_restore.py                                                              
130	2782	Use of shell=True could lead to shell injection	file pytorch lightning trainer training io py line number relevant code find job id job id o environ slurm job id cmd scontrol requeue format job id requeue job log info f requeing job job id result call cmd shell true executing shell command incorporate unsanitized input untrusted source make program vulnerable shell injection serious security flaw result arbitrary command execution reason use shell true strongly discouraged case command string constructed external input shell false disables shell based feature suffer vulnerability meaning anything set slurm job id environment variable perform code execution documentation also describes might need want shell true useful using python primarily enhanced control flow offer system shell still want convenient access shell feature shell pipe filename wildcards environment variable expansion expansion user home directory looking code look like need feature switch shell false change functionality gaining security benefit shell false	2020-07-31 17:56:06	1596218166	resolved fixed	96eb6ebacd5b8bba2dea4741355f576e8f1c6a16	1596338757	pytorch_lightning\trainer\training_io.py                                                                    
131	2844	Tensorboard logger fails to save model OmegaConf hparams	bug tensorboard logger fails log module hyperparameters configured omegaconf happens updating logger hparams trainer call logger log hyperparams inside log hyperparams logger hparams updated cause hparams type dict instead dictconfig result branch save hparams yaml never triggered stacktrace logging hyperparams reproduce code sample hacky fix would something like changing hparams update use inside tensorboard logger isinstance params container self hparams omegaconf merge self hparams params else self hparams update params expected behavior environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py pytorch version e g os e g linux installed pytorch conda pip source build command used compiling source python version cuda cudnn version gpu model configuration relevant information additional context	2020-08-06 01:26:00	1596677160	resolved fixed	b39f4798a6859d2237b48b29b39a2390164612c1	1596806001	CHANGELOG.md pytorch_lightning\core\saving.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\trainer\training_io.py tests\loggers\test_tensorboard.py                                                            
132	2859	Failing docker-Conda build	bug seems connection issue creating conda env reproduce additional context	2020-08-07 10:17:24	1596795444	resolved fixed	ad956b5ed9add7e601dfbe57e96ea586305127d0	1596802462	.github\workflows\docker-builds.yml                                                                    
133	286	Double check that fast_dev_run works correctly	run single validation training batch cover full loop suggested adefazio	2019-10-02 16:53:38	1570035218	resolved fixed	608a90a490798a743410768a832309fe40b6ab7b	1570630988	pytorch_lightning\trainer\trainer.py                                                                    
134	2862	"Metrics error due to inplace operation, ""computation has been modified by an inplace operation""."	hey williamfalcon got new error since upgraded library today used accuracy metric got error code sample lightning module def training step self batch batch idx x batch hat self x loss f cross entropy hat acc accuracy hat functional metric classification tensorboard log train loss loss return loss loss log tensorboard log error msg runtimeerror one variable needed gradient computation modified inplace operation torch cuda longtensor version expected version instead hint enable anomaly detection find operation failed compute gradient torch autograd set detect anomaly true solved using clone method however clone feeding accuracy function error shown acc accuracy hat clone inconvenience user manually actually use code without clone upgrade latest might due latest update rebase causing error error shown f1 score metric	2020-08-07 12:37:41	1596803861	resolved fixed	d9d7e91a3b68fb7bbb966c73745a932ea95a2e6b	1596880898	pytorch_lightning\metrics\functional\classification.py                                                                    
135	2868	Throw warning for changing val_loss	add warning user changing val loss another keyword break checkpointing early stopping feature relying	2020-08-07 17:53:24	1596822804	resolved fixed	51de6802edd6c050ba3f2803724298eb059dc5ad	1597674568	pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\core\step_result.py tests\trainer\test_trainer_steps_result_return.py                                                              
136	2891	The total number of batches shows by the progress bar of the sanity check is wrong	bug total sanity check progress bar set pytorch lightning pytorch lightning callback progress py line self val progress bar total convert inf trainer num sanity val step len trainer val dataloaders progress bar always show trainer num sanity val step even length validation dataloader le trainer num sanity val step maybe total could computed pytorch lightning trainer import data loading num full val dataloader batch len dataloader data loading len dataloader else float inf dataloader trainer val dataloaders self val progress bar total convert inf sum min num batch trainer num sanity val step num batch num full val dataloader batch use private function data loading len check dataloader len maybe could make data loading len public could make num full val dataloader batch num full train dataloader batch member variable trainer update value pytorch lightning trainer data loading trainerdataloadingmixin reproduce progress bar sanity check following code num sanity val step len val data loader show validation sanity check code sample import time import pytorch lightning pl torch utils import data class dataset data dataset def init self length self element list range length def getitem self item return self element item def len self return len self element class model pl lightningmodule def forward self args kwargs pas def training step self args kwargs pas def train dataloader self pas def configure optimizers self pas def validation step self args kwargs time sleep return pl evalresult name main model model val dataset length val dataset dataset val dataset length val data loader data dataloader val dataset trainer pl trainer num sanity val step limit val batch max epoch trainer fit model val dataloaders val data loader expected behavior program validation sanity check environment cuda gpu available version packages numpy pytorch debug false pytorch version cpu pytorch lightning tensorboard tqdm system os windows architecture windowspe processor python version additional context	2020-08-09 04:52:31	1596948751	resolved fixed	a628d181ee662a77b708a12c51477f912ce02f63	1601814738	CHANGELOG.md pytorch_lightning\callbacks\progress.py tests\callbacks\test_progress_bar.py tests\trainer\test_trainer.py                                                              
137	2916	ModelCheckpoint with custom filepath don't support training on multiple nodes	bug training multiple node using custom raise caused following line code model checkpoint py l127 maybe try except block needed	2020-08-11 15:41:05	1597160465	resolved fixed	56396abe9839fa075bcc087c32f098145b0bdc9f	1597228277	pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\utilities\cloud_io.py                                                            
138	2936	"Trainer ""optimizers"" attribute is None when saving checkpoint and callbacks list is not empty"	bug training gan running custom callback well model attempt save end first epoch crash strange thing exact code jupyter notebook error occur reproduce steps reproduce behavior bug occur callback list passed trainer empty none callback using anything saving checkpoint logging certain thing model enabling one cause error running exact code jupyter result crash stack trace traceback recent call last loss v num loss g loss file mnist dense gan convergence py line main args file mnist dense gan convergence py line main trainer fit gan file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer trainer py line fit result self run pretrain routine model file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training loop py line run training epoch self check checkpoint callback check val file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training loop py line check checkpoint callback c validation end self self get model c checkpoint callback file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training loop py line c validation end self self get model c checkpoint callback file users robbie conda envs ganresearch lib python3 site package pytorch lightning utility distributed py line wrapped fn return fn args kwargs file users robbie conda envs ganresearch lib python3 site package pytorch lightning callback model checkpoint py line validation end self check save filepath current epoch file users robbie conda envs ganresearch lib python3 site package pytorch lightning callback model checkpoint py line check save self save model filepath file users robbie conda envs ganresearch lib python3 site package pytorch lightning callback model checkpoint py line save model self save function filepath self save weight file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training io py line save checkpoint checkpoint self dump checkpoint weight file users robbie conda envs ganresearch lib python3 site package pytorch lightning trainer training io py line dump checkpoint optimizer enumerate self optimizers typeerror nonetype object iterable code sample relevant part setup code inception callback ganinceptionscorer classifier logits true sample size input shape log dir o path abspath log mnist dense gan convergence params parametermatrixcallback callback ganprogressbar gantensorboardimageview params inception callback trainer args max epoch default root dir log dir callback callback progress bar refresh rate print log dir try trainer trainer gpus trainer args except misconfigurationexception trainer trainer trainer args trainer fit gan expected behavior environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py code jupyter inception callback ganinceptionscorer classifier logits true sample size input shape log dir o path abspath log mnist gan dense params parametermatrixcallback trainer args max epoch callback ganprogressbar gantensorboardimageview n params inception callback progress bar refresh rate default root dir log dir trainer trainer args pytorch version e g os e g linux macos installed pytorch conda pip source conda python version relevant information pytorch lightning	2020-08-12 18:38:40	1597257520	resolved fixed	cb2a3265e5eb329a48fb44df6ab8fd74df62b85a	1601954152	tests\trainer\test_optimizers.py                                                                    
139	2943	Issue with pl.Trainer.from_argparse_args(...)	bug reproduce steps reproduce behavior use parser pl trainer add argparse args parser run python main py overfit batch training run whole dataset instead running single batch code sample expected behavior one batch run environment cuda gpu tesla p100 pcie available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp thu jul pdt additional context	2020-08-13 08:02:34	1597305754	resolved fixed	48f658fbb551e5f65a32938224dd782dd4605820	1597369495	pytorch_lightning\core\datamodule.py pytorch_lightning\trainer\trainer.py                                                                  
140	2955	Using IterableDatasets without __len__ for Training	calling fit model trainloader evalloader internally call enforce datamodule dataloader override function statement train dataloader val dataloaders datamodule pytorch lightning pytorch lightning trainer configuration validator py line train dataloader val dataloaders datamodule similar pr problem translates dataloader bool us dataloader dataloader us iterabledataset iterabledatasets undefined fix also dl replaced dl none open pr fixing	2020-08-13 17:26:43	1597339603	resolved fixed	88bfed371e9597e813384b3d951b0e5280be71bd	1597352777	pytorch_lightning\trainer\configuration_validator.py                                                                    
141	2956	'NoneType' object has no attribute 'lower'  while training on TPU	bug distributed backend set tpu break line pytorch lightning pytorch lightning trainer distrib data parallel py line self distributed backend lower ddp spawn ddp cpu tpu distributed backend explicitly specified trainer params working misleading doc reproduce steps reproduce behavior expected behavior automatically set distributed backend train successfully additional context related comment comment	2020-08-13 17:37:50	1597340270	resolved fixed	cfd06a083b47b6c5c619f5362441197cb4e93e9e	1597359443	pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\trainer.py tests\models\test_tpu.py                                                                
142	2961	AttributeError: 'NoneType' object has no attribute 'best_model_path' when `checkpoint_callback` = False	bug model complete training tpu error error attributeerror nonetype object attribute best model path checkpoint callback false reproduce steps reproduce behavior trainer trainer tpu core max epoch checkpoint callback false distributed backend tpu trainer fit model attributeerror traceback recent call last trainer trainer tpu core precision max epoch checkpoint callback false distributed backend tpu trainer fit model opt conda lib python3 site package pytorch lightning trainer state py wrapped fn self args kwargs entering none self state entering result fn self args kwargs interrupted state set inside run function indicate run interrupted opt conda lib python3 site package pytorch lightning trainer trainer py fit self model train dataloader val dataloaders datamodule self accelerator backend setup self accelerator backend train model self accelerator backend teardown model else opt conda lib python3 site package pytorch lightning accelerator tpu backend py teardown self model transfer back best path trainer self trainer checkpoint callback best model path best path todo pas also bet score attributeerror nonetype object attribute best model path expected behavior complete training additional context seems similar	2020-08-13 19:24:40	1597346680	resolved fixed	8be002ccc7c2e8371ab426ea07c953f72747269e	1601549846	pytorch_lightning\accelerators\tpu_backend.py                                                                    
143	3000	valdation_epoch_end won't log if no logging is done in validation_step	bug edenlightning look like setting logger false prog bar false anything intended maybe add warning something also saw another issue log anything validation step logged value validation epoch end logged even set logger true updated notebook attatched verify code sample environment pl master env colab	2020-08-16 11:50:39	1597578639	resolved fixed	3453bba898a8cab7e0a6fd73e988291740f295d0	1597883649	pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\logging.py pytorch_lightning\trainer\trainer.py tests\callbacks\test_model_checkpoint.py tests\trainer\test_eval_loop_dict_return.py tests\trainer\test_trainer_steps_scalar_return.py                                                          
144	3001	ModelCheckpoint does not create full path	bug reproduce run checkpoint callback modelcheckpoint path folder created think line discard last trailing slash directory created intended path getting split expected behavior path fully created	2020-08-16 12:10:00	1597579800	resolved fixed	580b04b490d4d6819133a5604ea0ef82e2a21727	1600463351	CHANGELOG.md pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\callbacks\model_checkpoint.py tests\callbacks\test_model_checkpoint.py tests\trainer\test_trainer.py tests\trainer\test_trainer_steps_result_return.py                                                          
145	3005	`type_as` bug in the doc of LightningModule	bug run line code doc complains given reproduce code sample last line following code x torch zero device cpu new x torch zero device cuda new x new x type x type give error typeerror type argument position must tensor str expected behavior cast new x type x potential fix new x new x type x environment cuda gpu geforce rtx geforce rtx available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor x86 python version ubuntu smp thu jul utc	2020-08-16 14:27:57	1597588077	resolved fixed	9f6be96f845cabb114ef0df7a04498af6d5d8874	1597787498	docs\source\introduction_guide.rst docs\source\lightning-module.rst docs\source\new-project.rst                                                                
146	3019	Results gathering with varying tensor shapes (e.g. last batch)	bug results object reduction batch size different work torch stack get different input shape happen dataloader return smaller batch last iteration example def recursive stack result mutablemapping k v result item isinstance v dict recursive stack v isinstance v list len v isinstance v torch tensor v torch stack v result k v context slack discussion artgor	2020-08-17 16:53:33	1597683213	resolved fixed	9031dc3b817d46dc9b36007cce1360cfcf99939f	1597796868	CHANGELOG.md pytorch_lightning\core\step_result.py tests\core\test_results.py                                                                
147	3032	Epoch counting is one-off in multiple instances	bug two issue occur final epoch save checkpoint training resuming checkpoint n start epoch n expected behavior final checkpoint save ckpt file usual resume epoch n environment cuda gpu tesla v100 dgxs tesla v100 dgxs tesla v100 dgxs tesla v100 dgxs available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp thu jul utc	2020-08-18 07:32:29	1597735949	resolved fixed	10150fccb001867472e3cbde298591999e321278	1597919268	pytorch_lightning\callbacks\progress.py                                                                    
148	3035	Incorrect Precision/Recall/F1 score compared to sklearn	bug reproduce steps reproduce behavior copy code run code top bottom compare print result see difference sklearn lightning code import torch import numpy np import pytorch lightning pl sklearn metric import accuracy score precision score recall score f1 score print pl version generate binary data pl seed everything n number sample np random choice n pred np random choice n p tensor torch tensor pred tensor torch tensor pred accuracy appears alright print accuracy sklearn accuracy score pred print accuracy lightning functional pl metric functional accuracy pred tensor tensor num class print accuracy lightning tensor pl metric accuracy num class pred tensor tensor result accuracy sklearn accuracy lightning functional tensor accuracy lightning tensor tensor precision appears compared sklearn print precision sklearn precision score pred print precision lightning functional pl metric functional precision pred tensor tensor num class print precision lightning tensor pl metric precision num class pred tensor tensor precision sklearn precision lightning functional tensor precision lightning tensor tensor recall appears compared sklearn print recall sklearn recall score pred print recall lightning functional pl metric functional recall pred tensor tensor num class print recall lightning tensor pl metric recall num class pred tensor tensor recall sklearn recall lightning functional tensor recall lightning tensor tensor f1 appears compared sklearn print f1 sklearn f1 score pred print f1 lightning functional pl metric functional f1 score pred tensor tensor num class print f1 lightning tensor pl metric f1 num class pred tensor tensor f1 sklearn f1 lightning functional tensor f1 lightning tensor tensor expected behavior precision recall f1 result expected consistent sklearn environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py pytorch version os e g linux macos installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version none gpu model configuration none relevant information additional context	2020-08-18 15:31:56	1597764716	resolved fixed	28af34bc5134fddf544425fed9ffe04445b237e3	1600173374	CHANGELOG.md pytorch_lightning\metrics\classification.py pytorch_lightning\metrics\functional\classification.py pytorch_lightning\metrics\functional\reduction.py pytorch_lightning\metrics\functional\regression.py pytorch_lightning\metrics\regression.py tests\metrics\functional\test_classification.py tests\metrics\functional\test_reduction.py                                                      
149	3053	load_from_checkpoint() doesn't work when a LightningModule inherits from typing.Generic	bug lightningmodule saved hyperparameters inherits hyperparameters saved checkpoint file loaded automatically causing error call gather list argument lightningmodule inherits return instead actual argument implement empty execution path end result pl filter saved hyperparameters checkpoint result error trying instantiate lightningmodule assume would happen lightningmodule inherits class implement reproduce create lightningmodule inherits typing generic hyperparameters fit try load checkpoint code sample import torch import torch nn functional f import pytorch lightning pl typing import generic typevar torch utils data import dataloader typevar class genericlitclassifier generic pl lightningmodule def init self dim super init self l1 torch nn linear dim self save hyperparameters def forward self x return torch relu self l1 x view x size def training step self batch batch nb x batch loss f cross entropy self x tensorboard log train loss loss return loss loss log tensorboard log def configure optimizers self return torch optim adam self parameter lr class litclassifier genericlitclassifier str pas class dataset def getitem self idx return torch one def len self return train loader dataloader dataset batch size model litclassifier trainer pl trainer max epoch trainer fit model train loader path trainer checkpoint callback best k model item lm litclassifier load checkpoint path expected behavior even lightningmodule inherits class implement new e g typing generic hyperparameters loaded automatically checkpoint environment cuda gpu available false version none packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os darwin architecture processor i386 python version darwin kernel version mon apr pdt root xnu release x86 additional context	2020-08-19 20:11:59	1597867919	resolved fixed	88886ace7232c8e25ece431969c5d8d101f3368d	1597922351	pytorch_lightning\core\saving.py tests\base\__init__.py tests\base\model_template.py tests\models\test_restore.py                                                              
150	3097	IoU metric returns 0 score for classes not present in prediction or target	bug iou metric implementation always return score class present either prediction target lead deflated score even perfectly predicted example case one example affected case multi class semantic segmentation image contain one class outlined follows possible class dataset optionally background class ground truth target image consists class model perfectly predicts target iou score perfect actual score deflated since unnecessary penalty class case another example bit implementation dependent explain target contains prediction perfectly assigns iou score perfect actual score deflated since unnecessary penalty class applies higher numbered class present lower numbered class present case also affected num class parameter passed functional iou implementation num class n given class id n appear target prediction always assigned iou score example n class present correct target prediction class iou score especially aggregate dataset substantial neutral ground truth value e semantic segmentation dataset lot image class present significantly deflate iou score also undesirably interact checkpointing look iou based metric reproduce code sample case import torch pytorch lightning metric functional classification import iou target torch tensor pred torch tensor iou pred target returns tensor computation none reduction illustrate score class get iou pred target reduction none returns tensor case target torch tensor pred torch tensor iou pred target returns tensor iou pred target reduction none returns tensor case target torch tensor pred torch tensor iou pred target num class returns tensor iou pred target num class reduction none returns tensor expected behavior fallback iou score use class target correctly prediction configurable probably default seems expected behavior case target torch tensor pred torch tensor iou pred target return tensor iou pred target reduction none return tensor case target torch tensor pred torch tensor iou pred target return tensor iou pred target reduction none return tensor case target torch tensor pred torch tensor iou pred target num class return tensor iou pred target num class reduction none return tensor environment cuda gpu geforce rtx max q design available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp tue aug utc additional context open attempt implement expected behavior described add test feedback welcome somewhat related issue	2020-08-21 23:04:35	1598051075	resolved fixed	76c4afb840b0ae5fcafee07d527c58e9245d099d	1600331869	CHANGELOG.md pytorch_lightning\metrics\classification.py pytorch_lightning\metrics\functional\classification.py tests\metrics\functional\test_classification.py tests\metrics\test_classification.py tests\trainer\test_trainer_tricks.py                                                          
151	3104	TPU available: true when there are no TPUs	bug using dgx machine tpus initiating trainer log tpu available true end returning missing xla configuration run script reproduce code sample simply running following line machine trainer pl trainer gpus gpu available true used true tpu available true using tpu core expected behavior trainer pl trainer gpus gpu available true used true tpu available false using tpu core environment cuda gpu tesla v100 sxm2 available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp wed jan utc	2020-08-22 19:24:01	1598124241	resolved fixed	69833dad5b2a0e7e68ed60a91a5a8c32ae22f707	1602006877	CHANGELOG.md pytorch_lightning\accelerators\tpu_backend.py pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\core\lightning.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\utilities\xla_device_utils.py tests\models\test_tpu.py tests\utilities\test_xla_device_utils.py                                                      
152	3111	Horovod with native 16 precision not working	bug reproduce steps reproduce behavior using precision distributed backend horovod traceback recent call last file workspace main lightning py line main hyperparams file workspace main lightning py line main trainer fit model file usr local lib python3 dist package pytorch lightning trainer state py line wrapped fn result fn self args kwargs file usr local lib python3 dist package pytorch lightning trainer trainer py line fit result self horovod train model file usr local lib python3 dist package pytorch lightning trainer distrib part py line horovod train model optimizers model configure apex amp model self optimizers self amp level file usr local lib python3 dist package pytorch lightning core lightning py line configure apex model optimizers amp initialize model optimizers opt level amp level code sample trainer trainer precision gpus distributed backend horovod environment pytorch version cu101 installed pytorch pip	2020-08-23 10:38:33	1598179113	resolved fixed	091d37f968b593e7e3b212d53bec6395a8c546de	1599611457	CHANGELOG.md pytorch_lightning\accelerators\horovod_backend.py tests\models\test_horovod.py                                                                
153	3143	Trainer crashed when optimizer frequency is defined.	bug reproduce steps reproduce behavior run following code traceback recent call last file pl bug py line trainer fit mnist model train loader file opt conda lib python3 site package pytorch lightning trainer state py line wrapped fn result fn self args kwargs file opt conda lib python3 site package pytorch lightning trainer trainer py line fit result self accelerator backend train model file opt conda lib python3 site package pytorch lightning accelerator gpu backend py line train result self trainer run pretrain routine model file opt conda lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file opt conda lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file opt conda lib python3 site package pytorch lightning trainer training loop py line run training epoch batch output self run training batch batch batch idx file opt conda lib python3 site package pytorch lightning trainer training loop py line run training batch batch output opt idx append opt closure result training step output epoch end code sample def configure optimizers self optimizer g torch optim adam self parameter lr weight decay optimizer torch optim adam self parameter lr weight decay return optimizer optimizer frequency optimizer optimizer g frequency culprit frequency removing line allow trainer run smoothly definition correct according documentation expected behavior model train without crash code work environment environment cuda gpu geforce gtx titan x available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp tue jun utc	2020-08-25 03:25:50	1598325950	resolved fixed	a1ea681c47004599ee5a47a05ddd1b4ea12e60d4	1599771680	CHANGELOG.md docs\source\converting.rst pytorch_lightning\trainer\training_loop.py tests\base\model_optimizers.py tests\trainer\test_optimizers.py                                                            
154	3144	ONNX model does not save on GPU	bug attempting export onnx training model gpu throw error input sample example input array cuda tensor reproduce steps reproduce behavior train model gpu try export onnx self example input array torch zero input sample torch zero runtimeerror traceback recent call last filepath model onnx model onnx filepath export params true opt conda lib python3 site package pytorch lightning core lightning py onnx self file path input sample kwargs example output kwargs self eval kwargs example output self input data torch onnx export self input data file path kwargs opt conda lib python3 site package torch nn module module py call self input kwargs result self slow forward input kwargs else result self forward input kwargs hook self forward hook value hook result hook self input result forward self input def forward self input return self model input def training step self batch batch idx opt conda lib python3 site package torch nn module module py call self input kwargs result self slow forward input kwargs else result self forward input kwargs hook self forward hook value hook result hook self input result opt conda lib python3 site package torch nn module container py forward self input def forward self input module self input module input return input opt conda lib python3 site package torch nn module module py call self input kwargs result self slow forward input kwargs else result self forward input kwargs hook self forward hook value hook result hook self input result opt conda lib python3 site package torch nn module conv py forward self input def forward self input return self conv forward input self weight class conv3d convnd opt conda lib python3 site package torch nn module conv py conv forward self input weight pair self dilation self group return f conv2d input weight self bias self stride self padding self dilation self group def forward self input runtimeerror input type torch floattensor weight type torch cuda floattensor code sample filepath model onnx model onnx filepath export params true expected behavior automatically convert example input array input sample device type save model onnx	2020-08-25 03:35:04	1598326504	resolved fixed	d9ea25590e95ca9e70401123a0f1f59de711e2ff	1598458939	CHANGELOG.md pytorch_lightning\core\lightning.py tests\models\test_onnx.py                                                                
155	3162	RMSLE metric appears to be incorrect	bug usage mse rmsle function look wrong look like function currently computes instead expected behavior would expect rmsle look like rmsle rmse torch log pred torch log target reduction reduction	2020-08-25 15:23:39	1598369019	resolved fixed	888340d17ed91eeee1b576cda36f13f0ef3e5459	1598443373	CHANGELOG.md pytorch_lightning\metrics\functional\regression.py pytorch_lightning\metrics\regression.py tests\metrics\functional\test_regression.py                                                              
156	3168	Max line length mismatch	bug pep8speaks yml set whereas pyproject toml expected behavior line length consistent	2020-08-25 17:28:04	1598376484	resolved fixed	59fb332677c0f865de1e42f2fc80caa2460915ff	1598404862	.pep8speaks.yml                                                                    
157	3172	"""Unsupported `ReduceOp` for distributed computing"" warning when using Result without distributed"	bug step result py import pytorch lightning metric converter converter py raise following warning torch distributed reduceop imported rank zero warn unsupported reduceop distributed computing use want use distributed training warning printed stdout non stop one warning per second rate reproduce use result object without distributed package available expected behavior warning printed use distributed need see warning environment cuda gpu geforce rtx available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os windows architecture windowspe processor intel64 family model stepping genuineintel python version additional context	2020-08-25 18:31:49	1598380309	resolved fixed	99f05ed23f818d4f21c2c6925a66e75df606c859	1600554546	pytorch_lightning\metrics\converters.py pytorch_lightning\metrics\sklearns.py                                                                  
158	3185	Value out of range (expected to be in range of [-1, 0], but got 1)	value range expected range got exception device tpu torch xla csrc helper cpp check failed min shape dim dim dim max shape dim following stack trace using tpu core kaggle exact code sync dist false work completely fine kaggle gpu value range expected range got exception device tpu torch xla csrc helper cpp check failed min shape dim dim dim max shape dim begin stack trace tensorflow currentstacktrace torch xla xlahelpers getcanonicaldimensionindex long long long long torch xla xlahelpers maketransposepermutation long long long long long long torch xla xlatensor transpose torch xla xlatensor const long long long long torch xla atenxlatype tensor const c10 impl wrap kernel functor unboxed tensor tensor const call c10 operatorkernel tensor const tensor const tensor const pymethoddef rawfastcallkeywords pymethoddescr fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcalldict pyobject call prepend pyobject call pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcalldict pyeval evalframedefault pyfunction fastcalldict pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcalldict pyobject call prepend pyobject fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcalldict pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyeval evalcodeex pyeval evalcode pymethoddef rawfastcallkeywords pycfunction fastcallkeywords pyeval evalframedefault pygen send pyeval evalframedefault pygen send pyeval evalframedefault pygen send pymethoddef rawfastcallkeywords pymethoddescr fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcalldict pyobject call prepend pyobject call pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pymethoddef rawfastcallkeywords pycfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pymethoddef rawfastcallkeywords pycfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcallkeywords pyeval evalframedefault pymethoddef rawfastcallkeywords pycfunction fastcallkeywords pyeval evalframedefault pyeval evalcodewithname pyfunction fastcalldict pyobject call prepend pyobject call pyeval evalframedefault pygen send pymethoddef rawfastcallkeywords pymethoddescr fastcallkeywords pyeval evalframedefault pyfunction fastcallkeywords pyeval evalframedefault pyfunction fastcalldict end stack trace code lightningmodule class graphaestage1 pl lightningmodule def init self config super graphaestage1 self init max deg config poc max degree input dim config input dim hidden feat config hidden feat dim layerid config layerid self lr config lr self encoder graphencoderstage1 max deg input dim hidden feat layerid self decoder graphdecoderstage1 max deg input dim hidden feat layerid self encoder apply self init weight self crit torch nn l1loss self node mae mae self adj mae mae self decoder self linear weight nn parameter self encoder self linear weight permute range config poc max degree self decoder neigh linear weight nn parameter self encoder neigh linear weight permute def training step self batch batch idx loss tf node self shared step batch result pl trainresult minimize loss result log train loss loss prog bar true logger true step false epoch true sync dist true return result def validation step self batch batch idx loss tf node recon node val node mae val adj mae self shared step batch log val loss loss node mae val node mae adj mae val adj mae result pl evalresult checkpoint loss result log dict log prog bar true logger true step false epoch true sync dist true return result def shared step self batch node adj deg mask batch tf node avg adj self encoder node adj deg mask recon node recon adj self decoder tf node deg node loss self criterion recon node node adj loss self criterion recon adj avg adj loss node loss adj loss node mae self node mae node recon node adj mae self adj mae recon adj avg adj return loss tf node recon node node mae adj mae def configure optimizers self optimizer torch optim adam self parameter lr self lr return optimizer def criterion self output target return self crit output target def init weight self type nn linear torch nn init xavier uniform weight bias data fill similar issue reported pytorch xla repo many using crossentropyloss using crossentropyloss	2020-08-26 05:19:53	1598419193	resolved fixed	3910ad033074367f6abfe0001562db725a75cb73	1598966272	pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\core\step_result.py tests\models\test_tpu.py                                                                
159	3189	Broken [Source] links in docs	documentation hello browsing doc curiosity wanted check source clicked source link method link however sends right repo name pytorch lightning familiar sphinx checked doc conf file think reason found pytorch lightning doc source conf py lines ee4eae8 project pytorch lightning copyright pytorch lightning copyright author pytorch lightning author short x version version pytorch lightning version full version including alpha beta rc tag release pytorch lightning version options linkcode extension github user pytorchlightning github repo project since github repo set project indeed pytorch lightning broken link someone familiar sphinx confirm glad submit pr fix	2020-08-26 08:25:32	1598430332	resolved fixed	9be26d0c1b3aa2923475cd83098850d1e438a24e	1602107724	docs\source\_templates\theme_variables.jinja docs\source\conf.py docs\source\lightning_module.rst                                                                
160	3199	Early Stopping + result dictionary + no validation not working.	bug case user use validation return dictionary instead trainresult training work combination early stopping test case check pytorch lightning test callback test early stopping py lines bd35c86 def test early stopping val step tmpdir test early stopping callback fall back training metric validation defined class currentmodel evalmodeltemplate def training step self args kwargs output super training step args kwargs output update train metric output loss could anything else return output model currentmodel model validation step none model val dataloader none stopping earlystopping monitor train metric min delta trainer trainer default root dir tmpdir early stop callback stopping overfit batch max epoch result trainer fit model assert result training failed complete assert trainer current epoch trainer max epoch check last line wrong actually compare assert trainer current epoch trainer max epoch reproduce steps reproduce behavior fix test case run test code sample guess using test case simpler easier expected behavior interesting question indeed possibilities test case pas correct comparison doc williamfalcon comment suggest loss work fixing issue settled expected behavior tell happy help could also include pull request already tried bring doc line test case environment cuda gpu geforce gtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor x86 python version ubuntu smp fri jul utc additional context	2020-08-26 17:53:25	1598464405	resolved fixed	197acd535fee5e79dafeeff14cc742095c77bd70	1600463284	docs\source\results.rst pytorch_lightning\callbacks\early_stopping.py tests\callbacks\test_early_stopping.py                                                                
161	3233	auto_scale_batch_size not working with datamodule	bug trainer expects lightningmodule self batch size see scale batch size training trick py however one using new lightningdatamodule class self batch size defined reproduce assert hasattr lightning data module batch size trainer trainer auto scale batch size true trainer fit lightning module datamodule lightning data module pytorch lightning utility exception misconfigurationexception field batch size found model model hparams expected behavior auto scale batch size work using lightningdatamodule environment packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm	2020-08-27 21:56:50	1598565410	resolved fixed	48c22c8bad9a47141c7160d92f2edc9e2e4ad159	1599163669	CHANGELOG.md pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_tricks.py pytorch_lightning\utilities\parsing.py tests\trainer\test_trainer_tricks.py                                                            
162	3253	**gather_all_tensors_if_available**  share the same underlying storage for all GPUs	bug hi one new feature copy bug would lead tensor gpus wrongly one gpu since share storage gathered result world size torch zero like result change gathered result torch zero like result range world size	2020-08-29 09:06:08	1598691968	resolved fixed	d521c1b1787930dd4f6375a3c61a25579ca59ee5	1599128852	pytorch_lightning\metrics\converters.py tests\metrics\test_converters.py                                                                  
163	3259	Cap batch size by number of training samples when using auto_scale_batch_size	bug batch size finder set unrealistically high batch size sample training dataset fit one batch batch size succeeded trying batch size batch size succeeded trying batch size batch size succeeded trying batch size finished batch size finder continue full run using batch size reproduce steps reproduce behavior run mnist example auto scale batch size true one need remove hardcoded batch size set self batch size expected behavior batch size search space larger number available training sample	2020-08-29 22:01:59	1598738519	resolved fixed	e245065fbcc7701da528fbe2568242d50586a0a3	1599641503	CHANGELOG.md pytorch_lightning\trainer\training_tricks.py pytorch_lightning\tuner\batch_size_scaling.py tests\trainer\test_trainer_tricks.py                                                              
164	326	Broken link in Examples readme	link template top work seems like underlying codebase shifted doc yet updated	2019-10-07 21:33:42	1570484022	resolved fixed	c0bd203cffad86cc55fda2d87b7f7e0d51135166	1570534794	docs\examples\Examples.md                                                                    
165	3260	auto_scale_batch_size won't reset current_epoch	bug auto scale batch size enabled model initially trained varying batch size training begin trainer current epoch equal instead reproduce either observe progress bar use simple callback track epoch number auto scale batch size enabled auto scale batch size disabled pytorch lightning import callback class printcallback callback def init self self observed epoch def train epoch start self trainer pl module print f current epoch trainer current epoch self observed epoch append trainer current epoch	2020-08-29 22:09:45	1598738985	resolved fixed	39b3704285e40a29a5862c4d8145b68d3b35d45e	1602006888	CHANGELOG.md pytorch_lightning\tuner\batch_size_scaling.py tests\trainer\test_trainer_tricks.py                                                                
166	3276	Logging non-tensor scalar with result breaks subsequent epoch aggregation	bug logging non tensor scalar result break subsequent epoch tbptt aggregation master process terminated following error traceback recent call last file opt conda lib python3 site package torch multiprocessing spawn py line wrap fn args file opt conda lib python3 site package pytorch lightning accelerator ddp spawn backend py line ddp train result self trainer run pretrain routine model file opt conda lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file opt conda lib python3 site package pytorch lightning trainer training loop py line train self run training epoch file opt conda lib python3 site package pytorch lightning trainer training loop py line run training epoch self run training epoch end epoch output checkpoint accumulator early stopping accumulator num optimizers file opt conda lib python3 site package pytorch lightning trainer training loop py line run training epoch end epoch log metric epoch progress bar metric self auto reduce result epoch end epoch output file opt conda lib python3 site package pytorch lightning trainer training loop py line auto reduce result epoch end tbptt out tbptt out class reduce across time tbptt out file opt conda lib python3 site package pytorch lightning core step result py line reduce across time result k tbptt reduce fx value typeerror mean argument input position must tensor list reproduce def training step self batch batch idx x batch batch x self forward x loss self loss x result pl trainresult loss result log non tensor scalar result log loss loss step false epoch true fix result log non tensor scalar torch tensor expected behavior log result object value accept non tensor value value cause issue metric logged additional context log changed accept tensor built conversion update investigate	2020-08-31 01:33:53	1598837633	resolved fixed	2d5a7f5e7dc686cfc8172101a81505bf421468af	1602585731	pytorch_lightning\core\step_result.py tests\trainer\logging\test_eval_loop_logging_1_0.py                                                                  
167	3280	Error in transfer_batch_to_device when None type is in the batch	bug reproduce steps reproduce behavior torchtext pre installed run sample code code sample torch utils data import dataloader import pytorch lightning pl def collate fn batch return batch class mydatamodule pl lightningdatamodule def init self super init def prepare data self pas def setup self stage self train input torch randn output none def train dataloader self return dataloader self train batch size collate fn collate fn class mymodel pl lightningmodule def init self super init self linear torch nn linear def forward self x return self linear x def configure optimizers self return torch optim adam self parameter def training step self batch batch idx x batch input batch output loss self x result pl trainresult loss result log train loss loss epoch true return result def main dataset data module mydatamodule model model mymodel train trainer pl trainer max step trainer fit model datamodule data module name main main expected behavior code run fine package torchtext installed however code raise following error torchtext available believe inconsistency bug file python3 site package pytorch lightning utility apply func py line batch return data device kwargs attributeerror nonetype object attribute python baseexception think line code cause problem environment cuda gpu titan xp titan xp titan xp titan xp titan xp titan xp titan xp titan xp available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture elf processor x86 python version ubuntu smp tue nov utc	2020-08-31 06:32:08	1598855528	resolved fixed	bd5f53c51994e14c79404c9dcededae53b21b664	1599836158	pytorch_lightning\utilities\apply_func.py tests\models\test_gpu.py                                                                  
168	3303	AUROC metric should throw an error when used for multi-class problems	bug auroc accepts multi class input without throwing error instead give random value give illusion working background reproduce steps reproduce behavior manually create multi class array use pytorch lightning auroc metric use sklearn auroc metric observe value matching code sample import torch import sklearn metric import pytorch lightning pl pytorch lightning metric classification import auroc pl seed everything auroc auroc def test auroc sk multiclass range target torch randint size pred torch rand softmax dim torch randint size score sk sklearn metric roc auc score target numpy pred numpy multi class ovo label score pl auroc pred target print score sk score pl assert torch allclose torch tensor score pl float torch tensor score sk float test auroc sk multiclass expected behavior throw error multi class auroc implemented yet note documentation auroc metric support multi class yet actual behavior giving random value giving false sense working environment cuda gpu geforce gtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version ubuntu smp thu jul utc additional context output value nonsense multi class classification instead error thought appropriate file bug instead feature request documentation improvement aware auroc implementation intended multi class discussion pytorch lightning forum used auroc value noticed wrong training model take many people guard current form feature request multiclassauroc	2020-09-01 09:37:48	1598953068	resolved fixed	b1347c956af4752560b53b891d352c48c6050305	1600681608	CHANGELOG.md pytorch_lightning\metrics\classification.py pytorch_lightning\metrics\functional\classification.py tests\metrics\functional\test_classification.py tests\metrics\test_classification.py                                                            
169	3335	Cannot replicate training results with seed_everything and deterministic flag = True with DDP	bug noticed adding metric calculation lightningmodule example adding confusion matrix end validation test epoch added function appear dependent random seed noticed training result exactly however added function ran yes got training result reproduce code sample expected behavior training result identical even deterministic function added environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py pytorch version e g os e g linux linux installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version gpu model configuration gpus ddp relevant information additional context	2020-09-02 21:51:08	1599083468	resolved fixed	a71d62d8409f4960a4b438b8d19c924d3636c73f	1600645378	CHANGELOG.md pytorch_lightning\accelerators\ddp_base_backend.py pytorch_lightning\utilities\seed.py                                                                
170	3393	MLFlow Logger slows training steps dramatically, despite only setting metrics to be logged on epoch	bug using mlflow logger remote server logging per step introduces latency slows training loop tried configure logging metric per epoch however seems still result much slower performance suspect logger still communicating mlflow server training step reproduce start mlflow server locally mlflow ui run minimal code example mlflow logger set use default file uri uncomment tracking uri use local mlflow server run code see time drop iteration per second code sample import torch torch utils data import tensordataset dataloader import pytorch lightning pl class mymodel pl lightningmodule def init self super init self num example self num valid self batch size self lr self wd self num feature self linear torch nn linear self num feature self loss func torch nn mseloss self x torch rand self num example self num feature self self x matmul torch rand self num feature torch rand self num example def forward self x return self linear x def train dataloader self d tensordataset self x self num valid self x self num valid dl dataloader d batch size self batch size return dl def val dataloader self d tensordataset self x self num valid self x self num valid dl dataloader d batch size self batch size return dl def configure optimizers self return torch optim adam self parameter lr self lr weight decay self wd def training step self batch batch idx x batch yhat self x loss self loss func yhat result pl trainresult minimize loss result log train loss loss epoch true step false return result def validation step self batch batch idx x batch yhat self x loss self loss func yhat result pl evalresult early stop loss result log val loss loss epoch true step false return result name main pytorch lightning logger import tensorboardlogger mlflowlogger mlf logger mlflowlogger experiment name f mymodel tracking uri trainer pl trainer min epoch max epoch early stop callback true logger mlf logger model mymodel trainer fit model expected behavior using trainresult evalresult manually handling metric logging using training epoch end validation epoch end callback possible avoid mlflow logger communicating server training loop would make feasible implement mlflow remote server used experiment tracking environment cuda gpu available false version none packages numpy pytorch debug false pytorch version cpu pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp tue may utc additional context host mlflow instance aws would like able track experiment without affecting training speed appears general mlflow logger much le performant default tensorboard logger would much problem could avoid call logger training loop solution done bit debugging codebase able isolate cause two place pytorch lightning pytorch lightning logger mlflow py lines d438ad8 property def run id self create experiment exist get run id self experiment return self run id self experiment called regardless whether self run id exists add self run id avoid calling self mlflow client get experiment name self experiment name step however still call time log metric mflow property self experiment pytorch lightning pytorch lightning logger mlflow py lines d438ad8 property rank zero experiment def experiment self mlflowclient r actual mlflow object use mlflow feature class pytorch lightning core lightning lightningmodule following example self logger experiment mlflow function expt self mlflow client get experiment name self experiment name store expt within logger call self mlflow client get experiment name exist eliminate overhead run fast fast tensorboard logger mlflow logging appears working expected happy raise pr fix	2020-09-08 06:28:36	1599546516	resolved fixed	656c1af0df0cd0a8102a69c9c5045e86dc2b6b3a	1599644306	CHANGELOG.md pytorch_lightning\loggers\mlflow.py tests\loggers\test_mlflow.py                                                                
171	3417	CometLogger failing without save_dir	bug cometmllogger api key without save dir result error happens due save dir set later train loop try read fails fixed setting save dir none supply pr moment reproduce steps reproduce behavior model lightningmodel comet logger cometlogger api key key workspace workspace trainer trainer logger comet logger trainer fit model traceback recent call last trainer fit model file python3 site package pytorch lightning trainer state py line wrapped fn result fn self args kwargs file python3 site package pytorch lightning trainer trainer py line fit result self accelerator backend train model file python3 site package pytorch lightning accelerator gpu backend py line train result self trainer run pretrain routine model file python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file python3 site package pytorch lightning trainer training loop py line train self train start file python3 site package pytorch lightning trainer callback hook py line train start callback train start self self get model file python3 site package pytorch lightning utility distributed py line wrapped fn return fn args kwargs file python3 site package pytorch lightning callback model checkpoint py line train start save dir trainer logger save dir trainer default root dir file python3 site package pytorch lightning logger comet py line save dir return self save dir additional context	2020-09-09 12:37:07	1599655027	resolved fixed	5b4db52851000d5e4eca8c680d851bcdaafc3a80	1599658055	pytorch_lightning\loggers\comet.py                                                                    
172	3424	DataModule with lr_find not supported	bug reproduce steps reproduce behavior create trainer trainer lightningmodule model datamodule data module call trainer lr find model datamodule data module error typeerror lr find got unexpected keyword argument datamodule code sample import torch import torch nn nn import pytorch lightning pl torch utils data import dataloader class datamodule pl lightningdatamodule def init self super init def gen set self start end vals torch tensor float range return torch stack torch sin vals torch co vals def train dataloader self return dataloader dataset self gen set def val dataloader self return dataloader dataset self gen set def test dataloader self return dataloader dataset self gen set class litmodel pl lightningmodule def init self feature super init self layer nn linear feature feature self layer nn linear feature feature self criterion nn mseloss self lr def forward self inp inp torch tanh self layer inp return self layer inp def training step self batch batch idx x batch hat self x loss self criterion hat x float return pl trainresult minimize loss def configure optimizers self return torch optim adam self parameter lr self lr self learning rate data module datamodule trainer pl trainer model litmodel feature lr finder trainer lr find model datamodule data module error expected behavior lr find function work passed train loader test loader invoking like fit environment packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python	2020-09-09 16:18:23	1599668303	resolved fixed	e4e60e9b82adc48482db4721ce3e1fdc3ab6d6fe	1601541192	CHANGELOG.md pytorch_lightning\tuner\lr_finder.py pytorch_lightning\tuner\tuning.py tests\trainer\test_lr_finder.py                                                              
173	3487	Gradient norms are not logged unless row_log_interval==1	bug version guard calculate gradient norm log metric satisfied batch unless row log interval place guard seems batch idx self row log interval pytorch lightning pytorch lightning trainer training loop py lines b40de54 def save train loop metric logger self batch idx batch output metric logged log metric batch idx self row log interval self stop log metric self fast dev run log user requested information logger metric batch output batch log metric grad norm dic batch output grad norm dic len metric len grad norm dic self log metric metric grad norm dic however run batch backward pas batch idx self row log interval pytorch lightning pytorch lightning trainer training loop py lines b40de54 def run batch backward pas self split batch batch idx opt idx optimizer grad norms track gradient norm requested grad norm dic batch idx self row log interval float self track grad norm model self get model grad norm dic model grad norm self track grad norm reproduce steps reproduce behavior run code sample taken confirm gradient logged tensorboard change row log interval rerun code confirm gradient logged code sample import pytorch lightning pl torch utils data import tensordataset dataloader pytorch lightning logger tensorboard import tensorboardlogger torch optim import sgd import torch nn nn import torch class mwenet pl lightningmodule def init self super mwenet self init self first nn conv2d self second nn conv2d self loss nn l1loss def train dataloader self x y torch zero torch one d tensordataset x y return dataloader d def forward self x self first x self second return def configure optimizers self first sgd self first parameter lr second sgd self second parameter lr return second first def training step self batch batch idx optimizer idx x y batch self forward x return loss self loss y net mwenet logger tensorboardlogger tb log name testing trainer pl trainer track grad norm row log interval max epoch logger logger trainer fit net expected behavior gradients logged track grad norm true environment cuda gpu geforce gtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os windows architecture windowspe processor amd64 family model stepping authenticamd python version additional context	2020-09-13 11:27:42	1599996462	resolved fixed	4ed96b2eb471124184144f96d259055e49ac97e7	1600188087	CHANGELOG.md pytorch_lightning\trainer\training_loop.py tests\models\test_grad_norm.py                                                                
174	3549	Bug in validation_epoch_end	bug documentation described running end validation epoch need necessarily return anything running slightly modified version example doc seemingly run single batch validation data return error nothing returned reproduce mwe import o import torch import torch nn functional f torchvision datasets import mnist torchvision import transforms torch utils data import dataloader import pytorch lightning pl torch utils data import random split class litmodel pl lightningmodule def init self super init self layer torch nn linear self layer torch nn linear def forward self x x x view x size x self layer x x f relu x x self layer x return x def configure optimizers self optimizer torch optim adam self parameter lr return optimizer def training step self batch batch idx x batch hat self x loss f cross entropy hat return loss loss def validation step self batch batch idx x batch hat self x loss f cross entropy hat return val loss loss def validation epoch end self validation step output print length output format len validation step output dummy return value avoid error return val loss model litmodel dataset mnist o getcwd download true train false transform transforms totensor train val random split dataset train loader dataloader train val loader dataloader val train trainer pl trainer progress bar refresh rate max epoch weight summary none gpus trainer fit model train loader val loader output gpu available true used true tpu available false using tpu core cuda visible devices usr local lib python3 dist package pytorch lightning utility distributed py userwarning could log computational graph since model example input array attribute set input array given warning warn args kwargs length output length output length output length output length output saving latest checkpoint length output return value given validation epoch end following error occurs attributeerror traceback recent call last train trainer pl trainer progress bar refresh rate max epoch weight summary none gpus trainer fit model train loader val loader frame usr local lib python3 dist package pytorch lightning trainer state py wrapped fn self args kwargs entering none self state entering result fn self args kwargs interrupted state set inside run function indicate run interrupted usr local lib python3 dist package pytorch lightning trainer trainer py fit self model train dataloader val dataloaders datamodule self accelerator backend gpubackend self model self accelerator backend setup model result self accelerator backend train model elif self use tpu usr local lib python3 dist package pytorch lightning accelerator gpu backend py train self model def train self model result self trainer run pretrain routine model return result usr local lib python3 dist package pytorch lightning trainer trainer py run pretrain routine self model run val batch training start self run sanity check ref model model clear cache training usr local lib python3 dist package pytorch lightning trainer trainer py run sanity check self ref model model num loader len self val dataloaders max batch self num sanity val step num loader eval result self evaluate model self val dataloaders max batch false allow return eval usr local lib python3 dist package pytorch lightning trainer evaluation loop py evaluate self model dataloaders max batch test mode log callback metric self update callback metric eval result using eval result write prediction disk available usr local lib python3 dist package pytorch lightning trainer evaluation loop py update callback metric self eval result using eval result flat val loss eval result else flat flatten dict eval result self callback metric update flat else usr local lib python3 dist package pytorch lightning utility parsing py flatten dict source result result k v source item isinstance v dict flatten dict v result attributeerror nonetype object attribute item expected behavior output validation epoch end contain result batch test validation batch running background could explain result one batch included first loop return value addressed error tell included release perhaps missing something environment pytorch pytorch lightning	2020-09-18 13:00:13	1600434013	resolved fixed	9acee67c31c84dac74cc6169561a483d3b9c9f9d	1600560050	pytorch_lightning\trainer\connectors\logger_connector.py pytorch_lightning\trainer\logging.py tests\base\model_valid_epoch_ends.py tests\trainer\test_trainer_steps_result_return.py                                                              
175	3578	"Incorrect ""Saving latest checkpoint"" warning"	bug saving latest checkpoint warning appears regardless whether modelcheckpoint exists save last set true pytorch lightning pytorch lightning trainer training loop py lines a71d62d save latest checkpoint rank zero warn saving latest checkpoint self check checkpoint callback check val false force save true pytorch lightning pytorch lightning trainer training loop py lines a71d62d def check checkpoint callback self check val force save false model self trainer get model val loop present fast dev run still need call checkpoint todo bake logic checkpoint callback activate overridden validation step model check val activate force save checkpoint callback c c self trainer callback isinstance c modelcheckpoint c validation end self trainer model c checkpoint callback might confuse user think last checkpoint got saved proposed change def check checkpoint callback self check val force save false model self trainer get model val loop present fast dev run still need call checkpoint todo bake logic checkpoint callback activate overridden validation step model check val activate force save checkpoint callback c c self trainer callback isinstance c modelcheckpoint c save last c checkpoint callback rank zero warn saving latest checkpoint c validation end self trainer model c checkpoint callback	2020-09-21 00:54:24	1600649664	resolved fixed	ed12e422a42472af1acb88f870dba3d43710b31d	1601036286	pytorch_lightning\trainer\training_loop.py tests\callbacks\test_model_checkpoint.py                                                                  
176	3597	distributed training: ModelCheckpoint is receiving bad data	reproduce minute tried master got unrelated wandb error gave trying reproduce must machine multiple gpus git clone git github com huggingface transformer git cd transformer pip install e pip install e example installs pytorch lightning git checkout pl checkpoint bug cd example seq2seq wget tar xzvf wmt en ro tar gz export max len export sshleifer student marian en ro python finetune py learning rate train predict fp16 val check interval data dir wmt en ro max source length max len max target length max len val max target length max len test max target length max len freeze encoder freeze embeds train batch size eval batch size tokenizer name model name path warmup step sortish sampler logger name wandb fp16 opt level o1 task translation num sanity val step model name path gpus num train epoch data dir wmt mar pl output dir dmar pl v3 save top k results l dmar pl v3 ckpt rw r r shleifer shleifer sep dmar pl v3 val avg bleu step count ckpt rw r r shleifer shleifer sep dmar pl v3 val avg bleu step count ckpt rw r r shleifer shleifer sep dmar pl v3 val avg bleu step count ckpt rw r r shleifer shleifer sep dmar pl v3 val avg bleu step count ckpt rw r r shleifer shleifer sep dmar pl v3 val avg bleu step count ckpt checkpoint much lower score pl think best checkpoint step cat dmar pl v3 metric json grep bleu val avg bleu val avg bleu val avg bleu val avg bleu val avg bleu best checkpoint step evaluate offline best checkpoint without truncation get val bleu make nearly certain number create save finetune py correct number saved path incorrect known issue workaround fix high priority suboptimal checkpoint saving huge productivity drain additional notes number logged wandb also low wrong one gpu number identical	2020-09-22 00:26:46	1600734406	resolved fixed	2aebf65241ab054df9256cc33d37236651691a48	1602070997	tests\checkpointing\test_model_checkpoint.py                                                                    
177	3600	Infinite hang when running `Trainer.test` after `Trainer.fit` with DDP	bug run trainer test running trainer fit distributed backend ddp system hang reproduce steps reproduce behavior run following script main py import o argparse import argumentparser pl example model lightning template import lightningtemplatemodel pytorch lightning import trainer seed everything seed everything def main args model lightningtemplatemodel var args trainer trainer argparse args args trainer fit model commented test complete otherwise hang trainer test model def run cli root dir o path dirname o path realpath file parent parser argumentparser add help false parser lightningtemplatemodel add model specific args parent parser root dir parser trainer add argparse args parser parser set default gpus args parser parse args main args name main run cli command line argument assuming gpus python main py gpus hidden dim max epoch distributed backend ddp running script cause program hang test phase expected behavior would expect trainer test complete rather hanging environment output collect env detail py cuda gpu geforce rtx ti geforce rtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os linux architecture elf processor x86 python version ubuntu smp sat sep utc pytorch version os ubuntu installed pytorch pip build command used compiling source python version cuda cudnn version gpu model configuration geforce rtx ti x2 list installed package output pip freeze absl py cachetools certifi chardet decorator fsspec future google auth google auth oauthlib grpcio idna importlib metadata markdown networkx numpy oauthlib packaging pillow pkg resource protobuf pyasn1 pyasn1 module pyparsing pytorch lightning pyyaml request request oauthlib rsa six tensorboard tensorboard plugin wit torch torchvision tqdm urllib3 werkzeug zipp additional context comment trainer fit everything work expected able pause execution hang running pycharm following stack frame main thread thread could get pause select selector py wait connection py poll connection py poll connection py get queue py worker loop worker py run process py bootstrap process py launch popen fork py init popen fork py popen context py popen context py start process py init dataloader py iter dataloader py run evaluation trainer py run test trainer py train test base backend py ddp train ddp backend py train ddp backend py fit trainer py wrapped fn state py test given model trainer py test trainer py wrapped fn state py main main py run cli main py main py	2020-09-22 01:50:07	1600739407	resolved fixed	d2a3d6aa8e8b69e6f373243bd25165a0963d7a53	1600808221	docs\source\multi_gpu.rst                                                                    
178	3619	ModelCheckpoint period should not always save on the first epoch	feature period work modelcheckpoint validation end epoch period save return e g period save epoch period save epoch period save epoch currently always run first epoch run every period epoch e g period save epoch period save epoch period save epoch would also allow period would never save save top k motivation want save checkpoint every period epoch current behaviour force always save first one	2020-09-23 02:00:38	1600826438	resolved fixed	3b2efe5b2afe664d88c9d5eda127774bba4cff4c	1601386605	CHANGELOG.md pytorch_lightning\callbacks\model_checkpoint.py tests\callbacks\test_model_checkpoint.py                                                                
179	3652	Creation of many data module instances incurs RecursionError	bug thank nice framework repeated hundred experiment time new instance single lightningdatamodule class recursionerror raised also found creating data module calling setup enough reproduce issue reproduce please look following code sample error message code sample import pytorch lightning pl class dummydm pl lightningdatamodule def setup self stage none pas name main max iters range max iters try dm dummydm dm setup except recursionerror print f recursionerror occured th iteration raise error message recursionerror occured th iteration traceback recent call last file test dm py line dm setup file workspace src venv lib python3 site package pytorch lightning core datamodule py line wrapped fn return fn args kwargs file workspace src venv lib python3 site package pytorch lightning core datamodule py line wrapped fn return fn args kwargs file workspace src venv lib python3 site package pytorch lightning core datamodule py line wrapped fn return fn args kwargs previous line repeated time file workspace src venv lib python3 site package pytorch lightning core datamodule py line wrapped fn fn name setup recursionerror maximum recursion depth exceeded comparison expected behavior code sample expected exit without output environment pytorch version e g pytorchlightning version os e g linux linux installed pytorch conda pip source pip build command used compiling source n python version cuda cudnn version gpu model configuration	2020-09-25 01:21:50	1600996910	resolved fixed	17c8c95fbc7b31f73671761430e86d881f6d6c6d	1601032190	pytorch_lightning\core\datamodule.py tests\core\test_datamodules.py                                                                  
180	3668	incorrect batch_sizes when Dataloader returns a dict with multiple tensors.	bug tracked batch size result object incorrect dataloader return dict multiple tensor reproduce create data loader return dict e g batch batcha tensor batchb tensor b entire batch size n n example batch size logged since len batch pytorch lightning pytorch lightning trainer evaluation loop py lines track batch size weighted average result obj isinstance output result result obj output track batch size len batch pytorch lightning pytorch lightning trainer training loop py lines track batch size weighted average result obj training step output track batch size len split batch expected behavior log correct batch size sure defined correct batch size multiple tensor expect tensor dict batch size maybe something like result obj isinstance batch dict batch batch list batch key result obj track batch size len batch	2020-09-26 15:38:17	1601134697	resolved fixed	b34c7add23553f10f6f0d7caf4177c67ee213f3a	1601947841	pytorch_lightning\core\step_result.py pytorch_lightning\loggers\tensorboard.py pytorch_lightning\trainer\evaluation_loop.py tests\base\boring_model.py tests\trainer\logging\test_train_loop_logging_1_0.py                                                            
181	367	setting gpus=-1 and gpus='-1' in Trainer give different behaviours	discovered looking code trainer constructor mention gpus however value passed accepted result different behaviour result gpus used use available gpus reproduce run model first setting trainer gpus parameter gpus used run model setting gpus available gpus used able set indicate gpus used believe useful behaviour issue function self parse gpu id gpus handling passed int implemented solution would implement equivalent logic happy submit pr	2019-10-14 05:21:19	1571030479	resolved fixed	2aba70e228b427b16e547e030ab3bbad736b5b00	1571821509	docs\Trainer\Distributed training.md pytorch_lightning\trainer\dp_mixin.py pytorch_lightning\trainer\trainer.py tests\test_models.py                                                              
182	3693	"Missing attribute ""training_step_output_for_epoch_end"""	used documentation way stopping training bath start method return beginning epoch titled attributeerror exception problem training loop py line batch output training step output epoch end code sample use method run code def batch start self batch return expected behavior check batch output value equal running trainin loop py line early stopping method achieved way documentation specifies throw exception rather simply stop training environment cuda gpu available false version none packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os windows architecture windowspe processor intel64 family model stepping genuineintel python version	2020-09-28 04:34:38	1601267678	resolved fixed	9942f3ebdf14d0139b1b156dd56662b425f3c777	1601668006	CHANGELOG.md docs\source\early_stopping.rst pytorch_lightning\trainer\training_loop.py tests\models\test_hooks.py                                                              
183	3778	training_step log requires that tbptt_reduce_fx is also set	bug training step log requires tbptt reduce fx also set code sample def training step self batch batch idx self log train loss loss step false epoch true sync dist true self log foo torch tensor self current epoch step false epoch true reduce fx max tbptt reduce fx max error commented return loss def validation step self batch batch idx issue self log bar torch tensor self global step step false epoch true reduce fx max error time output tr loss tensor foo tensor minimize tensor classmethod def reduce across time cl time output auto reduce across time tbptt meta time output meta result extra deprecate may need extra time output x pop extra none x time output result cl result recursive gather time output result recursive stack result k value result item k meta extra continue pick reduce fx k checkpoint early stop minimize tbptt reduce fx torch mean else tbptt reduce fx meta k tbptt reduce fx result k tbptt reduce fx value e runtimeerror calculate mean floating type got long instead venv lib python3 site package pytorch lightning core step result py runtimeerror expected behavior tbptt reduce fx required environment master commit	2020-10-01 22:03:07	1601589787	resolved fixed	89cc12311f5eaa7860d66bce9bfe3d93255f35b6	1601845825	pytorch_lightning\core\step_result.py tests\trainer\logging\test_train_loop_logging_1_0.py                                                                  
184	3780	auto_scale_batch_size doesnt use 'binsearch'	tried following still using power init model model litautoencoder init trainer trainer pl trainer auto scale batch size binsearch tune trainer fit model remove support bug	2020-10-02 01:21:06	1601601666	resolved fixed	f745c4a773fa9742a1c3cc9d051af0acbfe411ec	1601990009	docs\source\training_tricks.rst pytorch_lightning\tuner\tuning.py                                                                  
185	3797	Broken ddp_cpu backend	bug broken current master reproduce def test tmpdir import pytorch lightning pl trainer pl trainer default root dir tmpdir max epoch limit train batch limit val batch distributed backend ddp cpu model dummymodule linear layer mnist trainer fit model error e process terminated following error e traceback recent call last e file home carmocca project pylaia venv lib python3 site package torch multiprocessing spawn py line wrap e fn args e file home carmocca project pylaia venv src pytorch lightning pytorch lightning accelerator ddp cpu spawn backend py line ddp train e result self train test e file home carmocca project pylaia venv src pytorch lightning pytorch lightning accelerator base backend py line train test e result self trainer train e file home carmocca project pylaia venv src pytorch lightning pytorch lightning trainer trainer py line train e self run sanity check self get model e file home carmocca project pylaia venv src pytorch lightning pytorch lightning trainer trainer py line run sanity check e eval result self run evaluation test mode false max batch self num sanity val batch e file home carmocca project pylaia venv src pytorch lightning pytorch lightning trainer trainer py line run evaluation e output self evaluation loop evaluation step test mode batch batch idx dataloader idx e file home carmocca project pylaia venv src pytorch lightning pytorch lightning trainer evaluation loop py line evaluation step e output self trainer accelerator backend validation step args e file home carmocca project pylaia venv src pytorch lightning pytorch lightning accelerator ddp cpu spawn backend py line validation step e output self training step args e file home carmocca project pylaia venv src pytorch lightning pytorch lightning accelerator ddp cpu spawn backend py line training step e output self trainer model args e file home carmocca project pylaia venv lib python3 site package torch nn module module py line call impl e result self forward input kwargs e file home carmocca project pylaia venv src pytorch lightning pytorch lightning override data parallel py line forward e warn missing output fx called e file home carmocca project pylaia venv src pytorch lightning pytorch lightning override data parallel py line warn missing output e warning cache warn e unboundlocalerror local variable referenced assignment expected behavior fail	2020-10-02 15:05:18	1601651118	resolved fixed	22efce8f400ab452ad1369e6ec9e8e733cc9a93d	1601661062	pytorch_lightning\overrides\data_parallel.py                                                                    
186	3811	ModelCheckpoint not picking up metrics logged from lightning module	bug model checkpoint raise misconfiguration error metric logged validation epoch end mysteriously unavailable callback reproduce typing import optional import torch pytorch lightning import trainer lightningmodule pytorch lightning callback import modelcheckpoint torch utils data dataset import dataset class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class testmodule lightningmodule def init self epoch min loss override optional int none lightningmodule testing purpose args epoch min loss override int optional pass epoch set minimum validation loss testing purpose zero based none ignored defaults none super init self layer torch nn linear self epoch min loss override epoch min loss override def forward self x return self layer x def loss self batch prediction arbitrary loss loss update model weight trainer fit call return torch nn functional mse loss prediction torch one like prediction def training step self batch batch idx output self forward batch loss self loss batch output return output output loss loss checkpoint loss def validation step self batch batch idx output self forward batch loss self loss batch output return output output loss loss checkpoint loss def test step self batch batch idx output self forward batch loss self loss batch output return output output loss loss def training epoch end self output none avg loss torch stack x loss x output mean self log avg loss avg loss def validation epoch end self output none avg val loss torch stack torch randn requires grad true output mean testing purpose allow nominated epoch low loss self current epoch self epoch min loss override avg val loss self log avg val loss avg val loss self log checkpoint avg val loss def test epoch end self output none avg loss torch stack torch randn requires grad true output mean self log val loss avg loss def configure optimizers self optimizer torch optim sgd self layer parameter lr lr scheduler torch optim lr scheduler steplr optimizer step size return optimizer lr scheduler def train dataloader self return torch utils data dataloader randomdataset def val dataloader self return torch utils data dataloader randomdataset def test dataloader self return torch utils data dataloader randomdataset def train checkpoint callback modelcheckpoint save top k monitor avg val loss trainer trainer max epoch epoch min loss override logger false checkpoint callback checkpoint callback model testmodule epoch min loss override lightning trainer fit model error see raise misconfigurationexception pytorch lightning utility exception misconfigurationexception modelcheckpoint monitor avg val loss found returned metric avg loss hint call self log avg val loss tensor lightningmodule full stacktrace lightning trainer fit model file pytorch lightning trainer trainer py line fit result self accelerator backend train file pytorch lightning accelerator cpu backend py line train result self train test file pytorch lightning accelerator base backend py line train test result self trainer train file pytorch lightning trainer trainer py line train self train loop run training epoch file pytorch lightning trainer training loop py line run training epoch self trainer run evaluation test mode false file pytorch lightning trainer trainer py line run evaluation self evaluation loop evaluation end file pytorch lightning trainer evaluation loop py line evaluation end self trainer call hook validation end args kwargs file pytorch lightning trainer trainer py line call hook trainer hook args kwargs file pytorch lightning trainer callback hook py line validation end callback validation end self self get model file pytorch lightning callback model checkpoint py line validation end self save checkpoint trainer pl module file pytorch lightning callback model checkpoint py line save checkpoint self validate monitor key trainer file pytorch lightning callback model checkpoint py line validate monitor key raise misconfigurationexception pytorch lightning utility exception misconfigurationexception modelcheckpoint monitor avg val loss found returned trics avg loss hint call self log avg val loss tensor lightningmodule expected behavior save top checkpoint monitor based avg val loss environment based lightning git revision additional context	2020-10-03 01:14:40	1601687680	resolved fixed	d9bc95f83e163f1ef0e64012ad086d4448410817	1601742809	pytorch_lightning\callbacks\early_stopping.py pytorch_lightning\trainer\connectors\logger_connector.py pytorch_lightning\trainer\connectors\optimizer_connector.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\optimizers.py pytorch_lightning\trainer\training_loop.py tests\base\__init__.py tests\base\model_valid_epoch_ends.py tests\base\simple_model.py tests\callbacks\test_early_stopping.py tests\callbacks\test_model_checkpoint.py tests\core\test_datamodules.py tests\loggers\test_all.py tests\models\test_amp.py tests\models\test_restore.py tests\trainer\data_flow\__init__.py tests\trainer\data_flow\test_eval_loop_flow_1_0.py tests\trainer\data_flow\test_train_loop_flow_dict_1_0.py tests\trainer\data_flow\test_train_loop_flow_scalar_1_0.py tests\trainer\legacy_deprecate_flow_log_tests\__init__.py tests\trainer\legacy_deprecate_flow_log_tests\test_eval_loop_dict_return.py tests\trainer\legacy_deprecate_flow_log_tests\test_trainer_steps_dict_return.py tests\trainer\legacy_deprecate_flow_log_tests\test_trainer_steps_result_return.py tests\trainer\legacy_deprecate_flow_log_tests\test_trainer_steps_scalar_return.py tests\trainer\legacy_deprecate_flow_log_tests\test_validation_steps_result_return.py tests\trainer\logging\__init__.py tests\trainer\logging\test_eval_loop_logging_1_0.py tests\trainer\logging\test_train_loop_logging_1_0.py tests\trainer\test_optimizers.py tests\trainer\test_trainer.py          
187	3813	Calling module.log(...) within a callback fails	bug calling pl module log within callback fails even though recommended documentation error file callback file py line xx validation epoch end pl module log dict metric dict file home local usherbrooke pain5474 opt miniconda3 envs cav lib python3 site package pytorch lightning core lightning py line log dict self log file home local usherbrooke pain5474 opt miniconda3 envs cav lib python3 site package pytorch lightning core lightning py line log self result log file home local usherbrooke pain5474 opt miniconda3 envs cav lib python3 site package pytorch lightning core step result py line log self set meta file home local usherbrooke pain5474 opt miniconda3 envs cav lib python3 site package pytorch lightning core step result py line set meta internal self meta internal keyerror internal python baseexception cc nathanpainchaud happening master expected behavior log callback using lightning module environment happening pytorch lightning master	2020-10-03 05:59:48	1601704788	resolved fixed	3d202f9ecc4137b08cb5b1ac15af276456fcfaaf	1605114324	CHANGELOG.md pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py tests\models\test_hooks.py tests\trainer\legacy_deprecate_flow_log_tests\test_eval_loop_dict_return.py tests\trainer\logging\test_logger_connector.py tests\trainer\logging_tests\test_eval_loop_logging_1_0.py                                                    
188	3898	TypeError: expected str, bytes or os.PathLike object, not NoneType	bug summarizing source issue speedup fix line code pytorch lightning pytorch lightning accelerator ddp backend py line env copy pl global seed o environ get pl global seed env copy pl global seed none environment variable set none break subprocess popen pytorch lightning pytorch lightning accelerator ddp backend py line proc subprocess popen command env env copy cwd cwd fix moment add env copy pl global seed none del env copy pl global seed pytorch lightning pytorch lightning accelerator ddp backend py line env copy pl global seed o environ get pl global seed environment cuda gpu available false version packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os linux architecture processor x86 python version ubuntu smp wed apr utc	2020-10-06 10:39:25	1601980765	resolved fixed	e4a56fa5cfb5b67147c2013ae444ad0cd9a1b63a	1602001909	pytorch_lightning\accelerators\ddp_backend.py                                                                    
189	3906	Infinite recursion when calling `self.log(...)` in validation loop with dataset that returns string in item dict	bug sure behavior intended supported first place pr introduced regression passing string part data batch pas dictionary one value string fall infinite recursion loop trying log anything validation step reproduce see pr test reproduces bug current master test becomes functional commenting line call validation loop recursion happens specific statement unpack batch size elif isinstance sample iterable sample next iter sample size self unpack batch size sample recurses infinitely sample string full stacktrace get running test following test logging py pytorch lightning trainer trainer py fit result self accelerator backend train pytorch lightning accelerator cpu backend py train result self train test pytorch lightning accelerator base backend py train test result self trainer train pytorch lightning trainer trainer py train self run sanity check self get model pytorch lightning trainer trainer py run sanity check eval result self run evaluation test mode false max batch self num sanity val batch pytorch lightning trainer trainer py run evaluation step metric self evaluation loop log evaluation step metric batch batch idx pytorch lightning trainer evaluation loop py log evaluation step metric result track batch size batch pytorch lightning core step result py track batch size batch size self unpack batch size batch pytorch lightning core step result py unpack batch size size self unpack batch size sample pytorch lightning core step result py unpack batch size size self unpack batch size sample pytorch lightning core step result py unpack batch size size self unpack batch size sample e recursionerror maximum recursion depth exceeded comparison recursion detected local position code sample see see pr expected behavior able use string data returned dataset still able call self log validation loop environment cuda gpu titan xp available true version packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os linux architecture elf processor x86 python version ubuntu smp sat sep utc edit added reference draft pr	2020-10-06 16:35:46	1602002146	resolved fixed	c510a7f90077140d60c47adf8e1e73638c2d1017	1602012438	pytorch_lightning\core\step_result.py tests\base\boring_model.py tests\trainer\logging\test_train_loop_logging_1_0.py                                                                
190	394	ModelCheckpoint wipes out current directory	williamfalcon think seeing let create default callback use prefix end set current directory try clean previous checkpoint wipe everything current directory relevant bit code default save path set o getcwd modelcheckpoint fall back default save path modelcheckpoint blow away pre existing file checkpoint directory obvious fix provide better default checkpoint prefix would still lurking footgun user set default save path incorrectly maybe insist checkpoint directory exist training start empty	2019-10-18 23:21:11	1571440871	resolved fixed	9fa28066059c3bda0b022c33921796c7425cd41e	1572968519	pytorch_lightning\callbacks\pt_callbacks.py pytorch_lightning\logging\base.py pytorch_lightning\logging\mlflow_logger.py pytorch_lightning\logging\test_tube_logger.py pytorch_lightning\trainer\callback_config_mixin.py tests\test_y_logging.py                                                          
191	3945	Unexpected signature for validation_step	bug typeerror validation step take positional argument given full stacktrace test passing master reproduce typing import optional import unittest import torch pytorch lightning import lightningmodule torch utils data dataset import dataset class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class testmodule lightningmodule def init self epoch min loss override optional int none lightningmodule testing purpose args epoch min loss override int optional pass epoch set minimum validation loss testing purpose zero based none ignored defaults none super init self layer torch nn linear self epoch min loss override epoch min loss override def forward self x return self layer x def loss self batch prediction arbitrary loss loss update model weight trainer fit call return torch nn functional mse loss prediction torch one like prediction def training step self batch batch idx output self forward batch loss self loss batch output return output output loss loss checkpoint loss def validation step self batch batch idx output self forward batch loss self loss batch output return output output loss loss checkpoint loss def test step self batch batch idx output self forward batch loss self loss batch output return output output loss loss def training epoch end self output none avg loss torch stack x loss x output mean self log avg loss avg loss def validation epoch end self output none avg val loss torch stack torch randn requires grad true output mean testing purpose allow nominated epoch low loss self current epoch self epoch min loss override avg val loss self log val loss avg val loss self log checkpoint avg val loss def test epoch end self output none avg loss torch stack torch randn requires grad true output mean self log val loss avg loss def configure optimizers self optimizer torch optim sgd self layer parameter lr lr scheduler torch optim lr scheduler steplr optimizer step size return optimizer lr scheduler def train dataloader self return torch utils data dataloader randomdataset def val dataloader self return torch utils data dataloader randomdataset def test dataloader self return torch utils data dataloader randomdataset class testpl unittest testcase def test strict model load self model testmodule model layer torch nn linear checkpoint modelcheckpoint save top k monitor val loss trainer trainer checkpoint callback checkpoint logger logger overfit batch max epoch result trainer fit model expected behavior test crash trainer fit work	2020-10-07 16:53:58	1602089638	resolved fixed	6044cf900317ec9542fb1745976c9a96cc70b396	1602092787	pytorch_lightning\trainer\data_loading.py tests\trainer\flags\test_overfit_batches.py                                                                  
192	3974	[Bug]: Late update of Trainer `current_epoch` property for `LightningDataModule`	bug late update trainer current epoch property lightningdatamodule object reproduce code reproduces issue please check print log current epoch number train dataloader code sample import torch import torch nn nn import torch nn functional f torchvision import transforms torchvision datasets import mnist torch utils data import random split dataloader import pytorch lightning pl class litmodel pl lightningmodule def init self channel width height num class hidden size learning rate super init take input dimension parameter use dynamically build model self channel channel self width width self height height self num class num class self hidden size hidden size self learning rate learning rate self model nn sequential nn flatten nn linear channel width height hidden size nn relu nn dropout nn linear hidden size hidden size nn relu nn dropout nn linear hidden size num class def forward self x x self model x return f log softmax x dim def training step self batch batch idx x batch logits self x loss f nll loss logits return loss def configure optimizers self optimizer torch optim adam self parameter lr self learning rate return optimizer class mnistdatamodule pl lightningdatamodule def init self data dir str super init self data dir data dir self transform transforms compose transforms totensor transforms normalize self dims returned call dm size setting default dims know could optionally assigned dynamically dm setup self dims self num class def prepare data self download mnist self data dir train true download true mnist self data dir train false download true def setup self stage none assign train val datasets use dataloaders stage fit stage none mnist full mnist self data dir train true transform self transform self mnist train self mnist val random split mnist full assign test dataset use dataloader stage test stage none self mnist test mnist self data dir train false transform self transform def train dataloader self print n print f current epoch self trainer current epoch print self trainer current epoch return dataloader self mnist train batch size else return dataloader self mnist train batch size init datamodule dm mnistdatamodule init model datamodule attribute model litmodel dm size dm num class init trainer trainer pl trainer max epoch progress bar refresh rate gpus reload dataloaders every epoch true pass datamodule arg trainer fit override model hook trainer fit model dm log note current epoch two time indeed due late update property current epoch home nthere pytorch lightning pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs epoch loss v num current epoch epoch loss v num current epoch epoch loss v num current epoch epoch loss v num c home nthere pytorch lightning pytorch lightning utility distributed py userwarning detected keyboardinterrupt attempting graceful shutdown warning warn args kwargs epoch loss v num expected behavior current epoch updated reflect right epoch number lightningdatamodule environment please copy paste output environment collection script fill checklist manually get script run cuda gpu geforce gtx available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tqdm system os linux architecture elf processor x86 python version ubuntu smp fri jul utc	2020-10-08 04:31:02	1602131462	resolved fixed	fcfa5874923000a4b391c88b6488e065aee4d671	1602166855	CHANGELOG.md pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\core\test_datamodules.py                                                              
193	3993	Mismatch between docstring and code regarding when `on_load_checkpoint` hook is called	bug docstring load checkpoint hook say called trying load state dict pytorch lightning pytorch lightning core saving py lines cea5f1f def load checkpoint self checkpoint dict str none something checkpoint gives model chance load something state dict restored however lightningmodule load checkpoint called load state dict pytorch lightning pytorch lightning core saving py lines cea5f1f load state dict model automatically model load state dict checkpoint state dict strict strict give model chance load something model load checkpoint checkpoint additional context related discussion slack think docstring correct call load checkpoint moved right load state dict give model chance call setup	2020-10-08 15:07:54	1602169674	resolved fixed	a8573b005224bde87eb7a81ccdf5f428620c121f	1602212543	pytorch_lightning\core\saving.py                                                                    
194	4001	on_train_epoch_end and on_epoch_end are out of order	bug consider following order hook called confirmed pytorchlightning version still issue epoch start train epoch start validation start validation epoch start validation epoch end validation end epoch end train epoch end naturally one would expect opening closing scope hook match however train epoch end called epoch end seems incorrect natural open epoch scope train epoch scope done currently case epoch scope closed closing train epoch scope currently done pytorch version e g os e g linux ubuntu installed pytorch conda pip source pip build command used compiling source python version cuda cudnn version na gpu model configuration na relevant information na	2020-10-08 19:23:57	1602185037	resolved fixed	3777988502d1013508455a5fd34dc7d1a7e8e035	1603197226	pytorch_lightning\utilities\model_utils.py tests\models\test_hooks.py                                                                  
195	4011	Broken link in Documentation	documentation module index link bottom main page lightning documentation broken seems make html command create py modindex html file sure module index page required solution remove ref modindex index rst file additionally module index link link search page currently empty seeing searching possible sidebar sure page required could remove ref search well super familiar sphinx think break anything	2020-10-08 22:12:05	1602195125	resolved fixed	9e919763231d6f210f711515e496c953e6411a57	1602285048	docs\source\index.rst                                                                    
196	4020	Validation loss Tensor object is print in progress bar, it is expected only value	bug add validation loss progress bar training tensor object printed whereas loss value expected example epoch loss v num val loss tensor dtype torch float32 validation loss added following command self log val loss loss prog bar true tried self log val loss loss item prog bar true effect reproduce bug reproductible minimal code example see code sample validation step overridden code sample class testmodel boringmodel def validation step self batch batch idx output self layer batch loss self loss batch output self log val loss loss prog bar true return x loss expected behavior expected obtain value validation loss progress bar tensor object environment cuda gpu available false version none packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os darwin architecture processor i386 python version darwin kernel version thu jun pdt root xnu release x86	2020-10-09 08:30:30	1602232230	resolved fixed	bdbf84602973dc86a16f66d2902b22ee5a4c9f21	1602346811	CHANGELOG.md pytorch_lightning\trainer\connectors\logger_connector.py tests\trainer\logging\test_eval_loop_logging_1_0.py                                                                
197	403	Error when model checkpoint and no early stop	creating set get error line reproduce steps reproduce behavior create ckpt modelcheckpoint create trainer setting checkpoint callback ckpt early stop callback false see error attributeerror nonetype object attribute wait expected behavior possible save model without setting earlystopping condition course one could set earlystopping max integer changing condition solves problem desktop os ubuntu browser firefox quantum version	2019-10-21 12:28:38	1571660918	resolved fixed	e7c12d936e30aec96b1bf333ed9dc17c736dcc9e	1571764068	pytorch_lightning\trainer\trainer_io.py                                                                    
198	4073	Data Parallel bug (return outputs not being moved to same device)	bug backend dp handle reduction loss across multiple gpus correctly present v0 v1 reproduce code sample import torch import pytorch lightning ptl pytorch lightning import lightningmodule torch utils data import dataset class randomdictdataset dataset def init self size length self len length self data torch randn length size def getitem self index self data index b return b b def len self return self len class randomdictstringdataset dataset def init self size length self len length self data torch randn length size def getitem self index return id str index x self data index def len self return self len class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class boringmodel lightningmodule def init self testing pl module use follows subclass modify behavior want class testmodel basetestmodel def training step thing model basetestmodel model training epoch end none super init self layer torch nn linear def forward self x return self layer x def loss self batch prediction arbitrary loss loss update model weight trainer fit call return torch nn functional cross entropy prediction torch one len prediction dtype torch long device prediction device def training step self batch batch idx output self layer batch loss self loss batch output self log loss loss return loss def validation step self batch batch idx output self layer batch loss self loss batch output self log loss loss return loss def test step self batch batch idx output self layer batch loss self loss batch output return loss def configure optimizers self optimizer torch optim sgd self layer parameter lr lr scheduler torch optim lr scheduler steplr optimizer step size return optimizer lr scheduler def train dataloader self return torch utils data dataloader randomdataset batch size def val dataloader self return torch utils data dataloader randomdataset batch size def test dataloader self return torch utils data dataloader randomdataset batch size def main model boringmodel trainer ptl trainer distributed backend dp gpus trainer fit model name main main produces following gpu available true used true tpu available false using tpu core local rank cuda visible devices name type params layer linear home user conda envs env lib python3 site package pytorch lightning utility distributed py userwarning dataloader val dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs validation sanity check home user conda envs env lib python3 site package torch nn parallel function py userwarning asked gather along dimension input tensor scalar instead unsqueeze return vector warning warn asked gather along dimension home user conda envs env lib python3 site package pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs epoch traceback recent call last loss v num file dp bug py line main file dp bug py line main trainer fit model file home user conda envs env lib python3 site package pytorch lightning trainer trainer py line fit result self accelerator backend train file home user conda envs env lib python3 site package pytorch lightning accelerator dp accelerator py line train result self train test file home user conda envs env lib python3 site package pytorch lightning accelerator accelerator py line train test result self trainer train file home user conda envs env lib python3 site package pytorch lightning trainer trainer py line train self train loop run training epoch file home user conda envs env lib python3 site package pytorch lightning trainer training loop py line run training epoch self trainer run evaluation test mode false file home user conda envs env lib python3 site package pytorch lightning trainer trainer py line run evaluation eval loop result self evaluation loop log epoch metric deprecated eval result epoch log test mode file home user conda envs env lib python3 site package pytorch lightning trainer evaluation loop py line log epoch metric eval loop result self trainer logger connector evaluation epoch end file home user conda envs env lib python3 site package pytorch lightning trainer connector logger connector py line evaluation epoch end self log evaluation epoch end metric epoch log file home user conda envs env lib python3 site package pytorch lightning trainer connector logger connector py line log evaluation epoch end metric reduced epoch metric dl metric class reduce epoch end dl metric file home user conda envs env lib python3 site package pytorch lightning core step result py line reduce epoch end recursive stack result file home user conda envs env lib python3 site package pytorch lightning core step result py line recursive stack result k collate tensor v file home user conda envs env lib python3 site package pytorch lightning core step result py line collate tensor return torch stack item runtimeerror input tensor must device received cuda cuda exception ignored traceback recent call last file home user conda envs env lib python3 site package tqdm std py line del file home user conda envs env lib python3 site package tqdm std py line close file home user conda envs env lib python3 site package tqdm std py line display file home user conda envs env lib python3 site package tqdm std py line repr file home user conda envs env lib python3 site package tqdm std py line format dict typeerror unpack non iterable nonetype object specifically note line saying runtimeerror input tensor must device received cuda cuda expected behavior environment pytorch version e g os e g linux ubuntu installed pytorch conda pip source conda build command used compiling source n python version cuda cudnn version gpu model configuration gpu rtx relevant information additional context work v0 import torch import pytorch lightning ptl pytorch lightning import lightningmodule torch utils data import dataset class randomdictdataset dataset def init self size length self len length self data torch randn length size def getitem self index self data index b return b b def len self return self len class randomdictstringdataset dataset def init self size length self len length self data torch randn length size def getitem self index return id str index x self data index def len self return self len class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class boringmodel lightningmodule def init self testing pl module use follows subclass modify behavior want class testmodel basetestmodel def training step thing model basetestmodel model training epoch end none super init self layer torch nn linear def forward self x return self layer x def loss self batch prediction arbitrary loss loss update model weight trainer fit call return torch nn functional cross entropy prediction torch one len prediction dtype torch long device prediction device def training step self batch batch idx output self layer batch loss self loss batch output return loss loss def validation step self batch batch idx output self layer batch loss self loss batch output return val loss loss def test step self batch batch idx output self layer batch loss self loss batch output return test loss loss def configure optimizers self optimizer torch optim sgd self layer parameter lr lr scheduler torch optim lr scheduler steplr optimizer step size return optimizer lr scheduler def train dataloader self return torch utils data dataloader randomdataset batch size def val dataloader self return torch utils data dataloader randomdataset batch size def test dataloader self return torch utils data dataloader randomdataset batch size def main model boringmodel trainer ptl trainer distributed backend dp gpus log every n step flush log every n step benchmark true gradient clip val trainer fit model name main main cause error v1 gpu available true used true tpu available false using tpu core local rank cuda visible devices name type params layer linear home user conda envs env lib python3 site package pytorch lightning utility distributed py userwarning dataloader val dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs home user conda envs env lib python3 site package pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs epoch traceback recent call last file dp bug py line main file dp bug py line main trainer fit model file home user conda envs env lib python3 site package pytorch lightning trainer trainer py line fit result self accelerator backend train file home user conda envs env lib python3 site package pytorch lightning accelerator dp accelerator py line train result self train test file home user conda envs env lib python3 site package pytorch lightning accelerator accelerator py line train test result self trainer train file home user conda envs env lib python3 site package pytorch lightning trainer trainer py line train self train loop run training epoch file home user conda envs env lib python3 site package pytorch lightning trainer training loop py line run training epoch batch output self run training batch batch batch idx dataloader idx file home user conda envs env lib python3 site package pytorch lightning trainer training loop py line run training batch opt closure result self training step backward file home user conda envs env lib python3 site package pytorch lightning trainer training loop py line training step backward self backward result optimizer opt idx file home user conda envs env lib python3 site package pytorch lightning trainer training loop py line backward result closure loss self trainer accelerator backend backward file home user conda envs env lib python3 site package pytorch lightning accelerator accelerator py line backward model backward closure loss optimizer opt idx file home user conda envs env lib python3 site package pytorch lightning core lightning py line backward loss backward file home user conda envs env lib python3 site package torch tensor py line backward torch autograd backward self gradient retain graph create graph file home user conda envs env lib python3 site package torch autograd init py line backward grad tensor make grad tensor grad tensor file home user conda envs env lib python3 site package torch autograd init py line make grad raise runtimeerror grad implicitly created scalar output runtimeerror grad implicitly created scalar output exception ignored traceback recent call last file home user conda envs env lib python3 site package tqdm std py line del file home user conda envs env lib python3 site package tqdm std py line close file home user conda envs env lib python3 site package tqdm std py line display file home user conda envs env lib python3 site package tqdm std py line repr file home user conda envs env lib python3 site package tqdm std py line format dict typeerror unpack non iterable nonetype object	2020-10-11 11:59:57	1602417597	resolved fixed	f23f5e56480d1a4784fc7829d014590fe4ca1454	1607105407	CHANGELOG.md pytorch_lightning\core\step_result.py pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py tests\trainer\logging\test_logger_connector.py                                                            
199	4141	the self.log problem in validation_step()	doc say use self log last version loged data strange change evalresult self log epoch true check data tensorboard self log log result last batch epoch instead mean quite unreliable issue must turned back evalresult correct experiment	2020-10-14 09:57:48	1602669468	resolved fixed	45d05ff68dbf3db300a782af97ea54cab70a3ff9	1602767525	pytorch_lightning\core\step_result.py pytorch_lightning\trainer\connectors\logger_connector.py pytorch_lightning\trainer\evaluation_loop.py tests\core\test_metric_result_integration.py tests\trainer\logging\test_eval_loop_logging_1_0.py tests\trainer\logging\test_train_loop_logging_1_0.py                                                          
200	4188	To many backwards with LBFGS	bug using lbfgs one backward step much call backward optimiser step also gradient accumulation optimizer step get closure therefore call backward reproduce import torch import pytorch lightning ptl pytorch lightning import lightningmodule torch utils data import dataset class randomdictdataset dataset def init self size length self len length self data torch randn length size def getitem self index self data index b return b b def len self return self len class randomdictstringdataset dataset def init self size length self len length self data torch randn length size def getitem self index return id str index x self data index def len self return self len class randomdataset dataset def init self size length self len length self data torch randn length size def getitem self index return self data index def len self return self len class boringmodel lightningmodule def init self testing pl module use follows subclass modify behavior want class testmodel basetestmodel def training step thing model basetestmodel model training epoch end none super init self layer torch nn linear def forward self x return self layer x def loss self batch prediction arbitrary loss loss update model weight trainer fit call return torch nn functional cross entropy prediction torch one len prediction dtype torch long device prediction device def training step self batch batch idx output self layer batch loss self loss batch output self log loss loss return loss def validation step self batch batch idx output self layer batch loss self loss batch output self log loss loss return loss def test step self batch batch idx output self layer batch loss self loss batch output return loss def configure optimizers self optimizer torch optim lbfgs self parameter return optimizer def train dataloader self return torch utils data dataloader randomdataset batch size def val dataloader self return torch utils data dataloader randomdataset batch size def test dataloader self return torch utils data dataloader randomdataset batch size def main model boringmodel trainer ptl trainer distributed backend dp gpus trainer fit model name main main environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py cuda gpu geforce rtx ti geforce rtx ti available true version packages numpy pytorch debug false pytorch version pytorch lightning tqdm system os linux architecture elf processor x86 python version ubuntu smp preempt thu sep utc additional context probably fix passing closure optimisers consistent	2020-10-16 07:46:47	1602834407	resolved fixed	0ec410769744843726a140b7efabbeeb1c4e2929	1603305269	pytorch_lightning\accelerators\accelerator.py pytorch_lightning\core\lightning.py pytorch_lightning\trainer\training_loop.py tests\base\deterministic_model.py tests\trainer\data_flow\test_eval_loop_flow_1_0.py tests\trainer\data_flow\test_train_loop_flow_dict_1_0.py tests\trainer\data_flow\test_train_loop_flow_scalar_1_0.py tests\trainer\legacy_deprecate_flow_log_tests\test_eval_loop_dict_return.py tests\trainer\logging\test_eval_loop_logging_1_0.py tests\trainer\logging\test_train_loop_logging_1_0.py tests\trainer\optimization\test_backward_calls.py tests\trainer\test_trainer.py                                              
201	4208	AttributeError: 'Trainer' object has no attribute 'hpc_save'	bug getting following error slurm cluster attributeerror trainer object attribute hpc save environment pytorch	2020-10-17 17:12:40	1602954760	resolved fixed	66e58f5afb6ae8702b29ada52f7b022bbf201f9e	1603030436	pytorch_lightning\trainer\connectors\slurm_connector.py                                                                    
202	4229	Comet logger overrides COMET_EXPERIMENT_KEY env variable	changed logger behavior start using respect set already bug following already set variable logger overwrites value deletes variable way ignores variable deletes later moreover version function also ignores set variable create pull request fix	2020-10-19 10:49:14	1603104554	resolved fixed	4106e2f11292979022c437b9c49b0b3348f4682f	1603809056	pytorch_lightning\loggers\comet.py tests\loggers\test_comet.py                                                                  
203	4234	Values logged in test_epoch_end not returned when calling test()	bug calling test value logged test epoch end method returned lead following somewhat inconsistent behaviour values logged step method appear list returned test values logged step epoch end appear list returned test values logged epoch end value appear please reproduce using boringmodel post expected behavior value logged epoch end returned test environment pl version see colab	2020-10-19 14:34:45	1603118085	resolved fixed	c33688195964f7582011d10464cced0bc43fbe55	1603211598	pytorch_lightning\trainer\connectors\logger_connector.py tests\trainer\logging\test_eval_loop_logging_1_0.py                                                                  
204	4268	EarlyStopping mode auto is unknown, fallback to auto mode.	process refactoring upgraded lighting look like slight change callback interface code early stop callback pl callback earlystopping verbose true results message earlystopping mode auto unknown fallback auto mode earlystopping mode set min monitoring early stop default mode auto first message make sense	2020-10-21 00:06:22	1603238782	resolved fixed	2ffad4c89fcd19800a7532a8f7821578770451c6	1603304053	pytorch_lightning\callbacks\early_stopping.py                                                                    
205	427	save_weights_only parameter in ModelCheckpoint class look like doesn't work	common bug tensorboard showing jupyter notebook see issue pytorch v support see faq describe bug save weight parameter modelcheckpoint class look like work document describe save weight like save weight true model weight saved model save weight filepath else full model saved model save filepath save weight parameter save model differently different option reproduce steps reproduce behavior used sample script official document import o import torch torch nn import functional f torch utils data import dataloader torchvision datasets import mnist import torchvision transforms transforms import pytorch lightning pl class coolsystem pl lightningmodule def init self super coolsystem self init best model self l1 torch nn linear def forward self x return torch relu self l1 x view x size def training step self batch batch nb required x batch hat self forward x loss f cross entropy hat tensorboard log train loss loss return loss loss log tensorboard log def validation step self batch batch nb optional x batch hat self forward x return val loss f cross entropy hat def validation end self output optional avg loss torch stack x val loss x output mean tensorboard log val loss avg loss return avg val loss avg loss log tensorboard log def configure optimizers self required return multiple optimizers learning rate scheduler lbfgs automatically supported need closure function return torch optim adam self parameter lr pl data loader def train dataloader self required return dataloader mnist o getcwd train true download true transform transforms totensor batch size pl data loader def val dataloader self optional return dataloader mnist o getcwd train true download true transform transforms totensor batch size pl data loader def test dataloader self optional return dataloader mnist o getcwd train true download true transform transforms totensor batch size name main pytorch lightning import trainer pytorch lightning callback import modelcheckpoint weight path o path join o getcwd checkpoint o path exists weight path o mkdir weight path checkpoint callback modelcheckpoint filepath weight path save best false verbose true monitor val loss mode min prefix save weight false gpus torch cuda device count device torch device cuda torch cuda available else cpu model coolsystem model device trainer trainer checkpoint callback checkpoint callback max nb epoch train percent check trainer fit model changed save weight parameter weight directory saving model try restore weight example save model checkpoint directory trained move ckpt file directory like called test test directory two model file save weight true save weight false checking different using torch load path different two file parameter like save weight false epoch global step checkpoint callback best inf optimizer state state step exp avg tensor exp avg sq tensor step exp avg tensor exp avg sq tensor param group lr beta eps weight decay amsgrad false params lr scheduler state dict ordereddict l1 weight tensor l1 bias tensor save weight true epoch global step checkpoint callback best inf optimizer state state step exp avg tensor exp avg sq tensor step exp avg tensor exp avg sq tensor param group lr beta eps weight decay amsgrad false params lr scheduler state dict ordereddict l1 weight tensor l1 bias tensor expected behavior save weight true expected value like state dict ordereddict l1 weight tensor l1 bias tensor screenshots applicable add screenshots help explain problem desktop please complete following information os macbook pro inch mojave browser chrome version pytorch lightning torch post2 torchvision post2 test tube additional context try find reason save weight parameter work found traineriomixin class inside pytorch lightning feel save weight parameter implemented pytorch lightning	2019-10-24 17:39:22	1571938762	resolved fixed	8c4c7b105e16fbe255e4715f54af2fa5d2a12fad	1589721857	CHANGELOG.md pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\training_io.py tests\trainer\test_trainer.py                                                              
206	4275	[HOT-BUG] Checkpoint in callbacks list fails	bug please reproduce using boringmodel post modelcheckpoint properly setup provided list callback def test checkpoint within callback list tmpdir test validates checkpoint called provided callacks list o environ pl dev debug checkpoint callback modelcheckpoint monitor val loss filepath osp join tmpdir epoch class extendedboringmodel boringmodel def validation step self batch batch idx output self layer batch loss self loss batch output return val loss loss model extendedboringmodel model validation step end none model validation epoch end none trainer pl trainer max epoch limit train batch limit val batch limit test batch callback checkpoint callback trainer fit model assert o listdir tmpdir epoch ckpt test checkpointing test model checkpoint py pytorch lightning trainer trainer py fit result self accelerator backend train pytorch lightning accelerator cpu accelerator py train result self train test pytorch lightning accelerator accelerator py train test result self trainer train pytorch lightning trainer trainer py train self train loop run training epoch pytorch lightning trainer training loop py run training epoch self trainer run evaluation test mode false pytorch lightning trainer trainer py run evaluation self evaluation loop evaluation end pytorch lightning trainer evaluation loop py evaluation end self trainer call hook validation end args kwargs pytorch lightning trainer trainer py call hook trainer hook args kwargs pytorch lightning trainer callback hook py validation end callback validation end self self get model pytorch lightning callback model checkpoint py validation end self save checkpoint trainer pl module pytorch lightning callback model checkpoint py save checkpoint self save top k checkpoint monitor candidate trainer pl module epoch filepath pytorch lightning callback model checkpoint py save top k checkpoint self update best save filepath current epoch trainer pl module pytorch lightning callback model checkpoint py update best save self save model filepath trainer pl module self filepath private var folder q9 pytest thomas pytest test checkpoint within callbac0 epoch ckpt trainer pl module extendedboringmodel layer linear feature feature bias true def save model self filepath str trainer pl module debugging track save checkpoint trainer dev debugger track checkpointing history filepath make path trainer global zero self f makedirs o path dirname filepath exist ok true delegate saving trainer self save function none self save function filepath self save weight else raise valueerror save function set e valueerror save function set pytorch lightning callback model checkpoint py valueerror captured log call info lightning distributed py gpu available false used false info lightning distributed py tpu available false using tpu core info lightning lightning py name type params layer linear warning summary venv lib python3 site package comet ml monkey patching py users thomas documents project pytorch lightning venv lib python3 site package comet ml monkey patching py deprecationwarning imp module deprecated favour importlib see module documentation alternative us import imp venv lib python3 site package panda compat init py users thomas documents project pytorch lightning venv lib python3 site package panda compat init py userwarning could import lzma module installed python incomplete attempting use lzma compression result runtimeerror warning warn msg venv lib python3 site package wandb util py users thomas documents project pytorch lightning venv lib python3 site package wandb util py deprecationwarning using importing abcs collection instead collection abc deprecated since python stop working collection import namedtuple mapping sequence venv lib python3 site package wandb vendor graphql core graphql type directive py users thomas documents project pytorch lightning venv lib python3 site package wandb vendor graphql core graphql type directive py deprecationwarning using importing abcs collection instead collection abc deprecated since python stop working assert isinstance location collection iterable must provide location directive test checkpointing test model checkpoint py test checkpoint within callback list users thomas documents project pytorch lightning pytorch lightning utility distributed py userwarning dataloader val dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs test checkpointing test model checkpoint py test checkpoint within callback list users thomas documents project pytorch lightning pytorch lightning utility distributed py userwarning dataloader train dataloader many worker may bottleneck consider increasing value num worker argument try number cpu machine dataloader init improve performance warning warn args kwargs docs short test summary info failed test checkpointing test model checkpoint py test checkpoint within callback list valueerror save function set reproduce expected behavior environment please copy paste output environment collection script fill checklist manually get script run wget security purpose please check content collect env detail py running python collect env detail py pytorch version e g os e g linux installed pytorch conda pip source build command used compiling source python version cuda cudnn version gpu model configuration relevant information additional context	2020-10-21 07:54:54	1603266894	resolved fixed	8a20d6af51d13adec37593c1356ce08ef380e828	1603289202	pytorch_lightning\callbacks\model_checkpoint.py pytorch_lightning\trainer\connectors\callback_connector.py tests\checkpointing\test_model_checkpoint.py                                                                
207	4276	WandbLogger fails in 1.0.2 due to non-JSON serializable object	bug updating pl wandblogger fails following typeerror traceback recent call last file wandblogger issue py line wandb logger log hyperparams var args file home group mignot miniconda3 envs pl lib python3 site package pytorch lightning utility distributed py line wrapped fn return fn args kwargs file home group mignot miniconda3 envs pl lib python3 site package pytorch lightning logger wandb py line log hyperparams self experiment config update params allow val change true file home group mignot miniconda3 envs pl lib python3 site package wandb sdk wandb config py line update self callback data self dict file home group mignot miniconda3 envs pl lib python3 site package wandb sdk wandb run py line config callback self backend interface publish config data file home group mignot miniconda3 envs pl lib python3 site package wandb interface interface py line publish config cfg self make config config dict file home group mignot miniconda3 envs pl lib python3 site package wandb interface interface py line make config update value json json dump safer json friendly v file home group mignot miniconda3 envs pl lib python3 site package wandb util py line json dump safer return json dump obj cl wandbjsonencoder kwargs file home group mignot miniconda3 envs pl lib python3 json init py line dump kw encode obj file home group mignot miniconda3 envs pl lib python3 json encoder py line encode chunk self iterencode one shot true file home group mignot miniconda3 envs pl lib python3 json encoder py line iterencode return iterencode file home group mignot miniconda3 envs pl lib python3 site package wandb util py line default return json jsonencoder default self obj file home group mignot miniconda3 envs pl lib python3 json encoder py line default raise typeerror f object type class name typeerror object type function json serializable reproduce run following code snippet reproduce argparse import argumentparser pprint import pprint pytorch lightning import trainer pytorch lightning logger import wandblogger name main parser argumentparser parser trainer add argparse args parent parser parser args parser parse args pprint var args wandb logger wandblogger wandb logger log hyperparams var args expected behavior hyperparams logged usual without typeerror environment cuda gpu available false version packages numpy pytorch debug false pytorch version pytorch lightning tensorboard tqdm system os linux architecture processor x86 python version smp mon jul utc additional context pretty printing argument give following clue error accelerator none accumulate grad batch amp backend native amp level o2 auto lr find false auto scale batch size false auto select gpus false automatic optimization true benchmark false check val every n epoch checkpoint callback true default root dir none deterministic false distributed backend none fast dev run false flush log every n step gpus gradient clip val limit test batch limit train batch limit val batch log every n step log gpu memory none logger true max epoch max step none min epoch min step none num node num process num sanity val step overfit batch precision prepare data per node true process position profiler none progress bar refresh rate reload dataloaders every epoch false replace sampler ddp true resume checkpoint none sync batchnorm false terminate nan false tpu core track grad norm truncated bptt step none val check interval weight save path none weight summary top assume issue come gpus tpu core value function call explicitly supplied argument	2020-10-21 08:16:15	1603268175	resolved fixed	f07ee33db679a4b4bdcb4a2a221aa5cbb05d7b34	1603713423	.gitignore CHANGELOG.md pytorch_lightning\loggers\base.py pytorch_lightning\loggers\wandb.py tests\loggers\test_wandb.py                                                            
208	4304	TensorBoardLogger not working as expected with accumulate_grad_batches&gt;1	bug logging inside training step tensorboard using accumulate grad batch inside pl trainer behavior expected everything look good accumulate grad batch value reported step reproduce sorry using colab import o import torch torch nn import functional f torch utils data import dataloader random split import pytorch lightning pl pytorch lightning logger import tensorboardlogger torchvision datasets mnist import mnist torchvision import transforms class litclassifier pl lightningmodule def init self hidden dim learning rate super init self save hyperparameters self l1 torch nn linear self hparams hidden dim self l2 torch nn linear self hparams hidden dim def forward self x x x view x size x torch relu self l1 x x torch relu self l2 x return x def training step self batch batch idx x batch hat self x loss f cross entropy hat self log train loss loss return loss def validation step self batch batch idx x batch hat self x loss f cross entropy hat def configure optimizers self return torch optim adam self parameter lr self hparams learning rate def run test accumulate grad batch batch size num worker dataset mnist train true download true transform transforms totensor mnist train mnist val random split dataset train loader dataloader mnist train batch size val loader dataloader mnist val batch size model litclassifier trainer pl trainer logger tensorboardlogger o getcwd name bug accumulate grad batch accumulate grad batch max epoch trainer fit model train loader val loader run test run test expected behavior take mean value logged step environment pytorch version os linux installed pytorch conda python version tensorboard	2020-10-22 12:12:49	1603368769	resolved fixed	204a0a2d03ce7dfb014e347f1d34a49ef5e86902	1606333445	CHANGELOG.md pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py pytorch_lightning\trainer\trainer.py tests\loggers\test_all.py tests\loggers\test_tensorboard.py                                                            
209	4486	TrainerDataLoadingMixin.replace_sampler ignores multiprocessing_context	bug replace sampler trainerdataloadingmixin ignores multiprocessing context please reproduce using boringmodel post expected behavior return new data loader replaced sampler multiprocessing context environment cuda gpu tesla t4 available true version packages numpy pytorch debug false pytorch version cu101 pytorch lightning tqdm system os linux architecture processor x86 python version smp thu jul pdt	2020-11-02 19:19:18	1604344758	resolved fixed	dee968f20b89db7d6cbdd6069e5ed307980cbc86	1606481845	pytorch_lightning\trainer\data_loading.py tests\trainer\test_dataloaders.py                                                                  
210	4556	Gpu memory leak with self.log on_epoch=True	pl using new logging api want log metric lightningmodule self log step false epoch true dummy example sufficient add lightningmodule training step cause memory leak gpu could go wrong want log metric even cuda tensor could lead gpu memory leak well thanks magic metric epoch aggregation stuff let dig take look pytorch lightning pytorch lightning trainer training loop py lines b3db197 training step training step end batch output self run training batch batch batch idx dataloader idx returning train step end epoch early batch output signal break track output user implement training epoch end otherwise build unnecessary memory epoch end output self process train step output batch output training step output epoch end self early stopping accumulator self checkpoint accumulator hook todo add output batch self train batch end epoch output epoch end output batch batch idx dataloader idx run batch convert batch output epoch end output epoch set append epoch end output epoch output inside train batch end epoch output defined pytorch lightning pytorch lightning trainer training loop py line b3db197 epoch output range self num optimizers everything seems normal problem inside surprise loss value stored gpu think guess could go wrong store lot separate cuda tensor long long yeah gpu memory going end get famous runtimeerror cuda memory tried allocate mib gpu gib total capacity gib already allocated mib free gib reserved total pytorch loss appended output pytorch lightning pytorch lightning trainer training loop py lines b3db197 def process training step output self training step output split batch result self trainer get model result loss none hiddens none handle dict return isinstance training step output dict loss training step output pop loss none hiddens training step output pop hiddens none result extra training step output handle scalar return elif isinstance training step output torch tensor loss training step output result extra map result hood result minimize loss result hiddens hiddens track batch manual reduction result result track batch size len split batch track metric without grad epoch reduction training step output epoch end copy result training step output epoch end detach flow back system training step output result return training step output epoch end training step output first line get pretty result without loss line loss get appended start memory leak chain event affecting training lead error first epoch training got enough memory hold list gpu loss epoch exception subsequent epoch list loss get somewhere middle epoch course step epoch memory list gpu loss require one loss stored per step comparison task gpu could hold step memory error without see rapid growth first minute model loaded feeded batch difference subsequent minute former case list loss eats gpu memory lead crash latter nothing happens training go pretty cool one could eat time gpu memory actual training process	2020-11-06 19:52:04	1604692324	resolved fixed	514cb22bd719e6ca056cacce730c8de875c9dbf6	1605042821	pytorch_lightning\core\step_result.py pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py pytorch_lightning\utilities\memory.py                                                          
211	4681	self.log on validation_step is broken on pre 1.1 [nightly]		2020-11-15 01:41:54	1605404514	resolved fixed	867eef0e4c34e92887faee7040779e8cde00b20f	1605454893	pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py tests\trainer\logging_tests\test_eval_loop_logging_1_0.py                                                                
212	4781	Potential bug in metric when updated with a slice of tensor in DDP	bug metric updated slice tensor one input either pred target multiple gpu ddp throw error runtimeerror tensors must non overlapping dense slice tensor clone detach work please reproduce using boringmodel post issue reproduced reproduce expected behavior metric update work slice tensor environment cuda gpu tesla p100 pcie available true version packages numpy pytorch debug true pytorch version cu101 pytorch lightning tqdm system os linux architecture processor x86 python version smp thu jul pdt additional context	2020-11-20 03:55:48	1605844548	resolved fixed	1b40a4053d4b2116de02938b747946446443c54a	1607179785	CHANGELOG.md pytorch_lightning\utilities\distributed.py tests\metrics\test_ddp.py                                                                
213	4857	Logging not working in `on_train_batch_end` of a callback.	bug logging train batch end callback work train validation batch end e eval logged train class testcallback callback def train batch end self trainer pl module output batch batch idx dataloader idx pl module log train def validation batch end self trainer pl module output batch batch idx dataloader idx pl module log eval reproduce context found error logging training pl bolt callback ssl online sslonlineevaluator work	2020-11-25 16:44:23	1606322663	resolved fixed	2e838e6dd8803f40da3a1d4111669bd69ae7dd0f	1607259703	docs\source\logging.rst pytorch_lightning\trainer\connectors\logger_connector\epoch_result_store.py pytorch_lightning\trainer\connectors\logger_connector\logger_connector.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\test_deprecated.py tests\trainer\logging_tests\test_eval_loop_logging_1_0.py tests\trainer\logging_tests\test_train_loop_logging_1_0.py                                                    
214	4928	update min dependencies	bug pip install strategy change several package feasible install together reproduce see min ci config expected behavior update libs installable probably go one one list dependency dependency find minimal intersection	2020-12-01 08:19:47	1606810787	resolved fixed	563f9214fa4add3e984de993c231ac0ff2f4fca6	1606843184	.github\workflows\ci_test-full.yml requirements.txt requirements\extra.txt requirements\test.txt                                                              
215	4953	manual_optimization does not work with ddp	bug run ddp manual optimization fails second batch error runtimeerror expected mark variable ready error caused one following reason use module parameter outside forwardfunction please make sure model parameter shared across multiple concurrent forward backward passes2 reused parameter multiple reentrant backward pass example use multiplecheckpoint function wrap part model would result set parameter used different reentrant backward pass multiple time hence marking variable ready multiple time ddp support use case yet reproduce change optimization manual basic gan bolt expected behavior fail n gpus environment cuda gpu tesla v100 sxm2 tesla v100 sxm2 tesla v100 sxm2 tesla v100 sxm2 available true version packages numpy pytorch debug true pytorch version pytorch lightning tqdm system os linux architecture processor x86 python version smp tue sep edt additional context manual optimization working gans multi gpu regime useful applicaiton	2020-12-02 20:09:05	1606939745	resolved fixed	239347435029c0a02b305201ebbfa39d62746ca8	1607369514	benchmarks\test_sharded_parity.py pytorch_lightning\accelerators\accelerator.py pytorch_lightning\overrides\data_parallel.py pytorch_lightning\plugins\ddp_plugin.py pytorch_lightning\plugins\sharded_plugin.py pytorch_lightning\trainer\training_loop.py tests\special_tests.sh tests\trainer\optimization\test_manual_optimization.py                                                      
216	4974	AttributeError: 'LightningOptimizer' object has no attribute 'state'	using pytorch lightning adam optmiser train byol model model pipeline work fine training stop resume checkpoint raise error anything resume previous checkpoint idea error like upgrade bolt pytorch lightning mast think latest version opmizer like adam original adam provided pytorch	2020-12-04 15:02:39	1607094159	resolved fixed	7755572b4f37b811b83f6a933329b01af4735e66	1607694705	pytorch_lightning\core\optimizer.py pytorch_lightning\utilities\__init__.py requirements\extra.txt tests\core\test_lightning_module.py tests\core\test_lightning_optimizer.py tests\trainer\optimization\test_manual_optimization.py                                                          
217	4978	Fix pipy badges and images not rendering	seems work pypi page see rc open pkg info still see original path downloaded implemented	2020-12-04 16:21:42	1607098902	resolved fixed	e2c404bad2eaf90d77d2faf3d2802f783f8dc4f7	1607507984	.github\workflows\release-pypi.yml MANIFEST.in README.md pytorch_lightning\setup_tools.py                                                              
218	498	Escaping % in add_default_args	describe bug utility arg parse py percentage symbol escaped would cause error printing help information parser add argument overfit default type float help dataset use option float none reproduce steps reproduce behavior import o import random import sys pytorch lightning utility arg parse import add default args test tube import hyperoptargumentparser experiment name main root dir o path split o path dirname sys module main file parent parser hyperoptargumentparser strategy random search add help true add default args parent parser root dir hyperparams parent parser parse args execute file help python temp py help throws error warning root caffe2 python run gpu support run cpu mode traceback recent call last file users chenghaomou code ai2 temp py line hyperparams parent parser parse args file users chenghaomou anaconda envs elisa lib python3 site package test tube argparse hopt py line parse args result self parse args args namespace file users chenghaomou anaconda envs elisa lib python3 site package test tube argparse hopt py line parse args args argv self parse known args args namespace file users chenghaomou anaconda envs elisa lib python3 argparse py line parse known args namespace args self parse known args args namespace file users chenghaomou anaconda envs elisa lib python3 argparse py line parse known args start index consume optional start index file users chenghaomou anaconda envs elisa lib python3 argparse py line consume optional take action action args option string file users chenghaomou anaconda envs elisa lib python3 argparse py line take action action self namespace argument value option string file users chenghaomou anaconda envs elisa lib python3 argparse py line call parser print help file users chenghaomou anaconda envs elisa lib python3 argparse py line print help self print message self format help file file users chenghaomou anaconda envs elisa lib python3 argparse py line format help return formatter format help file users chenghaomou anaconda envs elisa lib python3 argparse py line format help help self root section format help file users chenghaomou anaconda envs elisa lib python3 argparse py line format help item help join func args func args self item file users chenghaomou anaconda envs elisa lib python3 argparse py line item help join func args func args self item file users chenghaomou anaconda envs elisa lib python3 argparse py line format help item help join func args func args self item file users chenghaomou anaconda envs elisa lib python3 argparse py line item help join func args func args self item file users chenghaomou anaconda envs elisa lib python3 argparse py line format action help text self expand help action file users chenghaomou anaconda envs elisa lib python3 argparse py line expand help return self get help string action params typeerror format integer required dict expected behavior escape percentage sign help printed desktop please complete following information os macos browser chrome version additional context add context problem	2019-11-12 18:37:49	1573583869	resolved fixed	89f7a82157297f32ca12283c0badbc5b50bb5224	1573643018	pytorch_lightning\utilities\arg_parse.py                                                                    
219	529	Training with DDP could fail at startup due to FileExistsError	multi gpu mode ddp starting training fail following error traceback recent call last file train py line main hyperparams file train py line main trainer fit model file home tanel miniconda3 lib python3 site package pytorch lightning trainer trainer py line fit mp spawn self ddp train nprocs self num gpus args model file home tanel miniconda3 lib python3 site package torch multiprocessing spawn py line spawn spawn context join file home tanel miniconda3 lib python3 site package torch multiprocessing spawn py line join raise exception msg exception process terminated following error traceback recent call last file home tanel miniconda3 lib python3 site package torch multiprocessing spawn py line wrap fn args file home tanel miniconda3 lib python3 site package pytorch lightning trainer ddp mixin py line ddp train self run pretrain routine model file home tanel miniconda3 lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self configure checkpoint callback file home tanel miniconda3 lib python3 site package pytorch lightning trainer callback config mixin py line configure checkpoint callback filepath ckpt path file home tanel miniconda3 lib python3 site package pytorch lightning callback pt callback py line init o makedirs filepath file home tanel miniconda3 lib python3 o py line makedirs mkdir name mode fileexistserror errno file exists home tanel devel torch xvectors lightning log version checkpoint happens quite rarely desktop please complete following information os linux version git fix easy create pr	2019-11-20 19:38:00	1574278680	resolved fixed	539d7bcb4476883771f0492b3a3774048de5163d	1574360859	pytorch_lightning\callbacks\pt_callbacks.py                                                                    
220	537	Summary not working for model on GPU with multiple inputs	describe bug want summary model requires multiple input parameter forward work set self example input array tuple code passing forward method however model cuda try pas move input directly cuda without check whether tuple list line error pytorch lightning blob master pytorch lightning root module memory py l53 example checked pytorch lightning blob master pytorch lightning root module memory py l61 reproduce steps reproduce behavior create model requires multiple input forward method set self example input array tuple run model gpu expected behavior list layer input output shape layer desktop please complete following information os linux mint browser chrome version official build bit	2019-11-21 15:44:20	1574351060	resolved fixed	d562172b4cd363b86f9d670120932cd333b03cf5	1575895327	pytorch_lightning\core\memory.py                                                                    
221	566	Using print_nan_grads in the Trainer results in an error	describe bug using print nan grad true trainer getting error trainer fit lstm model file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer trainer py line fit self run pretrain routine model file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer trainer py line run pretrain routine self train file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer train loop mixin py line train self run training epoch file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer train loop mixin py line run training epoch output self run training batch batch batch nb file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer train loop mixin py line run training batch self print nan gradient file users anaconda3 envs snorkel lib python3 site package pytorch lightning trainer training trick mixin py line print nan gradient torch isnan param grad float attributeerror nonetype object attribute float reproduce steps reproduce behavior param object grad object checked nan	2019-12-02 11:24:36	1575285876	resolved fixed	d4571d1d6f524b0b9284e84ea8f95bb8eb656c86	1575461098	pytorch_lightning\trainer\training_tricks_mixin.py                                                                    
222	604	failing Docs build	description sure happening seems documentation fails williamfalcon could pas detail documentation build	2019-12-07 22:15:17	1575756917	resolved fixed	ea59a99426c050cf301783f411c41a732af8c752	1579549831	.github\BECOMING_A_CORE_CONTRIBUTOR.md .github\ISSUE_TEMPLATE\bug_report.md .github\PULL_REQUEST_TEMPLATE.md .gitignore .readthedocs.yml MANIFEST.in README.md docs\source\_static\images\lightning_icon.svg docs\source\_static\images\lightning_logo-large.svg docs\source\_static\images\lightning_logo-name.svg docs\source\_static\images\lightning_logo.png docs\source\_static\images\lightning_logo.svg docs\source\_static\images\lightning_logo_medium.png docs\source\_static\images\lightning_logo_small.png docs\source\_templates\theme_variables.jinja docs\source\conf.py pl_examples\__init__.py pl_examples\basic_examples\lightning_module_template.py pl_examples\full_examples\imagenet\imagenet_example.py pytorch_lightning\__init__.py pytorch_lightning\callbacks\pt_callbacks.py pytorch_lightning\core\lightning.py pytorch_lightning\core\memory.py pytorch_lightning\core\root_module.py pytorch_lightning\testing\model_base.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\distrib_data_parallel.py pytorch_lightning\trainer\distrib_parts.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_io.py pytorch_lightning\trainer\training_loop.py pytorch_lightning\trainer\training_tricks.py setup.py tests\README.md
223	606	Early Stopping kicks in at min_epochs + 2 instead of min_epochs	describe bug working fix found early stopping start kick epoch despite min epoch reproduce run basic example gpu template py log callback call every epoch expected behavior setting min epoch n counting evaluate early stopping end epoch n proposed fix propose change line training loop epoch variable training loop start trainer argument min epoch start counting early stop check done end epoch hence epoch counter min epoch min epoch passed desktop please complete following information os linux version master	2019-12-08 00:30:41	1575765041	resolved fixed	e2ee4ddbdb75a91132394208fabc8c62ca39f3e9	1575916369	pytorch_lightning\trainer\training_loop.py                                                                    
224	618	Comet PAPI Depreciated	use comet api logger report unecessary depreciation warning relating use comet ml papi rather newer comet ml api example comet warning imported comet ml papi interface deprecated please use comet ml api instead information see	2019-12-10 08:43:52	1575967432	resolved fixed	d1633aac112fb35878aae83deb8b57259acea75b	1576023861	pytorch_lightning\logging\comet.py                                                                    
225	638	Pytorch lightning spawns processes after each epoch of training, causing training script to crash unexpectedly	bug running training script ptl noticed script running process spawning happening end every epoch reloads script unintended behavior often cause training crash middle changing code essentially lock script running edits possible fix create data loader object reproduce train ptl using ddp num worker place breakpoint top main file project	2019-12-19 12:52:41	1576759961	resolved fixed	3c2fd560aa4d31b4f48ee225b83361deec53d9c7	1584031643	CHANGELOG.md pytorch_lightning\core\grads.py pytorch_lightning\core\hooks.py pytorch_lightning\core\lightning.py pytorch_lightning\core\memory.py pytorch_lightning\core\saving.py                                                          
226	675	Mismatch of displayed 'epoch'	bug display epoch number mismatch progress bar checkpoint indicator wonder mismatch could confuse user progress bar number epoch start checkpoint indicator number epoch start metric csv also start think change checkpoint metric csv cause serious problem progress bar changed opinion think epoch batch idx loss train batch loss v num val loss ainfo root epoch val loss reached best saving model dummy version checkpoint ckpt epoch ckpt top loss train batch loss val loss epoch batch idx loss train batch loss v num val loss environment pytorch version os macos installed pytorch pip install git upgrade python version use cpu	2020-01-09 13:16:11	1578575771	resolved fixed	734b28ed2dcd0feb23b44744a3d3d40de0b20a08	1580897751	pytorch_lightning\callbacks\pt_callbacks.py pytorch_lightning\trainer\training_loop.py                                                                  
227	688	Checkpoint saving isn't atomic	bug saving checkpoint happens non atomically case cause incomplete write checkpoint example receiving sigkill writing causing subsequent loading fail runtimeerror unexpected eof expected byte file might corrupted reproduce difficult reproduce since relies timing outside code happens fast running model run second per epoch expected behavior checkpointing resistant issue instead simply continue	2020-01-15 15:42:14	1579102934	resolved fixed	9aad69d85635a8a65e1f0ee995516c0f8183c0f3	1579549904	pytorch_lightning\trainer\training_io.py                                                                    
228	694	JIT problem with `torchvision` 0.5	bug jit problem newly released freeze version future want support maybe temporal bug handle reproduce comment environment	2020-01-16 08:40:58	1579164058	resolved fixed	af445830506061680bd41744926c8bee1cca1104	1581392838	MANIFEST.in pl_examples\requirements.txt     requirements.txt tests\models\__init__.py tests\models\base.py tests\models\debug.py tests\models\mixins.py tests\models\utils.py tests\requirements.txt tests\test_amp.py tests\test_cpu_models.py tests\test_gpu_models.py tests\test_logging.py tests\test_restore_models.py tests\test_trainer.py                                    
229	703	Fitting with log_gpu_memory=True fails in python3.6.	bug fitting log gpu memory true trainer fails python3 version reproduce use python3 version create trainer log gpu memory true option fit see error pytorch lightning pytorch lightning core memory py get gpu memory map encoding utf capture output true check true convert line dictionary gpu memory int x x result stdout strip split o linesep usr lib python3 subprocess py run input timeout check popenargs kwargs kwargs stdin pipe popen popenargs kwargs process try stdout stderr process communicate input timeout timeout typeerror init got unexpected keyword argument capture output code sample trainer trainer log gpu memory true trainer fit expected behavior code error python3 environment pytorch ubuntu pytorch lightning installed pip environment commit python setup py develop version python cuda v10 cudnn gpu rtx ti additional context setup py python requires used calling valid python3 see also workaround maintain python3	2020-01-17 13:59:28	1579269568	resolved fixed	06242c200a318a37d1f882c786e60354ec04533f	1579549857	pytorch_lightning\core\memory.py                                                                    
230	704	TensorBoardLogger and ModelCheckpoint are not using the same folder by default	bug master branch default tensorboardlogger writes log lightning log modelcheckpoint writes checkpoint lightning log version	2020-01-17 16:17:56	1579277876	resolved fixed	de2ccc03a8df997b8841f33ae70050498960f08c	1579349873	pytorch_lightning\logging\tensorboard.py tests\test_logging.py                                                                  
231	708	LR Schedulers shouldn't get `epoch` argument in `step` function	bug pytorch lr scheduler get argument function see looks like call pytorchlightning line new interface see result unexpected lr change removing epoch argument step call solves issue environment pytorch pytorchlightning	2020-01-18 12:57:14	1579352234	resolved fixed	c58aab0b0024c36a9bd4d5a0a472c84b80edc61d	1582112255	pytorch_lightning\trainer\training_loop.py                                                                    
232	709	imagenet_example cannot run	bug imagenet example executed reproduce steps reproduce behavior download imagenet cd pl example full example imagenet python imagenet example py data path imagenet path error traceback recent call last file imagenet example py line main get args file imagenet example py line main model imagenetlightningmodel hparams typeerror instantiate abstract class imagenetlightningmodel abstract method forward expected behavior example run environment pytorch version debug build cuda used build pytorch os ubuntu lts gcc version ubuntu cmake version could collect python version cuda available yes cuda runtime version could collect gpu model configuration gpu geforce rtx ti nvidia driver version cudnn version could collect versions relevant library pip3 numpy pip3 pytorch lightning pip3 torch pip3 torchvision conda blas mkl conda mkl conda mkl service py37he904b0f conda mkl fft py37ha843d7b conda mkl random py37hd6b4f25 additional context suspect breaking change api example obsolete method forward expected	2020-01-19 02:35:32	1579401332	resolved fixed	eeb48ceb965f0cc140728676a3bb77e7271d9e35	1579642542	pl_examples\full_examples\imagenet\imagenet_example.py                                                                    
233	712	Trainer is setting parameters with requires_grad=False to requires_grad=True (bug)	bug training model parameter requires grad false trainer actually setting requires grad true parameter changing bug appears originate trainertrainloopmixin code reproduce steps reproduce behavior create model parameter requires grad false fit model using trainer check see parameter set requires grad false changed code sample reproduce bug import torch import numpy np import o torch nn import functional f torch utils data import dataloader import pytorch lightning pl make toy dataset feature torch numpy np asarray float target torch numpy np asarray train torch utils data tensordataset feature target train loader torch utils data dataloader train batch size shuffle true define lightning model class coolsystem pl lightningmodule def init self super coolsystem self init self l1 torch nn linear self l2 torch nn linear param self l2 parameter param requires grad false self loss func torch nn crossentropyloss def forward self x return self l2 torch relu self l1 x def training step self batch batch idx x batch hat self forward x loss self loss func hat tensorboard log train loss loss return loss loss log tensorboard log def configure optimizers self return torch optim adam self parameter lr pl data loader def train dataloader self return train loader run lightning model check parameter training coolsystem coolsystem print list coolsystem parameter trainer pl trainer min epoch max epoch logger false trainer fit coolsystem list coolsystem parameter expected behavior expected parameter requires grad false change training actual printed parameter training requires grad false training trainer parameter requires grad true changed value environment pytorch version linux pytorch installed pip python pytorch lightning think issue code snippet training loop py think causing issue class trainertrainloopmixin abc def run training batch self batch batch idx call training step per optimizer opt idx optimizer enumerate self optimizers make sure gradient current optimizer paramaters calculated training step prevent dangling gradient multiple optimizer setup param self get model parameter param requires grad false group optimizer param group param group params param requires grad true see params model set param requires grad true training batch	2020-01-19 20:18:08	1579465088	resolved fixed	a2b20b46bca5101627ed392aec17611ac0e97133	1579612167	pytorch_lightning\trainer\training_loop.py                                                                    
234	760	Test metrics not logging to Comet after training	bug testing model trainer test metric logged comet model previously trained using trainer fit training metric logged correctly code sample comet logger cometlogger trainer trainer logger comet logger model get model trainer fit model metrics logged comet trainer test model metric logged comet expected behavior test metric also logged comet environment pytorch version debug build cuda used build pytorch os ubuntu lts gcc version ubuntu cmake version version python version cuda available yes cuda runtime version gpu model configuration gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti gpu geforce gtx ti nvidia driver version cudnn version usr local cuda target x86 linux lib libcudnn versions relevant library pip3 numpy pip3 pytorch lightning pip3 torch pip3 torchvision conda could collect additional context believe issue caused end training routine called turn call inside logger object expect send information alternative create another trainer object another logger mean metric logged different comet experiment original issue solved using existingexperiment object form comet sdk solution seems little hacky cometlogger currently support kind experiment	2020-01-28 15:36:34	1580225794	resolved fixed	4ac9925dad71edda26db486795341f0b0ba4ed38	1582336068	pytorch_lightning\loggers\comet.py                                                                    
235	796	new profiler has failing tests	jeremyjordan tests fail osx test test profiler py test advanced profiler failed	2020-02-07 09:36:51	1581068211	resolved fixed	fc0ad03008f5b725814a9091dc6a874950f49b42	1581288517	tests\test_profiler.py                                                                    
236	850	Epoch end checkpoint restarts previous epoch	bug restarting training reloading model epoch checkpoint completed restarted rather beginning next expected behavior checkpoint upon epoch end saved restarting resume state start next epoch	2020-02-15 01:26:14	1581729974	resolved fixed	6e7dc9c2363779a12e8122ee1e2d470a0b0f013e	1582334839	pytorch_lightning\trainer\training_io.py tests\test_restore_models.py tests\test_trainer.py                                                                
237	922	Init'ing Dataloader calls get_train_dataloader	seems like code initializing dataloader call getting dataloader pytorch lightning pytorch lightning trainer data loading py line c00a8a1 exist iter dataset isinstance self get train dataloader dataset iterabledataset mean effort wrapping get dataloader sync barrier multi gpu tpu used first call result crash	2020-02-23 20:09:13	1582488553	resolved fixed	1015a0050621828c9e8af2c934e19c5c68d61a5e	1582601005	CHANGELOG.md docs\source\hooks.rst pl_examples\basic_examples\lightning_module_template.py pytorch_lightning\core\decorators.py pytorch_lightning\core\lightning.py pytorch_lightning\trainer\data_loading.py pytorch_lightning\trainer\evaluation_loop.py pytorch_lightning\trainer\model_hooks.py pytorch_lightning\trainer\trainer.py pytorch_lightning\trainer\training_loop.py tests\models\__init__.py tests\models\base.py tests\models\mixins.py tests\models\utils.py tests\test_cpu_models.py tests\test_gpu_models.py tests\test_restore_models.py tests\test_trainer.py                                  
238	939	logger is NoneType hence doesn't have any experiment or other functionality in a lightning module	bug trying use logging ability lightning hit wall default tensorboard logger seem stay uninitialized calling trainer fit model resulting crash everytime try log something reproduce create lightning module class simpleregressor pl lightningmodule use logger anywhere get kind stacktrace documents project metawatch metawatch notebook audio video interest simple regressor py configure optimizers self see required self logger experiment add hparams hidden layer size self hidden layer size linear layer size self linear layer size lstm layer self lstm layer attributeerror nonetype object attribute experiment code sample import pytorch lightning pl class simpleregressor pl lightningmodule def init self cuda false super simpleregressor self init self logger experiment add hparams hidden layer size expected behavior log described documentation environment pytorch version debug build cuda used build pytorch os microsoft windows pro gcc version could collect cmake version could collect python version cuda available yes cuda runtime version could collect gpu model configuration gpu geforce gtx nvidia driver version cudnn version could collect versions relevant library pip3 numpy pip3 pytorch lightning pip3 tinynumpy pip3 torch pip3 torchvision conda could collect additional context	2020-02-25 11:51:32	1582631492	resolved fixed	f5e0df390c6e1eaf11ad488e297aa2d383daa177	1582836846	docs\source\experiment_logging.rst pytorch_lightning\loggers\__init__.py pytorch_lightning\loggers\base.py pytorch_lightning\trainer\trainer.py                                                              
239	997	Precision=16 with TPUs bug	bug setting precision training tpu throw error reproduce see colab relavent stack trace exception device tpu str expected int traceback recent call last file usr local lib python3 dist package torch xla distributed xla multiprocessing py line start fn fn gindex args file usr local lib python3 dist package pytorch lightning trainer distrib part py line tpu train o environ xla use bf16 file usr lib python3 o py line setitem value self encodevalue value file usr lib python3 o py line encode raise typeerror str expected type value name typeerror str expected int fix needed casting string o environ xla use bf16 str environment collecting environment information pytorch version debug build cuda used build pytorch os ubuntu lts gcc version ubuntu cmake version version python version cuda available cuda runtime version gpu model configuration could collect nvidia driver version could collect cudnn version usr lib x86 linux gnu libcudnn versions relevant library pip3 numpy pip3 torch pip3 torchsummary pip3 torchtext pip3 torchvision conda could collect	2020-03-02 02:05:28	1583114728	resolved fixed	29cbc9e7230dd4c5e5e8e8ff789b838ed4a79e20	1583203865	pytorch_lightning\trainer\distrib_parts.py                                                                    
