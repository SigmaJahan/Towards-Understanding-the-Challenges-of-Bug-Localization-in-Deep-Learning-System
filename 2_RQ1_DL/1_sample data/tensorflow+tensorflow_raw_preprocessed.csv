id,bug_id,summary,description,report_time,report_timestamp,status,commit,commit_timestamp,files
0,10303,TensorflowDebugger does not dump Stack/Pack/Concat nodes,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command bazel version compiling source cuda cudnn version gpu model memory titan x pascal exact command reproduce import sys import tensorflow tf tensorflow python import debug tf debug base tf one dtype tf float32 name base stacked tf stack base base name stacked concat tf concat base base axis name concat session tf session session tf debug localclidebugwrappersession session session default re session run stacked concat print re describe problem using tensorflowdebugger stacked concated stacked concated node appear set dumped node run completed addition node fed node dumped,2017-05-30 21:37:53,1496180273,resolved fixed,6f36e6b27106fb4de065db18b9333a3c6c2fbb89,1497370310,tensorflow\docs_src\programmers_guide\debugger.md                                                            
1,10428,TensorBoard graph key does not match documentation,key tensorboard ui indicates reference edge single headed arrow documentation show double headed arrow moreover appears edge indicated reference edge ui according key fact edge example neither c tf constant name const share v tf variable name var share tf add c v name opvs1 tf add v c name opvs2 note tf add name opa include reference edge case key ui say,2017-06-04 12:59:01,1496581141,resolved fixed,65ce8c723da2da639af0f1dd237d50d2680a4cd9,1496786608,tensorflow\tensorboard\components\tf_graph\tf-graph-scene.html tensorflow\tensorboard\components\tf_graph_common\edge.ts tensorflow\tensorboard\components\tf_graph_common\scene.ts tensorflow\tensorboard\components\tf_graph_controls\tf-graph-controls.html                                                      
2,10519,tf.contrib.data: tf-slim training pipeline gets stuck,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux leto28 amd64 smp debian deb8u2 x86 gnu linux version id version jessie tensorflow installed source binary binary tensorflow version use command tf version rc2 tf git version v1 rc1 gce1d6ec tf compiler version v1 rc1 gce1d6ec bazel version compiling source none cuda cudnn version gpu model memory titan x pascal exact command reproduce python mwe py describe problem recently ported dataset handling new dataset api seems training pipeline stall request cpus job used work fine dataset api provided work grab cpus tried come mwe see interesting thing getting stuck remove one line suspect issue related source code log import o import tensorflow tf import tensorflow contrib data tcd import tensorflow contrib slim slim tensorflow contrib data python ops dataset ops import get file name dataset dir path dataset file pattern shape tfrecord image shape def parse function example proto feature image encoded tf fixedlenfeature tf string default value image annotation color tf fixedlenfeature tf int64 default value image annotation shape tf fixedlenfeature tf int64 default value parsed feature tf parse single example example proto feature image decoded tf image decode image parsed feature image encoded color parsed feature image annotation color shape parsed feature image annotation shape return image decoded color shape def get batch batch size group size split name train file pattern o path join dataset dir file pattern format split name file name get file name file pattern randomize input true dataset tcd tfrecorddataset file name dataset dataset map parse function dataset dataset map lambda image color shape image dataset dataset shuffle buffer size dataset dataset repeat batch group size batch size iterator dataset make one shot iterator image iterator get next image tf split image group size axis image tf reshape x batch size image shape x image return image name main tf graph default x x x get batch batch size group size val tf reduce sum tf add n x x x val tf print val tf constant alive global step slim get create global step tf control dependency val update global step op tf assign add global step train op update global step op tf summary scalar summary val tf summary scalar summary train op logdir mwe logdir slim learning train train op train op logdir logdir number step,2017-06-08 03:26:09,1496892369,resolved fixed,f5fcd1fdcf896f46aed03c7e61525b48b75d1acc,1497474571,tensorflow\contrib\data\python\kernel_tests\iterator_ops_test.py tensorflow\core\kernels\iterator_ops.cc                                                          
3,10641,bug: BeamSearchDecoder should not assume that  when time &gt; 0 beam will be full,score flat control flow ops cond time lambda array ops reshape score batch size lambda score num available beam control flow ops cond time lambda math ops reduce prod score shape lambda math ops reduce prod score shape pick next beam according specified successor function next beam size math ops minimum ops convert tensor beam width dtype dtypes int32 name beam width num available beam next beam score word index nn ops top k score flat k next beam size next beam score set shape static batch size beam width word index set shape static batch size beam width code start correct wrong think code assuming time beam full true vocabulary big case machine translation vocabulary small beam might full time might pose problem value next beam size code seems must beam width raise error since next beam score set shape static batch size beam width make next beam size math ops minimum useless trying write pointer network beamsearch decoder modifying source file vocabulary usually small possibility time beam fully filled appreciate finally one wrote general beamseach decoder make life easier,2017-06-12 02:16:00,1497233760,resolved fixed,be1b702ff357e851eb4a7237728d80fe08220816,1516485976,tensorflow\contrib\seq2seq\python\kernel_tests\beam_search_decoder_test.py tensorflow\contrib\seq2seq\python\ops\beam_search_decoder.py                                                          
4,10729,tf.nn.max_pool wrong docs?,system information applicable describe problem api state ksize length size window dimension input tensor however value tensor mean ksize length stride digging maxpooling op cc show check line op requires context ksize size error invalidargument sliding window ksize field must specify dimension,2017-06-15 10:33:01,1497522781,resolved fixed,d4a21196ac06e49f2581e27af62efc4efd5387c4,1501794300,tensorflow\python\ops\nn_ops.py                                                            
5,10741,[go] bug in Shape.size for dim == NumDimensions,system information matter describe problem go dim equal numdimensions function return instead panic source code log shape go method func shape size dim int int64 dim numdimensions return func shape size dim int int64 dim numdimensions return,2017-06-15 20:21:34,1497558094,resolved fixed,76a0a15cb90c370e41766d124a7a11b28c18089a,1497637289,tensorflow\go\shape.go                                                            
6,11016,map_func of tf.contrib.data.Dataset.map gets dict keys instead of values when the nested structure of Dataset is dict,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary source tensorflow version use command b g1111e06d9 rc2 bazel version compiling source cuda cudnn version gpu model memory describe problem nested structure call map func nested args pas key instead component dataset seems need passed could transform element dataset source code log import tensorflow tf def foo args kwargs print args kwargs b return tf contrib data dataset tensor b map foo,2017-06-23 17:16:38,1498238198,resolved fixed,9b11f458196f6f0528c9974238497a6c8b6da547,1498760112,tensorflow\contrib\data\python\kernel_tests\bucketing_test.py tensorflow\contrib\data\python\kernel_tests\filter_dataset_op_test.py tensorflow\contrib\data\python\kernel_tests\flat_map_dataset_op_test.py tensorflow\contrib\data\python\kernel_tests\map_dataset_op_test.py tensorflow\contrib\data\python\ops\dataset_ops.py tensorflow\contrib\data\python\util\nest.py tensorflow\contrib\data\python\util\nest_test.py                                                
7,11017,Tfdbg does not work with Coordinator/QueueRunners,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux mint tensorflow installed source binary binary pip tensorflow version use command v1 rc2 g12f033d bazel version compiling source n cuda cudnn version n gpu model memory n exact command reproduce n describe problem tensorflow debugger seem working queues data never seems fetched queuerunner thread file using tf tfrecordreader tf parse single example preloaded using tf train slice input producer instead coordinator stop true right away case wrapping session tf python debug localclidebugwrappersession example make thing clearer moreover another error occurs coordinator join thread aware faq entry threads explain data fetching thread would working source code log make easiest replicate simply took example working preloaded data wrapped session debugger uploaded gist two line added reproduce run file drop debugger run exit full output extracting tmp data train image idx3 ubyte gz extracting tmp data train label idx1 ubyte gz extracting tmp data t10k image idx3 ubyte gz extracting tmp data t10k label idx1 ubyte gz traceback recent call last file ex py line tf app run main main argv sys argv unparsed file home ruben anaconda3 lib python3 site package tensorflow python platform app py line run sys exit main sys argv flag passthrough file ex py line main run training file ex py line run training coord join thread file home ruben anaconda3 lib python3 site package tensorflow python training coordinator py line join six reraise self exc info raise file home ruben anaconda3 lib python3 site package six py line reraise raise value file home ruben anaconda3 lib python3 site package tensorflow python training queue runner impl py line run enqueue callable sess make callable enqueue op attributeerror localclidebugwrappersession object attribute make callable stacktrace coord join thread possible coord stop never seems false would indicate data load without added debugger line example simply work,2017-06-23 17:18:55,1498238335,resolved fixed,41bc76d28b8b301c546cc5624abd37fd8b97b64c,1499304123,tensorflow\python\client\session.py tensorflow\python\client\session_test.py tensorflow\python\debug\cli\cli_shared.py tensorflow\python\debug\wrappers\framework.py tensorflow\python\debug\wrappers\framework_test.py tensorflow\python\debug\wrappers\local_cli_wrapper.py tensorflow\python\debug\wrappers\local_cli_wrapper_test.py tensorflow\tools\api\golden\tensorflow.-interactive-session.pbtxt tensorflow\tools\api\golden\tensorflow.-session.pbtxt                                            
8,11091,tf.nn.elu: incorrect second derivative,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command bazel version compiling source n cuda cudnn version cuda cudnn gpu model memory gtx ti exact command reproduce see tf nn elu give incorrect second derivative consider graph elu x x tf placeholder tf float32 tf nn elu x evaluating x x evaluate first derivative automatic differentiation dy tf gradient x dy eval x x line analytic answer x however second derivative ddy tf gradient dy x ddy eval x x whoops look right analytically derivative x evaluated x workaround case anyone else need work around fixed def elu x return tf x x tf exp x looks like second derivative work,2017-06-27 20:57:44,1498597064,resolved fixed,e121535a7d04cfc7c7dbb09d8694c01eb29da26f,1499716354,tensorflow\python\kernel_tests\relu_op_test.py tensorflow\python\ops\nn_grad.py                                                          
9,11132,Go: SIGABRT when executing the same node more than once,problem go pas node fetch list sigabrt raised source code log package poc test import fmt tf github com tensorflow tensorflow tensorflow go github com tensorflow tensorflow tensorflow go op testing func testfunc testing create root scope root op newscope define graph create constant matrix op const root subscope int32 create constant column vector b op const root subscope b int32 create matmul operation mul op matmul root subscope matmul b finalize graph graph root finalize create session var sess tf session sess tf newsession graph tf sessionoptions run var result tf tensor var err error result err sess run nil tf output mul mul nil err nil errorf err error fmt println result value output go test poc test go tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name geforce gtx ti major minor memoryclockrate ghz pcibusid total memory free memory w tensorflow stream executor cuda cuda driver cc non primary context exists initializing streamexecutor verified streamexecutor work tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name geforce gtx major minor memoryclockrate ghz pcibusid total memory free memory tensorflow core common runtime gpu gpu device cc peer access supported device ordinal tensorflow core common runtime gpu gpu device cc peer access supported device ordinal tensorflow core common runtime gpu gpu device cc dma tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name geforce gtx ti pci bus id tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name geforce gtx pci bus id f tensorflow c c api cc check failed nelems v sigabrt abort pc sigcode signal arrived cgo execution goroutine syscall locked thread runtime cgocall usr lib go src runtime cgocall go fp sp github com tensorflow tensorflow tensorflow go cfunc tf sessionrun github com tensorflow tensorflow tensorflow go obj cgo gotypes go fp sp github com tensorflow tensorflow tensorflow go session run func1 home pgaleone project go src github com tensorflow tensorflow tensorflow go session go fp sp github com tensorflow tensorflow tensorflow go session run home pgaleone project go src github com tensorflow tensorflow tensorflow go session go fp sp command line argument test testfunc home pgaleone project go src github com galeone asd poc test go fp sp testing trunner usr lib go src testing testing go fp sp runtime goexit usr lib go src runtime asm amd64 fp sp created testing run usr lib go src testing testing go goroutine chan receive testing run usr lib go src testing testing go testing runtests func1 usr lib go src testing testing go testing trunner usr lib go src testing testing go testing runtests usr lib go src testing testing go testing run usr lib go src testing testing go main main command line argument test testmain go goroutine syscall locked thread runtime goexit usr lib go src runtime asm amd64 rax rbx rcx rdx rdi rsi rbp rsp r8 r9 r10 r11 r12 r13 r14 r15 rip rflags c f g fail command line argument logic python work without issue import tensorflow tf tf constant b tf constant mul tf matmul b tf session sess print sess run mul mul output array dtype int32 array dtype int32 expected system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu archlinux tensorflow installed source binary source tensorflow version use command bazel version compiling source cuda cudnn version cuda cudnn gpu model memory geforce gtx exact command reproduce go test,2017-06-29 08:49:31,1498726171,resolved fixed,66604b0355b32961f9a532792be2e008cc22221f,1499315740,tensorflow\core\common_runtime\direct_session.cc tensorflow\core\common_runtime\direct_session_test.cc tensorflow\core\distributed_runtime\rpc\grpc_session.cc tensorflow\core\distributed_runtime\rpc\grpc_session_test.cc                                                      
10,11411,Fetching data in Distributed Tensorflow has too much latency,system information written custom code opposed using stock example script provided tensorflow simple benchmark test overhead distributed tf fetch configurable sized variable parameter server matmul worker also matmul locally stored variable worker time difference two operation would overhead measuring os platform distribution e g linux ubuntu linux redhat tensorflow installed source binary source tensorflow version use command tensorflow python version python exact command reproduce python matmul benchmark py num feature batch size num hidden job name p python matmul benchmark py num feature batch size num hidden job name worker increasing batch size timing difference local remote computation eventually becomes negligible however small batch size overhead become example two run different model dataset size feature batch size hidden layer size return local gemm time network fetch gemm time feature batch size hidden layer size return local gemm time network fetch gemm time describe problem distributed tensorflow introduces overhead due communication stack overhead mean additional time required worker receive data parameter server compared computation without fetching remote data problem due overhead use node provide performance par non distributed single process tensorflow number node required par single process tf increase use gpus fetching small variable provides constant overhead limit scaling efficiency overhead creates two issue distributed tensorflow add several worker equal performance single process overhead fetching model parameter scale amount computation decrease add worker thus get moderately small batch size worker scale constant overhead fetching remote model parameter several issue posted distributed tensorflow improvement large tensor transfer problem exists small tensor might caused cpu performance bottleneck network however problem network transfer definitely bottleneck tried using rdma seen minimal benefit source code log,2017-07-10 15:50:23,1499701823,resolved fixed,11e2aef14f7f2d862363c350ca1d67b87ea6a57b,1502294292,configure.py tensorflow\BUILD tensorflow\c\c_api.cc tensorflow\contrib\gdr\BUILD tensorflow\contrib\gdr\README.md tensorflow\contrib\gdr\gdr.proto tensorflow\contrib\gdr\gdr_memory_manager.cc tensorflow\contrib\gdr\gdr_memory_manager.h tensorflow\contrib\gdr\gdr_rendezvous_mgr.cc tensorflow\contrib\gdr\gdr_rendezvous_mgr.h tensorflow\contrib\gdr\gdr_server_lib.cc tensorflow\contrib\gdr\gdr_server_lib.h tensorflow\contrib\gdr\gdr_worker.cc tensorflow\contrib\gdr\gdr_worker.h tensorflow\core\BUILD tensorflow\core\common_runtime\gpu\gpu_device.cc tensorflow\core\common_runtime\gpu\process_state.cc tensorflow\core\distributed_runtime\rpc\grpc_remote_worker.cc tensorflow\core\distributed_runtime\rpc\grpc_server_lib.cc tensorflow\core\distributed_runtime\rpc\grpc_server_lib.h tensorflow\core\distributed_runtime\rpc\grpc_worker_service.h tensorflow\core\platform\default\build_config.bzl tensorflow\core\platform\default\build_config_root.bzl tensorflow\python\BUILD tensorflow\tools\pip_package\build_pip_package.sh            
11,11692,A bug of tf.reduce_logsumexp with `-inf`,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux centos tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source cuda cudnn version gpu model memory tesla k40m exact command reproduce python c import tensorflow tf print tf session run tf reduce logsumexp float inf describe problem doc tf reduce logsumexp say computes log sum exp element across dimension tensor however tensor inf source code log python c import tensorflow tf print tf session run tf reduce logsumexp float inf print nan python c import tensorflow tf print tf session run tf log tf reduce sum tf exp float inf print inf,2017-07-23 15:20:45,1500823245,resolved fixed,30c13a450841b213d72dea93d9447a25169be0a7,1502222488,tensorflow\python\ops\math_ops.py tensorflow\python\ops\math_ops_test.py                                                          
12,11725,tf_cnn_benchmarks.py stuck when running with multiple GPUs and ImageNet data with protocol grpc+verbs,system information written custom code opposed using stock example script provided tensorflow running tf cnn benchmark py benchmark repo os platform distribution e g linux ubuntu ubuntu lts tensorflow installed source binary unmodified source rdma verbs enabled tensorflow version use command rc0 python version bazel version compiling source cuda cudnn version gpu model memory nvidia tesla p100 pcie per node exact command reproduce ps cuda visible devices python tf cnn benchmark py p host worker host batch size model inception3 variable update parameter server local parameter device cpu job name p task index server protocol grpc verb worker0 cuda visible devices python tf cnn benchmark py p host worker host batch size model inception3 variable update parameter server local parameter device cpu job name worker task index num gpus data dir data imagenet data train dir data imagenet train server protocol grpc verb worker1 cuda visible devices python tf cnn benchmark py p host worker host batch size model inception3 variable update parameter server local parameter device cpu job name worker task index num gpus data dir data imagenet data train dir data imagenet train server protocol grpc verb rdma driver version mlnx ofed linux describe problem running command inception v3 synchronized data parallelism training worker external p tf cnn benchmark application hang forever iteration usually warm happens real data involved imagenet gpus gpus le iteration hang happen grpc protocol running synthetic data master service worker stuck guess mean operation computation completed rdma protocol look valid clean message corresponds protocol see log tensor requested worker receive passed rdma verbs transport baserendezvoudmgr recvlocalasync valid way reason higher level worker service trigger send kernel tensor help much appreciated debug mechanism use understand tensor operation completed greatly help mostly debugging rdma verbs layer till without much success feel enough information understand missing also feel enough knowledge step id act diving code higher level documentation greatly help initial guess occurrence racy condition loading data since creates gap execution time worker0 start first training step second worker1 since preprocessing data twice reason understand yet first iteration usually pass successfully time synchronized worker source code log log runtime moving logging rdma cc vlog also adding tensor name step id case case step id mean anything like buffer request response example also vlog master session cc worker0 worker1 p unfortunately fairly large better cut log file imo example analysis verb layer comparing sent tensor request actual received tensor writes worker worker job p replica task cpu f3c10d28b54074c0 job worker replica task gpu edge group deps noop job worker replica task cpu job worker replica task gpu edge group deps noop job worker replica task gpu job worker replica task gpu edge group deps noop job worker replica task gpu b07185dd19f62088 job worker replica task gpu edge group deps noop worker job p replica task cpu f3c10d28b54074c0 job worker replica task cpu edge assignadd job worker replica task gpu f3df8abf03739fe8 job worker replica task cpu edge group deps tensor request received well side passed recvlocalasync called later thanks lot,2017-07-24 20:01:58,1500926518,resolved fixed,e650dcfb462a9efc9236e33cae87ac5bbf55d9f7,1503550627,tensorflow\contrib\verbs\rdma.cc tensorflow\contrib\verbs\rdma.h tensorflow\contrib\verbs\rdma_rendezvous_mgr.cc tensorflow\contrib\verbs\verbs_util.cc tensorflow\contrib\verbs\verbs_util.h                                                    
13,11829,Slow to import tensorflow.contrib with Python 3 because inspect.stack is slow,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos sierra tensorflow installed source binary source tensorflow version use command v1 g2b4a0f9a4 rc0 python version bazel version compiling source homebrew cuda cudnn version cpu build gpu model memory cpu build exact command reproduce time python3 c import tensorflow contrib problem import tensorflow contrib take second machine python python take second investigating revealed lot time spent inspect stack function make decorator python util tf decorator py stack inspected find name caller function python2 inspect stack fast python call inspect stack take approximately second call made account difference time python references keras default import tensorflow contrib tensorflow backend used therefore keras slow import using python kera team kera stackoverflow question referencing issue,2017-07-27 22:21:25,1501194085,resolved fixed,d42ca5a1462e75e80536aa9c46c6834bd9455f2b,1505680691,tensorflow\python\util\tf_decorator.py                                                            
14,11948,Memory leak in Java API when using GPU,system information custom code os centos tensorflow installed source binary binary tensorflow version use command n python version n bazel version compiling source n cuda cudnn version gpu model memory geforce gtx exact command reproduce see describe problem main memory machine continuously consumed running gpu memory consumption hovers around running cpu source code log see,2017-08-01 18:52:55,1501613575,resolved fixed,03d310cc61a864600d24977f73138e643659986c,1504121706,tensorflow\java\src\main\native\operation_builder_jni.cc                                                            
15,1198,reverse_sequence's inability to accept int32 can break bidirectional_rnn,latest release bidirectional rnn changed accept int32 tensor sequence length argument tf reverse sequence accepts int64 tensor currently causing error int32 tensor passed bidirectional rnn,2016-02-19 15:47:34,1455896854,resolved fixed,484a80ce99998b59cf9f606a7c2a9ad1c14ea29a,1457486353,tensorflow\python\ops\rnn.py                                                            
16,11985,windows bazel build failed: undeclared inclusion,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu windows tensorflow installed source binary source tensorflow version use command python version bazel version compiling source cuda cudnn version none gpu model memory none exact command reproduce bazel output base c build tensorflow tool pip package build pip package describe problem error c o tensorflow tensorflow core build undeclared inclusion rule tensorflow core lib internal rule missing dependency declaration following file included tensorflow core framework variant tensor data cc c o tensorflow tensorflow core framework tensor h c o tensorflow tensorflow core framework allocator h c o tensorflow tensorflow core framework numeric type h c o tensorflow tensorflow core framework type trait h c o tensorflow tensorflow core framework variant h c o tensorflow tensorflow core framework type index h c o tensorflow tensorflow core framework tensor shape h c o tensorflow tensorflow core framework tensor type h c o tensorflow tensorflow core framework type h c o tensorflow tensorflow core framework bfloat16 h source code log,2017-08-03 03:24:45,1501730685,resolved fixed,6e7f1dac288acda411a21949a5720b2ca2f1a3eb,1502217609,tensorflow\core\BUILD                                                            
17,12205,BUG: TypeError in DNNClassifier.eval() when using same name for feature in feature_engineering_fn,describe problem use key replace feature tensorflow might throw typeerror evaluating eg def feature engineering fn feature label feature x func feature x mutable object hence bug caused method run see code open pr later,2017-08-11 08:21:10,1502439670,resolved fixed,f47c3ad964f42121cbab02afed52e2df367ea9ef,1503359792,tensorflow\contrib\learn\python\learn\estimators\estimator.py tensorflow\contrib\learn\python\learn\estimators\estimators_test.py                                                          
18,12249,tf.estimator.Estimator breaks when using python 3.5 type annotations,minimal example import tensorflow tf def model fn feature dict label tf tensor mode str pas estimator tf estimator estimator model fn result file usr local lib python3 dist package tensorflow python estimator estimator py line init verify model fn args model fn params file usr local lib python3 dist package tensorflow python estimator estimator py line verify model fn args args set model fn args model fn file usr local lib python3 dist package tensorflow python estimator estimator py line model fn args return tuple tf inspect getargspec fn args file usr local lib python3 dist package tensorflow python util tf inspect py line getargspec decorator argspec none inspect getargspec target file usr lib python3 inspect py line getargspec raise valueerror function keyword argument annotation valueerror function keyword argument annotation use getfullargspec api support system information os platform distribution linux mint tensorflow version v1 g12f033d python version,2017-08-13 12:49:10,1502628550,resolved fixed,93a652ef5b635ffbd678d3992767c4862bffeb15,1513015202,tensorflow\python\estimator\util.py tensorflow\python\util\tf_inspect.py                                                          
19,12436,zeros_like doesn't fully respect the optimize argument,definition zero like def zero like tensor dtype none name none optimize true ops name scope name zero like tensor name tensor ops convert tensor tensor name tensor tensor shape fully defined produce zero tensor independent value tensor since shape known statically return zero tensor shape dtype dtype tensor dtype name name dtype none dtype tensor dtype return zero shape internal tensor optimize optimize dtype dtype name name else return gen array ops zero like tensor name name see shape already known parameter ignored inconsistent documented behavior,2017-08-21 03:15:45,1503285345,resolved fixed,9ba48146942219a2d97e9a2110f88f20d62c4cb6,1505671893,tensorflow\python\ops\array_ops.py                                                            
20,12569,missing Documentation of the method AttentionWrapper.zero_state(...),hello noticed method attentionwrapper zero state batch size dtype description functionality documentation website reference link really hope get fixed spent couple day trying debug code written realized misusing method thank,2017-08-24 21:04:12,1503608652,resolved fixed,aae34fa7e35d9c3931cae49bfc20384dd20dffec,1506731761,tensorflow\contrib\seq2seq\python\ops\attention_wrapper.py tensorflow\contrib\seq2seq\python\ops\beam_search_decoder.py                                                          
21,12608,gather_nd bounds checking not working,using gather nd sometimes bound index lead error bound checking expected behavior sometimes seems read zero expect reading memory gpu never observed anything zero sure run cpu bound seem appropriately checked e get error desired example code import tensorflow tf sess tf session print sess run tf gather nd tf zero print sess run tf gather nd tf zero print sess run tf gather nd tf reshape tf range first two print statement execute successfully bug index clearly range array clearly instead return appropriately shaped array necessary trigger bug highlight drawing incorrect memory third line reason bound checking operate correctly say yes index bound appears something based previous op maybe ops stack allow go outside bound others reshape example interactive session show output get python default nov gcc linux type help copyright credit license information import tensorflow tf sess tf session w tensorflow core platform cpu feature guard cc tensorflow library compiled use sse4 instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use sse4 instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use avx instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use avx2 instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use fma instruction available machine could speed cpu computation tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name geforce gtx major minor memoryclockrate ghz pcibusid total memory free memory tensorflow core common runtime gpu gpu device cc dma tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name geforce gtx pci bus id sess run tf gather nd tf zero array dtype float32 sess run tf gather nd tf zero array dtype float32 sess run tf gather nd tf reshape tf range traceback recent call last file usr local lib python3 dist package tensorflow python client session py line call return fn args file usr local lib python3 dist package tensorflow python client session py line run fn status run metadata file usr lib python3 contextlib py line exit next self gen file usr local lib python3 dist package tensorflow python framework error impl py line raise exception ok status pywrap tensorflow tf getcode status tensorflow python framework error impl invalidargumenterror flat index index param shape node gathernd gathernd tindices dt int32 tparams dt int32 device job localhost replica task cpu reshape gathernd index handling exception another exception occurred traceback recent call last file line file usr local lib python3 dist package tensorflow python client session py line run run metadata ptr file usr local lib python3 dist package tensorflow python client session py line run feed dict tensor option run metadata file usr local lib python3 dist package tensorflow python client session py line run option run metadata file usr local lib python3 dist package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl invalidargumenterror flat index index param shape node gathernd gathernd tindices dt int32 tparams dt int32 device job localhost replica task cpu reshape gathernd index caused op gathernd defined file line file usr local lib python3 dist package tensorflow python ops gen array ops py line gather nd name name file usr local lib python3 dist package tensorflow python framework op def library py line apply op op def op def file usr local lib python3 dist package tensorflow python framework ops py line create op original op self default original op op def op def file usr local lib python3 dist package tensorflow python framework ops py line init self traceback self graph extract stack pylint disable protected access invalidargumenterror see traceback flat index index param shape node gathernd gathernd tindices dt int32 tparams dt int32 device job localhost replica task cpu reshape gathernd index version info linux mint generic x86 python version cuda version release v8 cudnn version tensorflow version v1 rc2 g0787eee nvidia driver version,2017-08-26 00:19:52,1503706792,resolved fixed,5386775e64aac0bb5020974122645da900bc312a,1515185610,tensorflow\core\api_def\base_api\api_def_GatherNd.pbtxt tensorflow\core\api_def\base_api\api_def_GatherV2.pbtxt tensorflow\core\api_def\base_api\api_def_ScatterNd.pbtxt tensorflow\core\ops\array_ops.cc                                                      
22,12641,Improve all-in-memory file copy architecture (Python at least),current file copy least via python gfile py file io py file io involves copying source content memory writing memory destination scenario like working asset unacceptable design file system h writablefile stubbed allow anything like streaming though randomaccessfile entirely entirely true suppose writeablefile append const stringpiece data could employed streamable fashion ish cull python low hanging fruit least please implement file io using regular streaming design instead described current design,2017-08-28 04:58:44,1503896324,resolved fixed,b1f5f433959406c7aad634c05e85ccd62fd06e87,1518050791,tensorflow\core\platform\env.cc tensorflow\core\platform\env.h tensorflow\core\platform\file_system.cc tensorflow\core\platform\file_system.h tensorflow\core\platform\posix\posix_file_system.cc tensorflow\core\platform\posix\posix_file_system.h tensorflow\python\lib\io\file_io.i                                                
23,12902,Change TanhGrad() operation definition with respect to documentation,hello tanhgrad documentation say specifically grad dy tanh x dy corresponding input gradient tensorflow tensorflow core ops math ops cc line bab2db4 specifically grad dy tanh x dy correct look good operation following declaration input input x input tensorflow tensorflow core ops math ops cc line bab2db4 input x correlate documentated formula grad dy could please rename input respect documentation like input input dy thanks,2017-09-08 09:15:10,1504862110,resolved fixed,9b5bf2b6786a58df679b4be2249da8a235b9f4fd,1506452072,tensorflow\core\ops\math_ops.cc                                                            
24,13202,tf.InteractiveSession leaks sessions,following work fine tf session fail release resource tf interactivesession sess tf interactivesession stuff sess close del sess reason interactive session enters context using enter never quits leaving reference defaultstack object found debugging notebook hogging gpu ram two work arounds force c api close session using sess del get rid dangling reference sess default session exit none none none del sess import gc gc collect think better solution would sess close call tf closesession tf deletesession method reset session like session lib reset,2017-09-21 03:44:15,1505965455,resolved fixed,0f508d4de379e800ad7f990de08959bbd6fcabb5,1521142667,tensorflow\python\client\session.py tensorflow\python\client\session_test.py                                                          
25,13431,Windows nightly build Dataset.from_generator fails with pyfunc error,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu window tensorflow installed source binary pip tensorflow version dev20170929 python version bazel version compiling source cuda cudnn version gpu model memory exact command reproduce see describe problem described question code import tensorflow tf dataset tf contrib data dataset it2 dataset range make one shot iterator dataset generator need tensorflow tf session sess print tf version def dataset generator true try yield sess run it2 get next except tf error outofrangeerror return da dataset dataset generator dataset generator tf int64 da dataset da dataset make one shot iterator true try print sess run da dataset get next except tf error outofrangeerror break fails c dropbox pycharmvirtual tf nigthly scripts python exe c dropbox eclipse workspace python zebra generator py dev20170929 w c tf jenkins home workspace tf nightly window window py tensorflow core framework op kernel cc invalid argument th value returned pyfunc int32 expects int64 node pyfunc pyfunc tin tout dt int64 token pyfunc traceback recent call last file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line call return fn args file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line run fn status run metadata file c python35 lib contextlib py line exit next self gen file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python framework error impl py line raise exception ok status c api tf getcode status status tensorflow python framework error impl invalidargumenterror th value returned pyfunc int32 expects int64 node pyfunc pyfunc tin tout dt int64 token pyfunc node iteratorgetnext iteratorgetnext output shape output type dt int64 device job localhost replica task cpu oneshotiterator handling exception another exception occurred traceback recent call last file c dropbox eclipse workspace python zebra generator py line print sess run da dataset get next file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line run run metadata ptr file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line run feed dict tensor option run metadata file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line run option run metadata file c dropbox pycharmvirtual tf nigthly lib site package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl invalidargumenterror th value returned pyfunc int32 expects int64 node pyfunc pyfunc tin tout dt int64 token pyfunc node iteratorgetnext iteratorgetnext output shape output type dt int64 device job localhost replica task cpu oneshotiterator process finished exit code problem window nightly installing nightly ubuntu machine work pipenv run python3 generator py tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use sse4 sse4 avx avx2 fma dev20170929 w tensorflow core framework op kernel cc range stopiteration iteration finished maybe related,2017-10-01 13:44:27,1506865467,resolved fixed,9b027db459ff771c246a266ac3ec40cfbb4a63ce,1506987057,tensorflow\contrib\data\python\kernel_tests\dataset_constructor_op_test.py tensorflow\contrib\data\python\ops\dataset_ops.py tensorflow\python\data\ops\dataset_ops.py tensorflow\python\kernel_tests\dataset_constructor_op_test.py tensorflow\python\ops\script_ops.py                                                    
26,13506,tf.image.pad_to_bounding_box crashes when passed bounds with dtype int64,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary pip virtualenv tensorflow version use command v1 rc2 g0787eee python version default nov n gcc bazel version compiling source cuda cudnn version gpu model memory exact command reproduce description passing argument type int64 tf image pad bounding box trigger crash python interpreter bug type required tf image pad bounding box documented anywhere cause crash cryptic error message sources logs following snippet crash whole python interpreter core dump import tensorflow tf tf constant dtype tf int64 img tf one dtype tf float32 sess tf session sess run tf image pad bounding box img leaf following f tensorflow core framework tensor cc check failed dtype expected dtype v,2017-10-05 18:06:45,1507226805,resolved fixed,cbb705f10149a11b8d17182343ef12ab2dbfd7a8,1508276151,tensorflow\core\kernels\pad_op.cc tensorflow\core\kernels\pad_op.h tensorflow\core\kernels\pad_op_gpu.cu.cc tensorflow\python\kernel_tests\pad_op_test.py tensorflow\python\ops\image_ops_test.py                                                    
27,13526,Importing TF in Python yields 'cannot import name 'build_info',system information fedora x64 fc26 x86 tensorflow installed source tf version tf git version b v1 rc1 gd86448938 tf compiler version b v1 rc1 gd86448938 python version anaconda bazel installed fedora copr repository version non git cuda compatible gpu intel mkl c gcc red hat bazel build c opt config mkl tensorflow tool pip package build pip package notice mkl flag bazel build describe problem configuration bazel build finished without error attempting import tensorflow python get import tensorflow tf traceback recent call last file line file home torstein progs tensorflow tensorflow init py line tensorflow python import file home torstein progs tensorflow tensorflow python init py line tensorflow python import pywrap tensorflow file home torstein progs tensorflow tensorflow python pywrap tensorflow py line tensorflow python platform import self check file home torstein progs tensorflow tensorflow python platform self check py line tensorflow python platform import build info importerror import name build info,2017-10-06 15:00:17,1507302017,resolved fixed,251a1e70dc04b10fb25e8013d1ad1f27d5eda30b,1507310869,tensorflow\python\platform\self_check.py                                                            
28,13536,BeamSearchDecoder incorrectly truncates results when used with dynamic_decode,system information irrelevant bug written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command v1 rc2 g0787eee python version python continuum analytics inc bazel version compiling source n cuda cudnn version irrelevant gpu model memory irrelevant exact command reproduce irrelevant describe problem tf contrib seq2seq beamsearchdecoder incorrectly truncates result index previously used beam member ended earlier step root problem loop body dynamic decode assumes sequence independent finish time beamsearchdecoder creates tree like structure beam index reused later step state originates different parent index cause decoding loop sometimes record wrong sequence length beam member wrong sequence length passed beamsearchdecoder finalize return truncated sequence source code log use following code workaround problem cause right sequence returned still length returned dynamic decode wrong class fixedbeamsearchdecoder seq2seq beamsearchdecoder def finalize self output final state sequence length beamsearchdecoder follow correct semantics finished flag result taking wrong length getting wrong decoded string substitute sequence length recorded dynamic decoder wrong wrong finished flag returned beamsearchdecoder step length recorded beamsearchstate correct return super finalize output final state final state length,2017-10-06 20:53:52,1507323232,resolved fixed,18f89c81d288f191abd56501ec6f86fe29265bdd,1508255785,tensorflow\contrib\seq2seq\kernels\beam_search_ops.cc tensorflow\contrib\seq2seq\kernels\beam_search_ops.h tensorflow\contrib\seq2seq\kernels\beam_search_ops_gpu.cu.cc tensorflow\contrib\seq2seq\ops\beam_search_ops.cc tensorflow\contrib\seq2seq\python\kernel_tests\beam_search_decoder_test.py tensorflow\contrib\seq2seq\python\kernel_tests\beam_search_ops_test.py tensorflow\contrib\seq2seq\python\ops\beam_search_decoder.py tensorflow\contrib\seq2seq\python\ops\decoder.py                                              
29,13558,segfaults in GPU tf.matrix_inverse,running segfaults tf matrix inverse adding identity matrix invertible procedure work fine numpy tensorflow cpu version non deterministically crash second various backtraces ie tensorflow tensor totalbytes const home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework tensorflow tensor tensor data const home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework bool tensorflow internal transposeusingtile eigen gpudevice const tensorflow tensor const tensorflow gtl arrayslice tensorflow tensor home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow status tensorflow dotranspose eigen gpudevice const tensorflow tensor const tensorflow gtl arrayslice tensorflow tensor home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow svdopgpu performsvd mgeqn tensorflow opkernelcontext std function long long long long long long tensorflow gtl arrayslice const tensorflow tensor const tensorflow tensor tensorflow tensor tensorflow tensor home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow svdopgpu computeasync tensorflow opkernelcontext std function home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow basegpudevice computeasync tensorflow asyncopkernel tensorflow opkernelcontext std function home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework tensorflow anonymous namespace executorstate process tensorflow anonymous namespace executorstate taggednode long long home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework usr lib x86 linux gnu libcuda usr lib x86 linux gnu libcuda usr lib x86 linux gnu libcuda culaunchkernel usr lib x86 linux gnu libcuda usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver usr local cuda lib64 libcusolver tensorflow status tensorflow cudasolver getrf int int float int int int home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow matrixinverseopgpu computeasync tensorflow opkernelcontext std function home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python pywrap tensorflow internal tensorflow basegpudevice computeasync tensorflow asyncopkernel tensorflow opkernelcontext std function home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework tensorflow anonymous namespace executorstate process tensorflow anonymous namespace executorstate taggednode long long home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework std function handler tensorflow anonymous namespace executorstate tensorflow anonymous namespace executorstate taggednode long long invoke std data const home yaroslav anaconda3 envs oct10 lib python3 site package tensorflow python libtensorflow framework tensorflow commit nvidia smi libcudart libcudnn nvidia gtx,2017-10-07 23:40:22,1507419622,resolved fixed,3629fc4e98254c37e614ac3f77fa250b75c70f8d,1514511507,tensorflow\core\kernels\matrix_inverse_op.cc                                                            
30,13576,sparse_softmax_cross_entropy_with_logits wrong annotation,tensorflow tensorflow python ops nn ops py line label equal rank label minus one logits scalar need rank rank label equal rank logits minus one,2017-10-09 04:53:41,1507524821,resolved fixed,edfb9bb100f9814bf1bbcff2e8a32f12f049bfcc,1507564818,tensorflow\python\ops\nn_ops.py                                                            
31,13764,Failure in TestNewTensor when running go test,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary source branch tensorflow version use command dev python version bazel version compiling source cuda cudnn version gpu model memory nvidia exact command reproduce go test v github com tensorflow tensorflow tensorflow go describe problem trying use go binding tensorflow c library run test get nil pointer dereference segfault detail note built c library source using following option bazel build c opt config cuda config mkl c opt copt mavx copt mavx2 copt mfma copt mfpmath copt msse4 c opt cxxopt glibcxx use cxx11 abi tensorflow libtensorflow source code log run go test v github com tensorflow tensorflow tensorflow go get following error e tensorflow core common runtime bfc allocator cc tried allocate byte w tensorflow core common runtime allocator retry cc request allocate byte fail testnewtensor panic runtime error invalid memory address nil pointer dereference recovered panic runtime error invalid memory address nil pointer dereference signal sigsegv segmentation violation code addr pc goroutine running testing trunner func1 usr lib go src testing testing go panic usr lib go src runtime panic go github com tensorflow tensorflow tensorflow go tensordata home vishvananda go src github com tensorflow tensorflow tensorflow go tensor go github com tensorflow tensorflow tensorflow go newtensor home vishvananda go src github com tensorflow tensorflow tensorflow go tensor go github com tensorflow tensorflow tensorflow go testnewtensor home vishvananda go src github com tensorflow tensorflow tensorflow go tensor test go testing trunner usr lib go src testing testing go created testing run usr lib go src testing testing go exit status fail github com tensorflow tensorflow tensorflow go adding debugging turn testnewtensor test fails attempting create following tensor int64 int64 comment line test pas,2017-10-17 00:17:31,1508199451,resolved fixed,db10718b38b2884cb5ed46d33c135c079f649d16,1509764978,tensorflow\go\tensor.go                                                            
32,13827,"Tensorflow 1.3: tf.constant with dtype=[float32, float64, float16] may have inconsistent behavior.",system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu docker running gcr io tensorflow tensorflow latest tensorflow installed source binary na tensorflow version use command v1 rc2 g0787eee python version bazel version compiling source na cuda cudnn version na gpu model memory na exact command reproduce work test numpy array none dtype numpy float32 sess tf session print sess run tf constant test dtype tf float32 work sess tf session print sess run tf constant none dtype tf float16 return error sess tf session print sess run tf constant none dtype tf float32 typeerror expected float32 got none type message instead describe problem tensorflow constant none array dtype float32 float64 seem throw error however first wrapped numpy array none accepted turned nan behavior seems inconsistent,2017-10-19 03:47:14,1508384834,resolved fixed,c43d777b56a17832f7de288d0fe966bf537ffeb7,1510210171,tensorflow\python\framework\ops.py tensorflow\python\framework\tensor_util.py                                                          
33,13885,tf.reduce_mean is not compatible with np.mean,tf reduce mean emphasized function compatible numpy equivalent np mean output type consider following code example import tensorflow tf x tf variable init tf global variable initializer sess tf session sess run init print sess run tf reduce mean x output zero seems tf reduce mean infer output type input tensor casting input tensor float value solve problem attribute compatible np mean import numpy np print np mean system information os platform distribution linux ubuntu tensorflow installed source binary source tensorflow version use command python version,2017-10-21 17:39:20,1508607560,resolved fixed,a43f911e103aa5910d4e2405d77bdee8f9314fac,1510190090,tensorflow\python\ops\math_ops.py                                                            
34,14292,Can't import contrib.boosted_trees,system information written custom code opposed using stock example script provided tensorflow yes cat etc issue linux microsoft microsoft wed dec pst x86 x86 x86 gnu linux version lts xenial xerus version id version codename xenial docker compiler c ubuntu copyright c free software foundation inc free software see source copying condition warranty even merchantability fitness particular purpose uname linux microsoft microsoft wed dec pst x86 x86 x86 gnu linux check pip numpy protobuf tensorflow tensorflow tensorboard check virtualenv false tensorflow import tf version tf git version v1 gd752244 tf compiler version v1 gd752244 sanity check array dtype int32 env ld library path unset dyld library path unset nvidia smi tf env collect sh line nvidia smi command found cuda libs describe problem import boosted tree module boosted tree properly listed contrib init py get import tensorflow tf est tf contrib boosted tree estimator batch estimator gradientboosteddecisiontreeclassifier traceback recent call last file line file usr local lib python2 dist package tensorflow python util lazy loader py line getattr return getattr module item attributeerror module object attribute boosted tree source code log see,2017-11-06 15:10:05,1509981005,resolved fixed,e52706d1696faa2ab926c2d91a0d85ec99dac314,1524691683,tensorflow\contrib\cmake\python_modules.txt                                                            
35,14455,Tensorflow cannot be installed with default Windows Python 3.5 stack,installing python using windows bit installer includes pip install pip3 install upgrade tensorflow collecting tensorflow could find version satisfies requirement tensorflow version matching distribution found tensorflow using pip version however version available consider upgrading via python pip install upgrade pip command tried different machine worked found difference pip version updating pip solved issue explicitly stated anywhere need newer version pip old version something required run something people tend ignore message indicating newer version exactly expecting yeah know newer version meant resolved older version pip specifically version included required python version could please state documentation,2017-11-10 15:53:55,1510329235,resolved fixed,2ae9c6c7a20dbd8f05e4b60e921e60986e2968bf,1510600784,tensorflow\docs_src\install\install_windows.md                                                            
36,14542,'Model' object has no attribute 'container_nodes',problem model tf kera model model model add tf kera utils plot model model file model png output traceback recent call last file model py line k utils plot model model file model png file usr local lib python3 dist package tensorflow python kera impl kera utils vi utils py line plot model dot model dot model show shape show layer name rankdir file usr local lib python3 dist package tensorflow python kera impl kera utils vi utils py line model dot node key model container node attributeerror model object attribute container node environment system ubuntu tensorflow gpu bin v1 rc1 g130a514,2017-11-14 10:16:22,1510654582,resolved fixed,3e53570d3bf518ec2b6cfeed4b5fd57d11370289,1510943659,tensorflow\python\keras\_impl\keras\utils\vis_utils.py                                                            
37,14739,Eager: Warn with invalid policy,user accidentally writes tfe enable eager execution tfe device placement warn instead correct tfe enable eager execution device policy tfe device placement warn get error later program example tfe num gpus incorrect enable call produce attributeerror traceback recent call last tfe num gpus anaconda3 lib python3 site package tensorflow python eager context py num gpus number available gpu device return context num gpus anaconda3 lib python3 site package tensorflow python eager context py num gpus self def num gpus self number gpus available execute operation self initialize handle device return self num gpus anaconda3 lib python3 site package tensorflow python eager context py initialize handle device self error raise exception ok status status self config none config str self config serializetostring pywrap tensorflow tfe contextoptionssetconfig opts config str len config str status attributeerror int object attribute serializetostring think make sense throw error immediately incorrect enable eager execution ab00df9,2017-11-21 02:31:54,1511231514,resolved fixed,ba87a8030aa30f24c354cf705e79734658bb0a8b,1511900529,tensorflow\python\framework\ops.py tensorflow\python\framework\ops_test.py                                                          
38,14776,tf.keras.estimator.estimator_from_model does not respect options set in RunConfig,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command tf version tf git version v1 rc1 g130a514 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory nvidia tesla m60 gb exact command reproduce see describe problem trying use estimator derived tf kera estimator estimator model training tf estimator train evaluate setting gpu option session config tf estimator runconfig cause setting respected passed estimator model function example setting per process gpu memory fraction decrease memory allocated process gpu similarly setting allow growth true continues allocate memory allow memory growth also tested canned estimator tf estimator dnnregressor setting applied expected runconfig passed estimator code demonstrate issue source code log minimal example run completion train successfully changing gpuoptions setting cause gpu memory utilized expected import o import numpy np import tensorflow tf tf logging set verbosity tf logging info neither gpuoptions respected gpu option tf gpuoptions per process gpu memory fraction gpu option tf gpuoptions allow growth true sess config tf configproto gpu option gpu option run config tf estimator runconfig session config sess config input tf kera layer input shape output tf kera layer dense input model tf kera model model input output model compile optimizer sgd loss mse est kera tf kera estimator model estimator kera model model config run config input name model input name data np random rand astype np float32 train input fn tf estimator input numpy input fn input name data data batch size num epoch none shuffle false train spec tf estimator trainspec input fn train input fn max step eval spec tf estimator evalspec input fn train input fn step tf estimator train evaluate est kera train spec eval spec,2017-11-22 00:35:51,1511310951,resolved fixed,355fb5e14b325a1d106c4046f478da4bda350205,1520286771,tensorflow\python\keras\_impl\keras\estimator.py tensorflow\python\keras\_impl\keras\estimator_test.py                                                          
39,14800,Potential memory leak from deleting array and closing file handler,couple minor memory leak review tensorflow tensorflow c c api cc lines char base new char size char data start base sizeof tensorflow uint64 srcarray size char dst data start next string encoded size dst len size static cast data start base tensorflow uint64 offset reinterpret cast base int srcarray size offset dst data start offset const string srcarray size consumed tf stringencode data size dst dst len status status status ok status status invalidargument invalid string tensor encoding string srcarray size status status error message return nullptr dst consumed dst len consumed dst base size status status invalidargument invalid string tensor encoding decoded dst base byte tensor encoded size byte return nullptr delete base look missing tensorflow tensorflow core lib io snappy snappy outputbuffer cc lines char compressed length array new char std fill compressed length array compressed length array int little endian compressed length array output size tf return error addtooutputbuffer compressed length array write compressed output buffer tf return error addtooutputbuffer output data output size delete compressed length array look missing macro tf return error fails tensorflow tensorflow core platform profile utils android armv7a cpu utils helper cc lines file fp fopen file path c str r fp nullptr return invalid cpu frequency int64 freq khz invalid cpu frequency const int retval fscanf fp lld freq khz retval log warning failed file path return invalid cpu frequency pclose fp two potential problem fclose called fscanf fails b fclose could called instead pclose tensorflow tensorflow tool proto text gen proto text function cc lines file f fopen path c str w f nullptr return fwrite data c str data size f data size return fclose f fwrite fails fclose could called return ps handy working environment setup yet currently browsing code may better fit,2017-11-22 16:13:41,1511367221,resolved fixed,e17ae378063b46c894a8c193823f029d7d87de81,1512956694,tensorflow\c\c_api.cc tensorflow\core\lib\io\snappy\snappy_outputbuffer.cc tensorflow\core\platform\profile_utils\android_armv7a_cpu_utils_helper.cc tensorflow\tools\proto_text\gen_proto_text_functions.cc                                                      
40,14819,Keras Dropout support_masking gets reset to False,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac os x tensorflow installed source binary binary tensorflow version use command v1 rc1 g130a514 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n exact command reproduce see collect information using environment capture script obtain tensorflow version python c import tensorflow tf print tf git version tf version describe problem describe problem clearly sure convey bug tensorflow feature request keras dropout layer constructor tensorflow python kera impl kera layer core py set support masking true call super constructor set back false layer defined module appear set support masking true super constructor call source code log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached try provide reproducible test case bare minimum necessary generate problem tensorflow contrib kera api kera model import sequential tensorflow contrib kera api kera layer import dropout inputlayer lstm masking name main test1 true def model1 model sequential model add inputlayer model add masking model add dropout def model2 model sequential model add inputlayer model add masking model add lstm return sequence true model add dropout test1 model1 else model2 traceback recent call last file expose dropout bug py line model add dropout file venv lib python3 site package tensorflow python kera impl kera model py line add output tensor layer self output file venv lib python3 site package tensorflow python kera impl kera engine topology py line call output super layer self call input kwargs file venv lib python3 site package tensorflow python layer base py line call output mask self compute mask input previous mask file venv lib python3 site package tensorflow python kera impl kera engine topology py line compute mask passed input mask str mask typeerror layer dropout support masking passed input mask tensor masking shape dtype bool,2017-11-23 04:24:01,1511411041,resolved fixed,fd1263fb9b9a81b4c8d7e7922308146b4f57428d,1512960284,tensorflow\python\keras\_impl\keras\layers\core.py tensorflow\python\keras\_impl\keras\layers\core_test.py                                                          
41,14942,tensorflow 1.4 is 8 times slower than tensorflow 1.3 when read data,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu tensorflow installed source binary python wheel tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version none gpu model memory none exact command reproduce run tensorflow1 script using estimator script time slower tensorflow source code log main script usr bin env python author zj import argparse import o import sys import numpy np import time try import better exception except importerror pas import tensorflow tf src model ori import crnn fn src data handler import data loader src config import params alphabet src input utils import input fn def main unused argv model path flags input model dir o path exists model path assert filenotfounderror model list o path join model path x x o listdir model path x endswith meta o path exists flags output model dir o makedirs flags output model dir parameter params eval batch size input shape digit false alphabet alphabet chinesechar letters digits extended alphabet decoding image channel csv delimiter csv file eval flags csv file eval output model dir flags output model dir gpu flags gpu model params params parameter o environ cuda visible devices parameter gpu config sess tf configproto config sess gpu option per process gpu memory fraction config estimator est config tf estimator runconfig est config est config replace session config config sess save summary step model dir parameter output model dir estimator tf estimator estimator model fn crnn fn params model params config est config model dir parameter output model dir try open flags output file encoding utf mode w save file model model list start time time eval result estimator evaluate input fn data loader csv filename parameter csv file eval params parameter batch size parameter eval batch size num epoch step checkpoint path model print time time time start print model evaluation result model str eval result save file write model str eval result n except keyboardinterrupt print interrupted name main parser argparse argumentparser parser add argument fe csv file eval required false type str help csv filename evaluation nargs default e val1 csv parser add argument output model dir required false type str help directory output default model vgg eval parser add argument input model dir required false type str help directory output default model test parser add argument g gpu type str help gpu default parser add argument output file required false type str default txt help log output file tf logging set verbosity tf logging debug flags unparsed parser parse known args tf app run main main argv sys argv unparsed data loader script usr bin env python import tensorflow tf import numpy np config import params const typing import tuple def data loader csv filename str params params batch size int data augmentation bool false num epoch int none image summary bool false def input fn choose case one csv file list csv file isinstance csv filename list filename queue tf train string input producer csv filename num epoch num epoch name filename queue elif isinstance csv filename list filename queue tf train string input producer csv filename num epoch num epoch name filename queue skip line already processed reader tf textlinereader name csv reader skip header line key value reader read filename queue name file reading op default line none none path label tf decode csv value record default default line field delim params csv delimiter name csv reading op image img width image reading path resized size params input shape params params data augmentation data augmentation padding true batch image image image width img width filename path label label prepared batch tf train shuffle batch batch batch size batch size min dequeue num thread capacity allow smaller final batch false name prepared batch queue image summary tf summary image input image prepared batch get image max output tf summary text input label prepared batch get label tf summary text input width tf string prepared batch get image width return prepared batch prepared batch get label return input fn def image reading path str params params resized size tuple int int none data augmentation bool false padding bool false tuple tf tensor tf tensor read image image content tf read file path name image reader image tf cond tf equal tf string split path value tf constant jpg dtype tf string true fn lambda tf image decode jpeg image content channel params image channel try recover truncated true todo channel false fn lambda tf image decode png image content channel params image channel name image decoding data augmentation data augmentation image augment data image padding padding tf name scope padding image img width padding input width image resized size increment const dimension reduction w pooling resize else image tf image resize image image size resized size img width tf shape image tf control dependency tf assert equal image shape resized size return image img width def random rotation img tf tensor max rotation float crop bool true tf tensor seguinbe tf name scope randomrotation rotation tf random uniform max rotation max rotation rotated image tf contrib image rotate img rotation interpolation bilinear crop rotation tf ab rotation original shape tf shape rotated image h w original shape original shape see formula old l old tf cond h w lambda h w lambda w h old l old tf cast old l tf float32 tf cast old tf float32 new l old l tf co rotation old tf sin rotation tf co rotation new old tf sin rotation new l tf co rotation new h new w tf cond h w lambda new l new lambda new new l new h new w tf cast new h tf int32 tf cast new w tf int32 bb begin tf cast tf ceil h new h tf int32 tf cast tf ceil w new w tf int32 rotated image crop rotated image bb begin h bb begin bb begin w bb begin crop remove entire image keep original image rotated image tf cond tf equal tf size rotated image crop true fn lambda img false fn lambda rotated image crop return rotated image def random padding image tf tensor max pad w int max pad h int tf tensor w pad list np random randint max pad w size h pad list np random randint max pad h size padding h pad w pad return tf pad image padding mode reflect name random padding def augment data image tf tensor tf tensor tf name scope dataaugmentation random padding image random padding image image tf image random brightness image max delta image tf image random contrast image image random rotation image crop true image shape image tf image random hue image image tf image random saturation image return image def padding input width image tf tensor target shape tuple int int increment int tuple tf tensor tf tensor target ratio target shape target shape compute ratio keep ratio new image get size padding necessary final desired shape shape tf shape image ratio tf divide shape shape name ratio new h target shape new w tf cast tf round ratio new h increment increment tf int32 f1 lambda new w ratio f2 lambda new h tf constant dtype tf float64 new w ratio tf case tf greater new w f1 tf le equal new w f2 default f1 exclusive true target w target shape definitions case def pad fn tf name scope mirror padding pad tf subtract target w new w img resized tf image resize image image new h new w padding desired width padding pad pad image tf pad img resized padding mode symmetric name none set manually shape pad image set shape target shape target shape img resized get shape return pad image new h new w def replicate fn tf name scope replication padding img resized tf image resize image image new h new w one symmetry enough full width count number replication needed n replication tf cast tf ceil target shape new w tf int32 img replicated tf tile img resized tf stack n replication pad image tf image crop bounding box image img replicated offset height offset width target height target shape target width target shape set manually shape pad image set shape target shape target shape img resized get shape return pad image new h new w def simple resize tf name scope simple resize img resized tf image resize image image target shape img resized set shape target shape target shape img resized get shape return img resized target shape case pad image new h new w tf case case new w target w tf logical tf greater equal ratio target ratio tf greater equal new w target w simple resize case new w target w new w target w ratio target ratio tf logical tf le ratio target ratio tf logical tf greater equal new w tf cast tf divide target w tf int32 tf le new w target w pad fn case new w target w new w target w ratio target ratio tf logical tf le ratio target ratio tf logical tf le new w target w tf le new w tf cast tf divide target w tf int32 replicate fn default simple resize exclusive true return pad image new w new w image width used computing sequence length def preprocess image prediction fixed height int min width int input function use exporting model making prediction see estimator export savedmodel param fixed height height input image resizing param min width minimum width image resizing return def serving input fn define placeholder input image image tf placeholder dtype tf float32 shape none none shape tf shape image assert shape h x w x c c ratio tf divide shape shape increment const dimension reduction w pooling new width tf cast tf round ratio fixed height increment increment tf int32 resized image tf cond new width tf constant min width dtype tf int32 true fn lambda tf image resize image image size fixed height min width false fn lambda tf image resize image image size fixed height new width features serve feature image resized image none cast x h x w x c image width new width none cast tensor inputs received receiver input image image return tf estimator export servinginputreceiver feature receiver input return serving input fn log tensorflow1 info tensorflow using config model dir model vgg eval tf random seed none save summary step save checkpoint step none save checkpoint sec session config gpu option per process gpu memory fraction keep checkpoint max keep checkpoint every n hour log step count step service none cluster spec task type worker task id master chief true num p replica num worker replica info tensorflow starting evaluation info tensorflow restoring parameter model test model ckpt c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation info tensorflow finished evaluation info tensorflow saving dict global step eval cer eval accuracy global step loss time model model test model ckpt evaluation result eval cer eval accuracy loss global step tensorflow info tensorflow using config model dir model vgg eval tf random seed save summary step save checkpoint sec save checkpoint step none session config gpu option per process gpu memory fraction keep checkpoint max keep checkpoint every n hour log step count step info tensorflow starting evaluation info tensorflow restoring parameter model test model ckpt c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation c tf jenkins home workspace rel win window py tensorflow core kernel logging ops cc loss info tensorflow evaluation info tensorflow finished evaluation info tensorflow saving dict global step eval cer eval accuracy global step loss time model model test model ckpt evaluation result eval cer eval accuracy loss global step,2017-11-28 14:01:08,1511877668,resolved fixed,2d4c29cd6a0627fdd71a752e6bd919204c7cb8bf,1512686367,tensorflow\python\training\server_lib.py tensorflow\python\training\server_lib_test.py                                                          
42,14985,tf.nn.fractional_max_pool output have same batch size when feed with different input batch size,describe problem tf nn fractional max pool output batch size feed different input batch size attached test code write different input feed different batch size output get batch size pool test py txt code result shape input shape output shape input b shape output b system information cat etc issue linux c generic ubuntu smp thu nov utc x86 x86 x86 gnu linux version lts xenial xerus version id version codename xenial docker compiler c ubuntu copyright c free software foundation inc free software see source copying condition warranty even merchantability fitness particular purpose uname linux c generic ubuntu smp thu nov utc x86 x86 x86 gnu linux check pip numpy numpydoc check virtualenv false tensorflow import traceback recent call last file line modulenotfounderror module named tensorflow env ld library path usr local cuda lib64 dyld library path unset nvidia smi thu nov nvidia smi driver version gpu name persistence bus id disp volatile uncorr ecc fan temp perf pwr usage cap memory usage gpu util compute geforce gtx n p8 default processes gpu memory gpu pid type process name usage g usr lib xorg xorg g compiz cuda libs usr local cuda doc man man7 libcudart usr local cuda doc man man7 libcudart usr local cuda target x86 linux lib libcudart static usr local cuda target x86 linux lib libcudart cat etc issue linux c generic ubuntu smp thu nov utc x86 x86 x86 gnu linux version lts xenial xerus version id version codename xenial docker compiler c ubuntu copyright c free software foundation inc free software see source copying condition warranty even merchantability fitness particular purpose uname linux c generic ubuntu smp thu nov utc x86 x86 x86 gnu linux check pip numpy protobuf post1 tensorflow gpu tensorflow tensorboard check virtualenv false tensorflow import tf version tf git version v1 rc1 g130a514 tf compiler version v1 rc1 g130a514 sanity check array dtype int32 env ld library path usr local cuda lib64 dyld library path unset nvidia smi thu nov nvidia smi driver version gpu name persistence bus id disp volatile uncorr ecc fan temp perf pwr usage cap memory usage gpu util compute geforce gtx n p0 default processes gpu memory gpu pid type process name usage g usr lib xorg xorg g compiz cuda libs usr local cuda doc man man7 libcudart usr local cuda doc man man7 libcudart usr local cuda target x86 linux lib libcudart static usr local cuda target x86 linux lib libcudart,2017-11-30 04:20:21,1512015621,resolved fixed,5f0d3395d4c61000cf0cfb3dc681177147be938d,1515021302,tensorflow\core\kernels\BUILD tensorflow\core\kernels\fractional_avg_pool_op.cc tensorflow\core\kernels\fractional_max_pool_op.cc tensorflow\python\kernel_tests\BUILD tensorflow\python\kernel_tests\fractional_avg_pool_op_test.py tensorflow\python\kernel_tests\fractional_max_pool_op_test.py                                                  
43,15034,Optimize graph & graph transform tools do not support NCHW,tried optimizing graph using graph transform tool optimize graph inference case produced error fused batchnorm used nchw nhwc got error like invalidargumenterror see traceback must provide many bias channel dimension input tensor v node prefix convblock batchnorm fusedbatchnorm biasadd dt float data format nhwc device job localhost replica task device gpu prefix convblock conv2d prefix convblock conv2d bn offset although nchw faster nhwc gpu environment tool support nchw,2017-12-01 10:24:45,1512123885,resolved fixed,6afe900f543e0005ce69b3152330f1b7b16cb286,1517439745,tensorflow\python\tools\optimize_for_inference_lib.py tensorflow\python\tools\optimize_for_inference_test.py                                                          
44,15239,No gradient defined for op: Pow,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu windows x64 tensorflow installed source binary binary tensorflow version use command bazel version n python version none cuda cudnn version none gpu model memory none exact command reproduce describe problem seems gradient defined pow operation c api actually transferring issue migueldeicaza tensorflowsharp similar case select seems also gradient pow operation c api,2017-12-09 20:09:30,1512850170,resolved fixed,e1ded7fa7cfacaeea43a903e738dd3fe2baabc57,1514263731,tensorflow\cc\gradients\math_grad.cc tensorflow\cc\gradients\math_grad_test.cc                                                          
45,15345,Using wrong location for x86_64 android build,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu osx tensorflow installed source binary source tensorflow version use command python version bazel version compiling source gcc compiler version compiling source configured prefix applications xcode app contents developer usr gxx include dir usr include c apple llvm version clang target x86 apple darwin17 thread model posix installeddir applications xcode app contents developer toolchains xcodedefault xctoolchain usr bin cuda cudnn version gpu model memory exact command reproduce make f tensorflow contrib makefile makefile target android android arch x86 describe problem android x86 build fails makefile using make f tensorflow contrib makefile makefile target android android arch x86 find binary x86 linux android g fixed changing tensorflow contrib makefile makefile line bin prefix x86 linux android bin prefix x86 linux android,2017-12-13 18:38:09,1513190289,resolved fixed,df9189cc4671facfecd3e8249c9e8b01b11c0df5,1513197698,tensorflow\contrib\makefile\Makefile                                                            
46,15611,'saved_model_cli.py' bug fix!,file python tool saved model cli py function def print tensor info tensor info first line print dtype value key key value type pb2 datatype item tensor info dtype print dtype type pb2 datatype key tensor info dtype tensor info dtype integer value type index type value,2017-12-24 09:33:59,1514108039,resolved fixed,2e2715baa84720f786b38d1f9cb6887399020d6f,1514498466,tensorflow\python\tools\BUILD tensorflow\python\tools\saved_model_cli.py tensorflow\python\tools\saved_model_cli_test.py                                                        
47,15766,tf.assert_equal raises incorrect traceback in Eager mode,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu lts tensorflow installed source binary pip binary tensorflow version use command dev20171227 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version none gpu model memory none exact command reproduce python main py describe problem eager mode tf assert equal show traceback message two input different however graph mode show different value message source code log import tensorflow tf import tensorflow contrib eager tfe tfe enable eager execution x tf constant tf constant tf control dependency tf assert equal x output tf reduce sum x eager mode traceback traceback recent call last file users matt pycharmprojects scratch main py line tf control dependency tf assert equal x file usr local var pyenv version anaconda3 lib python3 site package tensorflow python ops check ops py line assert equal summary msg tensorflow python framework error impl invalidargumenterror condition x hold indices first different value corresponding x value corresponding value graph mode traceback traceback recent call last file users matt pycharmprojects scratch main py line tf control dependency tf assert equal x file usr local var pyenv version anaconda3 lib python3 site package tensorflow python ops check ops py line assert equal assert static condition static data file usr local var pyenv version anaconda3 lib python3 site package tensorflow python ops check ops py line assert static message n join data static tensorflow python framework error impl invalidargumenterror condition x hold element wise x const const,2018-01-01 09:43:43,1514799823,resolved fixed,89cd0cd81ae829610fcbf4437597451ae5a59fe6,1514939720,tensorflow\python\kernel_tests\check_ops_test.py tensorflow\python\ops\check_ops.py                                                          
48,15882,"tfdbg error ""Dump root directory does not exist"" with empty fetches",system information written custom code yes os platform distribution linux ubuntu tensorflow installed binary pip install tensorflow version tensorflow import tf version tf git version v1 ga52c8d9 tf compiler version v1 ga52c8d9 sanity check array dtype int32 python version cuda cudnn version cuda libs usr local cuda target x86 linux lib libcudart static usr local cuda target x86 linux lib libcudart usr local cuda doc man man7 libcudart usr local cuda doc man man7 libcudart usr local cuda target x86 linux lib libcudart usr local cuda target x86 linux lib libcudart static usr local cuda doc man man7 libcudart usr local cuda doc man man7 libcudart gpu model memory geforce gtx exact command reproduce see code describe problem localclidebugwrappersession run behave like tf session run fetch dump directory never created crash ioerror issue occured situation like session run var initializer var initialized checkpoint actually everything restored checkpoint empty code run fine ordinary tf session crashed tfdbg took time track issue hard fix would nice keep user pain maybe speculating crash reason source code log import tensorflow tf tensorflow python import debug tf debug sess tf session dbg sess tf debug localclidebugwrappersession tf session print sess run tf constant print sess run print dbg sess run tf constant print dbg sess run ioerror dump root directory tmp tfdbg ai awv exist,2018-01-05 15:34:48,1515166488,resolved fixed,1f26c65254268730b7409f517d1ed1b554d01e50,1517250785,tensorflow\python\debug\wrappers\dumping_wrapper_test.py tensorflow\python\debug\wrappers\framework.py tensorflow\python\debug\wrappers\local_cli_wrapper_test.py                                                        
49,15891,Dependencies of tensors created within a tf.while_loop() might not be executed,system information written custom code opposed using stock example script provided tensorflow yes see test case os platform distribution e g linux ubuntu macos sierra version tensorflow installed source binary compiled tensorflow small change pr also tried using pip package tensorflow version use command v1 ga52c8d9b01 pip package python version bazel version compiling source homebrew gcc compiler version compiling source apple llvm version clang cuda cudnn version cuda mac cudnn osx x64 v7 gpu model memory nvidia geforce gt mb device memory cuda compute capability exact command reproduce python repro py repro py contains test case reproduce listed describe problem test case part future import division print function import numpy np import tensorflow tf tensorflow python ops import resource variable ops rr r np random randomstate seed r normal size print singular value np linalg svd compute uv false b r normal size print singular value b np linalg svd b compute uv false part ii var tf variable b init var op tf assign var dep tf constant tf int32 tf control dependency init var op dep dep tf control dependency dep var tf svd var compute uv false tf session session session run tf global variable initializer computed computed dep session run var dep print computed computed dep computed computed dep part iii var tf variable b init var op tf assign var dep tf constant tf int32 def loop condition j dep return j def loop body j dep tf control dependency init var op dep dep return j dep dep tf loop loop condition loop body loop var tf constant tf int32 dep parallel iteration back prop false tf control dependency dep var tf svd var compute uv false tf session session session run tf global variable initializer computed computed dep session run var dep print computed computed dep computed computed dep part iv var rr resourcevariable b init var op var assign dep tf constant tf int32 def loop condition j dep return j def loop body j dep tf control dependency init var op dep dep return j dep dep tf loop loop condition loop body loop var tf constant tf int32 dep parallel iteration back prop false tf control dependency dep var tf svd var read value compute uv false tf session session session run tf global variable initializer computed computed dep session run var dep print computed computed dep computed computed dep part basic setup create two random matrix compute singular value singular value singular value b part ii show usage control dependency guarantee assigned var singular value var computed output part computed computed dep expected result part ii part iii introduced use tf loop tf svd returning singular value b computed computed dep expected result part iii expect singular value would printed part iv based reading comment switched using however output still singular value computed computed dep expected result part iv expect singular value would printed appears issue tf control dependency tensor created tf loop might execute tensor dependency used work okay around tensorflow recall correctly searching previous report issue found appears related sample code tf loop creates tensor dependency run sample code consistently get result unexpected result opinion happening run exactly loop iteration value tried rewriting sample code use resourcevariable output future import division print function import tensorflow tf tensorflow python ops import resource variable ops rr tf variable scope state x rr resourcevariable tf constant dtype tf float32 update x x assign x read value def iter fun comment line program run without error need control dependency least way replace tf control dependency update x tf print x read value x x read value return tf variable scope iteration num iteration initial tf constant dtype tf int32 initial tf constant dtype tf float32 result tf loop cond lambda num iteration body iter fun loop var initial initial init op tf global variable initializer tf session sess sess run init op print sess run result,2018-01-05 21:51:29,1515189089,resolved fixed,f8f921c828fb2c97da7c7b80c01390ccec90ae40,1517864895,tensorflow\python\kernel_tests\control_flow_ops_py_test.py tensorflow\python\ops\control_flow_ops.py                                                          
50,16100,Exception when not providing optional parameter frequency_skip in TimeFreqLSTMCell,system information written custom code opposed using stock example script provided tensorflow yes see os platform distribution tensorflow installed pip3 install user tensorflow gpu tensorflow version python version cuda gpu nvidia titan x describe problem using timefreqlstmcell dynamic rnn static rcnn without providing optional parameter frequency skip result exception typeerror unsupported operand type int nonetype line throw exception tensorflow tensorflow contrib rnn python ops rnn cell py lines num feat int input size self feature size self frequency skip frequency skip default value none maybe default changed source code log sadly allowed share full source code however create rnn layer lstmcell tf contrib rnn timefreqlstmcell lstm input shape list forget bias self lstm forget bias feature size lstm input rev shape list stacked lstm tf nn rnn cell multirnncell lstmcell self layer lstm lstm output lstm state tf nn dynamic rnn stacked lstm lstm input rev dtype float32 time major true,2018-01-13 12:20:41,1515846041,resolved fixed,4b6abfd95254910d01e886123cd24c29f722e8d7,1516652834,tensorflow\contrib\rnn\python\ops\rnn_cell.py                                                            
51,16152,DeprecationWarning from `inspect.getargspec()`,deprecated python solved problem kera like kera team kera system information using tensorflow kera backend kera linux ubuntu installed conda version python describe problem recently switched theano tensorflow warning message filling test output source code log home conda envs lib python3 site package tensorflow python util tf inspect py deprecationwarning inspect getargspec deprecated use inspect signature inspect getfullargspec,2018-01-16 09:41:53,1516095713,resolved fixed,1744b8c0519cec31764d205b813bd4fd6028cbf9,1525968464,tensorflow\python\util\tf_inspect.py                                                            
52,16163,Dataset.from_generator doesn't release memory after recreating the session,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command rc0 python version python bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory exact command reproduce see describe problem closing session creating new one iterator creates generator instance free memory previous one every calling line session run x see increase memory consumption script mib first mib second mib third see delta equal mib n sizeof data dtype data dtype float64 source code log import numpy np import tensorflow tf n def generate data np random rand n k range n yield data k copy graph tf graph graph default x tf data dataset generator generate tf float32 make one shot iterator get next true session tf session graph graph session run x put breakpoint careful running code without session close,2018-01-16 16:55:16,1516121716,resolved fixed,be862d5b91e9b9044f4e028dcdae0b6ad283e8b4,1519165089,tensorflow\core\api_def\base_api\api_def_GeneratorDataset.pbtxt tensorflow\core\kernels\data\BUILD tensorflow\core\kernels\data\captured_function.cc tensorflow\core\kernels\data\captured_function.h tensorflow\core\kernels\data\generator_dataset_op.cc tensorflow\core\ops\dataset_ops.cc tensorflow\python\data\kernel_tests\dataset_from_generator_op_test.py tensorflow\python\data\ops\dataset_ops.py                                              
53,16167,Documentation Method Templates Improvement,system information n describe problem method class template documentation include full functioning path method instead truncating method name e present bad practical copy paste friendly version constantly grabbing method template pasting text editor coming back doc copy paste package path header page awful workflow source code log n,2018-01-16 19:28:06,1516130886,resolved fixed,a1a34b1440c4c4792f945275529e6c5b3c7aa2ca,1517533748,tensorflow\tools\docs\pretty_docs.py                                                            
54,16238,//tensorflow/contrib/gan:losses_impl_test fails with AssertionError,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu s390x tensorflow installed source binary source tensorflow version use command v1 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu gpu model memory na exact command reproduce bazel test c opt tensorflow contrib gan loss impl test describe problem one sub test test stable global norm unchanged fails s390x assertionerror seems like minor difference tried changing tolerance slightly self assertnear gnorm np precond gnorm np self assertnear gnorm np precond gnorm np test passing ok create pr change could please share thought source code log f fail test stable global norm unchanged main combineadversariallosstest test preconditioning change global norm value traceback recent call last file home test cache bazel bazel test execroot org tensorflow bazel local opt bin tensorflow contrib gan loss impl test runfiles org tensorflow tensorflow contrib gan python loss python loss impl test py line test stable global norm unchanged self assertnear gnorm np precond gnorm np file home test cache bazel bazel test execroot org tensorflow bazel local opt bin tensorflow contrib gan loss impl test runfiles org tensorflow tensorflow python framework test util py line assertnear msg none else assertionerror ran test failed failure,2018-01-19 10:25:54,1516357554,resolved fixed,4383f3d002ddb0712a7aac3303cde6e599de65eb,1516944645,tensorflow\contrib\gan\python\losses\python\losses_impl_test.py                                                            
55,16481,Container localhost does not exist.,hi upgraded rc1 current master branch started receiving following error w tensorflow core framework op kernel cc op requires failed lookup table op cc found container localhost exist could find resource localhost hash table users anthony development github symphony mt temp data iwslt vocab vi whole line line number w tensorflow core framework op kernel cc op requires failed iterator ops cc found container localhost exist could find resource localhost hash table users anthony development github symphony mt temp data iwslt vocab vi whole line line number node lookup lookuptablefind lookuptablefindv2 tin dt string tout dt int64 lookup placeholder input lookup placeholder exception thread main org platanios tensorflow jni notfoundexception container localhost exist could find resource localhost hash table users anthony development github symphony mt temp data iwslt vocab vi whole line line number node lookup lookuptablefind lookuptablefindv2 tin dt string tout dt int64 lookup placeholder input lookup placeholder node model model iterator next iteratorgetnext output shape output type dt int32 dt int32 dt int32 dt int32 dt int32 device job localhost replica task device cpu model model iterator hard reproduce error summary context lookup table op inside dataset map operator get error try execute corresponding iterator getnext op looking information parse debug error never explicitly set container variable lookup table e leave default value empty string change introduced recently could result error note happens scala api python api may updated something code really know look thanks,2018-01-27 07:58:18,1517039898,resolved fixed,77e6a452188e83ae4498cc3ae23e20e60061b367,1517534109,tensorflow\core\kernels\data\iterator_ops.cc tensorflow\python\data\kernel_tests\BUILD tensorflow\python\data\kernel_tests\iterator_ops_cluster_test.py                                                        
56,16747,No documentation on the order of eigenvalues returned by tf.self_adjoint_eig,system information os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary tensorflow version use command v1 rc1 g130a514 python version describe problem documentation tf self adjoint eig see order eigenvalue tried several example found sorted ascending order always hold,2018-02-04 06:48:59,1517726939,resolved fixed,6f0dd0425c51360fe2be5a938a8f3fb39e420fa3,1521239625,tensorflow\core\api_def\base_api\api_def_SelfAdjointEig.pbtxt tensorflow\core\api_def\base_api\api_def_SelfAdjointEigV2.pbtxt tensorflow\python\ops\linalg_ops.py                                                        
57,16829,tf.contrib.estimator.replicate_model_fn fails when a trainable variable doesn't have gradient,tf contrib estimator replicate model fn fails gradient trainable variable none error message file usr local lib python2 dist package tensorflow python estimator estimator py line train loss self train model input fn hook saving listener file usr local lib python2 dist package tensorflow python estimator estimator py line train model feature label model fn lib modekeys train self config file usr local lib python2 dist package tensorflow python estimator estimator py line call model fn model fn result self model fn feature feature kwargs file usr local lib python2 dist package tensorflow contrib estimator python estimator replicate model fn py line replicated model fn local p device p device file usr local lib python2 dist package tensorflow contrib estimator python estimator replicate model fn py line get loss tower optional params file model bn50000 net py line model fn train op optimizer minimize model total loss global step file usr local lib python2 dist package tensorflow python training optimizer py line minimize name name file usr local lib python2 dist package tensorflow contrib estimator python estimator replicate model fn py line apply gradient ops lib control dependency extract tensor grad var file usr local lib python2 dist package tensorflow python framework ops py line control dependency return get default graph control dependency control input file usr local lib python2 dist package tensorflow python framework ops py line control dependency c self graph element c file usr local lib python2 dist package tensorflow python framework ops py line graph element return self graph element locked obj allow tensor allow operation file usr local lib python2 dist package tensorflow python framework ops py line graph element locked type str typeerror convert nonetype tensor operation,2018-02-07 11:27:24,1518002844,resolved fixed,96564330fb0508a50a0515be11c9202c64b0f5b7,1518481694,tensorflow\contrib\estimator\python\estimator\replicate_model_fn.py tensorflow\contrib\estimator\python\estimator\replicate_model_fn_test.py                                                          
58,16954,Iterator.get_next() documentation improvement request,system information n describe problem recently written code using dataset api would like request problem documentation imo instead hardcoding comment please move mrry annotation method documentation know get beautiful warning console output think first person funny thread bomb running consuming system resource know also see comment would great could move critical annotation main documentation thinking ml newcomer rather yeah actually found solution source code log n,2018-02-12 20:20:58,1518466858,resolved fixed,620dc3f097d047346943c416823f5e370df9fe4b,1518645158,tensorflow\python\data\ops\iterator_ops.py                                                            
59,17130,Java: SIGSEGV when `Tensors.create`-ing from an uninitialized array,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos jre version java tm se runtime environment b13 build b13 tensorflow installed source binary maven org tensorflow tensorflow tensorflow version use command python version n bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n exact command reproduce junit test case public void testsigsegv byte bb new byte note new byte crash presumably initialized compile bb new byte bb new byte bb next line sigsegv tensors create bb describe problem using tensors create get tensor uninitialized byte array byte result sigsegv jni see full log source code log running test case get following output fatal error detected java runtime environment sigsegv pc pid tid jre version java tm se runtime environment b13 build b13 java vm java hotspot tm bit server vm b13 mixed mode bsd amd64 compressed oops problematic frame v libjvm dylib failed write core dump core dump disabled enable core dumping try ulimit c unlimited starting java error report file information saved users ben aglabs nfl javaprojects nlp h err pid30179 log would like submit bug report please visit process finished exit code interrupted signal sigabrt familiar enough jni general know expecting much surprised mark wontfix surprised able crash process segfault given bad data easy enough work around size init array carefully thought might want know cheers thanks much library,2018-02-19 15:01:11,1519052471,resolved fixed,624a2e47329fefa1f17373954ac541b0e42a9fca,1519162807,tensorflow\java\src\main\native\tensor_jni.cc tensorflow\java\src\test\java\org\tensorflow\TensorTest.java                                                          
60,17246,Fetching value of Variable unnecessarily slow,sess run var slower sess run var python variable fetch bug report py variable fetch cpu variable gb sec min median mean fetch cpu variable add gb sec min median mean fetch cpu variable concat gb sec min median mean tensorflow version info version dev20180221 v1 rc1 gd100729 d100729,2018-02-24 23:39:54,1519515594,resolved fixed,879fc3440495d9388754cb7d1878caf034d03d61,1528309758,tensorflow\python\lib\core\ndarray_tensor.cc                                                            
61,17284,tensor-valued seeds in tf.data API can result in nondeterministic results,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary source tensorflow version use command v1 g4588350f20 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version n gpu model memory n exact command reproduce see code describe problem tf data api allows requires seed provided tf tensor issue graph level seed set provided op level seed tensor take value noted comment code tf get seed seed problematic c ops assume mean nondeterminism course user specifying seed expecting deterministic behaviour unfortunately tf get seed check issue case seed ints tensor see code example would happy submit pr idea fix bug especially familiar code base apparent whether even possible code tf get seed check value tensor seed guessing tf data api would need provide check source code log following code reproduces bug import tensorflow tf tf set random seed seed tensor tf placeholder tf int64 shape name data seed data tf data dataset range shuffle seed seed tensor iterator tf data iterator structure tf int64 tf tensorshape init iterator make initializer data value iterator get next print first run end tf session sess1 sess1 run init feed dict seed tensor value true try value append str sess1 run value except tf error outofrangeerror break print join value print second run end tf session sess2 sess2 run init feed dict seed tensor value true try value append str sess2 run value except tf error outofrangeerror break print join value result get first run second run would expect first second run produce exact sequence though particular sequence might differ environment environment change feed dict provide value seed tensor run get expected result first run second run change shuffle call take value directly e shuffle seed get expected result well first run second run record encountered issue using iterator via iterator structure use iterator dataset shuffle get order epoch get around provided epoch number seed dataset shuffle first epoch epoch case avoid bug starting epoch count took track may case api used similar way would problematic expecting deterministic result,2018-02-26 21:15:35,1519679735,resolved fixed,f6bda409206dc642d7a6f02842e76b0be7234491,1519787833,tensorflow\contrib\data\python\ops\random_ops.py tensorflow\contrib\data\python\ops\shuffle_ops.py tensorflow\python\data\kernel_tests\shuffle_dataset_op_test.py tensorflow\python\data\ops\BUILD tensorflow\python\data\ops\dataset_ops.py tensorflow\python\data\util\BUILD tensorflow\python\data\util\random_seed.py tensorflow\python\data\util\random_seed_test.py                                              
62,17360,C++ api: use of op::Attrs methods in gradients,generated op attrs struct return new instance chainable method change original object tensorflow tensorflow cc framework cc op gen cc line d7d7f4e string strappend setter attrs ret n related issue e g tensorflow tensorflow cc gradient nn grad cc line grad attrs dataformat data format code assumes underlying object mutated parameter actually pas guess might couple way forward depending tensorflow prefers c api decide attrs chaining method mutate underlying object fix code generation decide attrs chaining method return new instance fix us suggestions fwiw option might nice add tf must use result generated api unfortunately long standing bug gcc mean may unreliable actual error across version gcc contributor may use cc suharshs keveman,2018-03-01 16:26:37,1519921597,resolved fixed,5279cf29cea96b3ec50df506bb51d8ffabdabac9,1520290163,tensorflow\cc\framework\cc_op_gen.cc tensorflow\cc\gradients\nn_grad.cc                                                          
63,17374,Potential resource leaks caused by unclear Java examples,system information java example tensorflow describe problem return list closables javadoc clearly state caller responsible free none java example found highlight realized happy accident depth reading implementation session java quite long time wrote code us tensorflow execute graph fragment necessary compute requested fetch warning caller assumes ownership returned link tensor e caller must call link tensor close element returned list free resource public list run return runhelper false output sure example self contain resource leak free first element list may general would expect explicit loop properly freeing returned resource example beginner explicit possible clear understandable anyone lot people like base core code may easily introduce significant resource leak bug application hellotf example referenced advanced example labelimage source code log none,2018-03-02 08:55:38,1519980938,resolved fixed,de72c8cccef2ee77667c041b68a34be6fb61ea65,1523496730,tensorflow\docs_src\install\install_java.md tensorflow\java\src\main\java\org\tensorflow\examples\LabelImage.java                                                          
64,1748,Optimizers incompatible with sampling -- missing docs?,hi perhaps tensorflow doc mention available optimizers work sampling loss fail mysterious message following script fail momentum adagrad adadelta rmsprop ftrl also look like implement optimizers gpu import tensorflow tf import numpy random nr import numpy np config num class num sampled num true activation dim batch sz model setup activation tf placeholder tf float32 shape none activation dim label tf placeholder tf int64 shape none num true nce w tf variable tf truncated normal num class activation dim nce b tf variable tf truncated normal num class nce loss tf reduce mean tf nn nce loss nce w nce b activation label num sampled num class num true optimizer setup global step tf variable initial alpha tf variable alpha tf variable optimizer tf train ftrloptimizer alpha fetch step optimizer minimize nce loss global step global step name sgd step init tf initialize variable synthetic data x nr randn batch sz activation dim astype np float32 nr randint num class batch sz num true astype np int64 tf session sess sess run init sess run step feed dict activation x label error message statusnotok traceback recent call last statusnotok invalid argument assign device node variable read could satisfy explicit device specification node colocated group node required incompatible device job localhost replica task gpu node variable read identity dt float class loc variable variable,2016-04-02 15:05:39,1459609539,resolved fixed,c34a0d7ea6b557588a7a0c9f9c4e60d59f593af7,1463095893,tensorflow\core\BUILD tensorflow\core\common_runtime\direct_session.cc tensorflow\core\common_runtime\direct_session.h tensorflow\core\common_runtime\direct_session_test.cc tensorflow\core\common_runtime\simple_graph_execution_state.cc tensorflow\core\common_runtime\simple_graph_execution_state.h tensorflow\core\common_runtime\simple_placer.cc tensorflow\core\protobuf\config.proto tensorflow\python\client\session.py tensorflow\python\client\session_test.py                                          
65,17614,Error command in installation guild,please go stack overflow help support small error installation guild step section site give example command installing tensorflow active virtualenv macos python actually py3 pip3 command pip3 install upgrade,2018-03-10 08:25:36,1520670336,resolved fixed,df2b8447dc026d1402e3c0cbf7c0071ad5c67178,1520746825,tensorflow\docs_src\install\install_mac.md                                                            
66,17802,Importing a meta graph which contains a SummaryWriter doesn't work,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary via pip tensorflow version use command v1 gd2e24b6039 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory gtx exact command reproduce first run import tensorflow tf v1 tf placeholder tf float32 name v1 v2 tf placeholder tf float32 name v2 v3 v1 v2 vx tf variable name vx v4 v3 vx writer tf contrib summary create file writer foo saver tf train saver vx sess tf session sess run tf initialize variable sess run vx assign tf add vx vx result sess run v4 feed dict v1 v2 print result saver save sess model ex1 different python instance work done right first snippet within instance import tensorflow tf saver tf train import meta graph model ex1 meta sess tf session saver restore sess model ex1 describe problem trying restore meta graph via import meta graph work graph contains summarywriter shown example example work import meta graph called within instance python tf contrib summary create file writer foo call removed graph source code log keyerror traceback recent call last import tensorflow tf saver tf train import meta graph model ex1 meta sess tf session saver restore sess model ex1 miniconda lib python3 site package tensorflow python training saver py import meta graph meta graph file clear device import scope kwargs clear device clear device import scope import scope kwargs meta graph def hasfield saver def return saver saver def meta graph def saver def name import scope miniconda lib python3 site package tensorflow python framework meta graph py import scoped meta graph meta graph file clear device graph import scope input map unbound input col name restore collection predicate importer import graph def input graph def name import scope input map input map producer op list producer op list restores collection miniconda lib python3 site package tensorflow python util deprecation py new func args kwargs future version date none else date instruction return func args kwargs return tf decorator make decorator func new func deprecated add deprecated arg notice docstring miniconda lib python3 site package tensorflow python framework importer py import graph def graph def input map return element name op dict producer op list producer op list none todo skyewm make copy graph def mutating argument removedefaultattrs op dict producer op list graph def graph ops get default graph miniconda lib python3 site package tensorflow python framework importer py removedefaultattrs op dict producer op list graph def remove default attr value op def node op producer op dict op def op dict node op producer op def producer op dict node op make copy node attr iterate since may modify keyerror summarywriter,2018-03-18 03:24:59,1521343499,resolved fixed,88334807a5beb8b61a967d21e534ed238e7916c0,1521516338,tensorflow\contrib\cmake\tf_python.cmake tensorflow\contrib\summary\BUILD tensorflow\contrib\summary\summary_ops.py tensorflow\core\BUILD tensorflow\core\api_def\base_api\api_def_CloseSummaryWriter.pbtxt tensorflow\core\api_def\base_api\api_def_CreateSummaryDbWriter.pbtxt tensorflow\core\api_def\base_api\api_def_CreateSummaryFileWriter.pbtxt tensorflow\core\api_def\base_api\api_def_FlushSummaryWriter.pbtxt tensorflow\core\api_def\base_api\api_def_ImportEvent.pbtxt tensorflow\core\api_def\base_api\api_def_SummaryWriter.pbtxt tensorflow\core\api_def\base_api\api_def_WriteAudioSummary.pbtxt tensorflow\core\api_def\base_api\api_def_WriteGraphSummary.pbtxt tensorflow\core\api_def\base_api\api_def_WriteHistogramSummary.pbtxt tensorflow\core\api_def\base_api\api_def_WriteImageSummary.pbtxt tensorflow\core\api_def\base_api\api_def_WriteScalarSummary.pbtxt tensorflow\core\api_def\base_api\api_def_WriteSummary.pbtxt tensorflow\core\api_def\python_api\api_def_CloseSummaryWriter.pbtxt tensorflow\core\api_def\python_api\api_def_CreateSummaryDbWriter.pbtxt tensorflow\core\api_def\python_api\api_def_CreateSummaryFileWriter.pbtxt tensorflow\core\api_def\python_api\api_def_FlushSummaryWriter.pbtxt tensorflow\core\api_def\python_api\api_def_ImportEvent.pbtxt tensorflow\core\api_def\python_api\api_def_SummaryWriter.pbtxt tensorflow\core\api_def\python_api\api_def_WriteAudioSummary.pbtxt tensorflow\core\api_def\python_api\api_def_WriteGraphSummary.pbtxt tensorflow\core\api_def\python_api\api_def_WriteHistogramSummary.pbtxt tensorflow\core\api_def\python_api\api_def_WriteImageSummary.pbtxt tensorflow\core\api_def\python_api\api_def_WriteScalarSummary.pbtxt tensorflow\core\api_def\python_api\api_def_WriteSummary.pbtxt tensorflow\core\ops\summary_ops.cc tensorflow\python\BUILD tensorflow\python\summary\summary.py
67,17932,tf.contrib.data.bucket_by_sequence_length fails for nested Dataset element,hello everyone tried new function group variable length input dataset api namely tf contrib data bucket sequence length small estimator model implemented return dataset element tuple feature dict label however run get following exception traceback recent call last file home leo anaconda3 lib python3 site package tensorflow python data ops dataset ops py line apply dataset transformation func self file home leo anaconda3 lib python3 site package tensorflow contrib data python ops grouping py line apply fn window size func window size fn file home leo anaconda3 lib python3 site package tensorflow python data ops dataset ops py line apply dataset transformation func self file home leo anaconda3 lib python3 site package tensorflow contrib data python ops grouping py line apply fn window size func file home leo anaconda3 lib python3 site package tensorflow contrib data python ops grouping py line init self make key func key func input dataset file home leo anaconda3 lib python3 site package tensorflow contrib data python ops grouping py line make key func self key func add graph ops get default graph file home leo anaconda3 lib python3 site package tensorflow python framework function py line add graph self create definition needed file home leo anaconda3 lib python3 site package tensorflow python framework function py line create definition needed self create definition needed impl file home leo anaconda3 lib python3 site package tensorflow python framework function py line create definition needed impl output self func input file home leo anaconda3 lib python3 site package tensorflow contrib data python ops grouping py line tf key func ret key func nested args typeerror element bucket id take positional argument given link function code snipped reproduce error import tensorflow tf def input fn def generator text label x zip text label yield x dataset tf data dataset generator generator generator output shape tf tensorshape none tf tensorshape output type tf int32 tf int32 dataset dataset map parse example dataset dataset apply tf contrib data bucket sequence length element length func element length fn bucket batch size bucket boundary pad bucket boundary false return dataset def parse example x return dict x x def element length fn element feature label element return tf shape feature x name main tf session sess dataset input fn iter dataset make one shot iterator print sess run iter get next env specs logged tf env txt thanks advance,2018-03-22 19:22:53,1521746573,resolved fixed,2219b88a3d5154b9158a1902b061cad6cae2d0a8,1521972000,tensorflow\contrib\data\python\kernel_tests\bucketing_test.py tensorflow\contrib\data\python\ops\grouping.py                                                          
68,17946,Formatting issue in tf debugger documentation,faq section seem markdown formatting problem,2018-03-23 09:20:00,1521796800,resolved fixed,cde06a39592a849a2bc0ba022e858e6366c87cc5,1522973669,tensorflow\docs_src\programmers_guide\debugger.md                                                            
69,17949,incorrect description of num_sampled parameter in tf.nn.nce_loss() function: num_sampled is number of negative examples per 1 positive example (NOT per batch),hi looks like parameter function defines number negative example per positive example per batch described tensorflow documentation see next code import tensorflow tf import numpy np compute sampled logits invoked nce loss generate negative sample calculate logits tensorflow python ops nn impl import compute sampled logits embedding size word number batch size num sampled graph tf graph graph default input data train input tf placeholder tf int32 shape batch size train label tf placeholder tf int64 shape batch size tf device cpu embeddings tf variable tf random uniform word number embedding size embed tf nn embedding lookup embeddings train input nce weight tf variable tf random uniform word number embedding size nce bias tf variable tf zero word number logits label compute sampled logits weight nce weight bias nce bias input embed label train label num true num sampled num sampled num class word number remove accidental hit false init tf global variable initializer session tf interactivesession graph graph init run session session batch input np array dtype np int32 batch label np array dtype np int32 feed dict train input batch input train label batch label logits val label val session run logits label feed dict feed dict print logits val format logits val print label val format label val result compute sampled logits function generated num sampled example per positive example logits val label val,2018-03-23 11:54:29,1521806069,resolved fixed,600caf99897e82cd0db8665acca5e7630ec1a292,1534794156,tensorflow\python\ops\nn_impl.py                                                            
70,18094,"`tf.keras.estimator._create_ordered_io` casts everything to floatx, which breaks non-floatx inputs",system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu debian tensorflow installed source binary installed via pip tensorflow version use command v1 gd2e24b6039 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version n gpu model memory n exact command reproduce requires significant code let know necessary describe problem kind simple issue using keras model tensorflow estimators unfortunately need awkward conversion order use sagemaker even awkwardly behind two version tensorflow fun basically model expects input passed lookup layer text embeddings work fine keras model work fine extract input layer connect estimator however go create estimator model using run code path conversion cause model break line sure float cast occurs commit diff seems imply keras model meant take floatx input really seem right would cast break anything way use non float32 input keras model need converted estimators thanks source code log exact traceback issue home u1 zach proj dataplayground2 local lib python2 site package h5py init py futurewarning conversion second argument issubdtype float np floating deprecated future treated np float64 np dtype float type conv import register converter register converter warning tensorflow using temporary folder model directory tmp tmp6wogzk tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma warning tensorflow output final representation missing loss dictionary assume done purpose expecting data passed final representation training warning tensorflow output oov code missing loss dictionary assume done purpose expecting data passed oov code training testing common estimator fns py locally making estimator model dir tmp tmp6wogzk training estimator float64 tensor random shuffle queue dequeuemany shape dtype string device device cpu traceback recent call last file common estimator fns py line hook tf debug localclidebughook file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python estimator estimator py line train loss self train model input fn hook saving listener file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python estimator estimator py line train model feature label model fn lib modekeys train self config file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python estimator estimator py line call model fn model fn result self model fn feature feature kwargs file common estimator fns py line model fn return kera model fn feature label mode file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python kera impl kera estimator py line model fn label file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python kera impl kera estimator py line clone build model model model clone model kera model input tensor input tensor file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python kera impl kera model py line clone model return clone functional model model input tensor input tensor file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python kera impl kera model py line clone functional model output tensor topology list layer computed tensor kwargs file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python kera impl kera engine topology py line call output super layer self call input kwargs file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python layer base py line call self assert input compatibility input file home u1 zach proj dataplayground2 local lib python2 site package tensorflow python layer base py line assert input compatibility found dtype str x dtype valueerror input layer lookedup incompatible layer expected dtype found dtype provide code absolutely necessary take work get minimal reproduction,2018-03-29 18:13:25,1522347205,resolved fixed,3fa8795c511931b55a9703956bdf564fde817c2a,1524265841,tensorflow\python\keras\_impl\keras\estimator.py tensorflow\python\keras\_impl\keras\estimator_test.py                                                          
71,18180,Eager: tf.size() does not respect `out_type`,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n exact command reproduce import tensorflow tf tf enable eager execution print tf size dtype describe problem per documentation tf size returned tensor default optionally overridden providing argument however snippet return tensor related stackoverflow question used resulting tensor long story short buggy discrepancy eager execution graph construction likely introduced commit cc alextp,2018-04-02 17:10:21,1522689021,resolved fixed,46df4a1afd50f69966e63245e7758cc0d5656c4e,1522695835,tensorflow\python\kernel_tests\array_ops_test.py tensorflow\python\ops\array_ops.py                                                          
72,1853,shuffle_batch gives ZeroDivisionError when computing capacity stat,import tensorflow tf raw tf one tf train shuffle batch raw batch size capacity min dequeue seed fails zerodivisionerror traceback recent call last import tensorflow tf raw tf one tf train shuffle batch raw batch size capacity min dequeue seed users yaroslav anaconda envs tim jan17 lib python3 site package tensorflow python training input py shuffle batch tensor batch size capacity min dequeue num thread seed enqueue many shape allow smaller final batch shared name name allow smaller final batch allow smaller final batch shared name shared name name name users yaroslav anaconda envs tim jan17 lib python3 site package tensorflow python training input py shuffle batch tensor batch size capacity min dequeue keep input num thread seed enqueue many shape allow smaller final batch shared name name full math ops cast math ops maximum queue size min dequeue dtypes float32 capacity min dequeue note name contains end intentionally place unlike tf tensor python handle float division zero one solution wrap capacity min dequeue tf tensor get inf result instead runtimeerror,2016-04-11 17:40:39,1460396439,resolved fixed,70ade1b64f65d0a2275672d27129627ff116a997,1497398301,tensorflow\python\training\input.py                                                            
73,18769,"InvalidArgumentError for save/restore of variables (same version, same OS, same directory)",get invalidargumenterror information try save restore part model later continue training due needing laptop class initialization saver tf train saver embeddings embeddings weight nce weight bias nce bias save saver save sess model checkpoint path load saver restore sess model checkpoint path w tensorflow core framework op kernel cc op requires failed save restore v2 ops cc invalid argument users nroth documents trained model embeddings ckpt data invalid argument traceback recent call last file users nroth tf python lib python3 site package tensorflow python client session py line call return fn args file users nroth tf python lib python3 site package tensorflow python client session py line run fn option feed dict fetch list target list run metadata file users nroth tf python lib python3 site package tensorflow python client session py line call tf sessionrun status run metadata file users nroth tf python lib python3 site package tensorflow python framework error impl py line exit c api tf getcode self status status tensorflow python framework error impl invalidargumenterror users nroth documents trained model embeddings ckpt data invalid argument node save restorev2 restorev2 dtypes dt float dt float dt float device job localhost replica task device cpu arg save const save restorev2 tensor name save restorev2 shape slice invalidargumenterror see traceback users nroth documents trained model embeddings ckpt data invalid argument node save restorev2 restorev2 dtypes dt float dt float dt float device job localhost replica task device cpu arg save const save restorev2 tensor name save restorev2 shape slice yes modified code work tensorflow use embeddings variable document word average instead concatenation also updated saved variable include nce weight nce bias training may resumed macos pip virtualenv according instruction na na na saver tf train saver embeddings embeddings weight nce weight bias nce bias saver restore sess trained model saved stuff,2018-04-22 06:03:46,1524377026,resolved fixed,f2be10a6d278f9a4546fa9cded94074959e67302,1557280877,tensorflow\core\platform\posix\posix_file_system.cc                                                            
74,19043,Code documetnantion. Probably misprint in function parameter description.,tensorflow tensorflow contrib slim python slim learning py line a44996a log every n step frequency term global step loss believe typo description penultimate word probably worth replacing example log every n step frequency term global step loss global step logged,2018-05-03 01:09:21,1525309761,resolved fixed,ebcde41d721ec554a7840cb18e4e8a7a489e424a,1525371220,tensorflow\contrib\slim\python\slim\learning.py                                                            
75,19360,tf.split's -1 support doesn't handle zero dimensions,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu colab tensorflow installed source binary colab tensorflow version use command unknown python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n exact command reproduce tf split tf zero axis describe problem variable size version tf split splitv c allows one size corresponding output expand necessary total output size match input unfortunately support currently assumes dimension corresponds positive size handle zero well e g work tf split tf zero axis traceback recent call last file users irving anaconda envs openai lib python3 site package tensorflow python framework ops py line create c op c op c api tf finishoperation op desc tensorflow python framework error impl invalidargumenterror sum output size must match size original tensor along split dimension sum positive size must le contains split op splitv input shape computed input tensor input input comparison positive case work fine tf split tf zero axis,2018-05-17 20:28:10,1526588890,resolved fixed,88ba64b668044c5cb776fa27c8429e2c0e64e665,1533833099,tensorflow\core\ops\array_ops.cc tensorflow\python\kernel_tests\split_op_test.py                                                          
76,19496,Segfault with rpc ops in eager mode,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary pip tensorflow version use command python version bazel version compiling source na gcc compiler version compiling source na cuda cudnn version na gpu model memory na exact command reproduce see describe problem rpc ops rpc try rpc working eager mode see minimal example source code log non eager version work import tensorflow tf tensorflow contrib rpc python ops gen rpc op import try rpc tf graph default response try rpc localhost test simple message protocol grpc session tf interactivesession print session run response feed dict eager version result segfault import tensorflow tf tensorflow contrib rpc python ops gen rpc op import try rpc tf enable eager execution response try rpc localhost test simple message protocol grpc,2018-05-23 11:18:27,1527074307,resolved fixed,2c75dbfd2d37a3c06d34cc4b12682a63a75503f7,1527642775,tensorflow\core\util\rpc\call_container.h                                                            
77,19499,tf.data.Dataset iterators are not cleaned when the loop ends with a break,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu centos7 tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory exact command reproduce describe problem tf data dataset iterators cleaned loop end break code open one file per epoch eventually hit system limit maximum number open file replacing break continue work better since file closed however inefficient need iterate small fraction data source code log dataset tf data textlinedataset fp epoch xrange epoch batch x dataset batch batch max batches break,2018-05-23 13:47:21,1527083241,resolved fixed,70674b950ab48f913ed1c99e48c4162287595d46,1527615411,tensorflow\core\api_def\base_api\api_def_AnonymousIterator.pbtxt tensorflow\core\api_def\python_api\api_def_AnonymousIterator.pbtxt tensorflow\core\kernels\data\iterator_ops.cc tensorflow\core\ops\dataset_ops.cc tensorflow\python\data\kernel_tests\reader_dataset_ops_test.py tensorflow\python\data\ops\iterator_ops.py                                                  
78,19551,Cannot use AdagradOptimizer with MirroredStrategy,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary tensorflow version use command v1 g93bc2e2072 python version bit bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory nvidia gtx gb exact command reproduce python train model py describe problem took work going seems tf train adagradoptimizer specific implementation detail cause error used mirroredstrategy spot check gradientdescentoptimizer rmspropoptimizer appear work environment happy use different optimizer workaround thought least might save others time hunting cause error source code log almost exactly copied example except choice optimizer import tensorflow tf def model fn feature label mode layer tf layer dense logits layer feature mode tf estimator modekeys predict prediction logits logits return tf estimator estimatorspec mode prediction prediction loss tf loss mean squared error label label prediction tf reshape logits mode tf estimator modekeys eval return tf estimator estimatorspec mode loss loss mode tf estimator modekeys train train op tf train adagradoptimizer minimize loss return tf estimator estimatorspec mode loss loss train op train op def input fn feature tf data dataset tensor repeat label tf data dataset tensor repeat return tf data dataset zip feature label distribution tf contrib distribute mirroredstrategy config tf estimator runconfig train distribute distribution classifier tf estimator estimator model fn model fn config config classifier train input fn input fn log output tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core common runtime gpu gpu device cc found device property name geforce gtx major minor memoryclockrate ghz pcibusid totalmemory freememory tensorflow core common runtime gpu gpu device cc found device property name geforce gtx major minor memoryclockrate ghz pcibusid totalmemory freememory tensorflow core common runtime gpu gpu device cc adding visible gpu device tensorflow core common runtime gpu gpu device cc device interconnect streamexecutor strength edge matrix tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc n n tensorflow core common runtime gpu gpu device cc n n tensorflow core common runtime gpu gpu device cc created tensorflow device job localhost replica task device gpu mb memory physical gpu device name geforce gtx pci bus id compute capability tensorflow core common runtime gpu gpu device cc created tensorflow device job localhost replica task device gpu mb memory physical gpu device name geforce gtx pci bus id compute capability warning tensorflow using temporary folder model directory tmp tmpqglycjzk tensorflow core common runtime gpu gpu device cc adding visible gpu device tensorflow core common runtime gpu gpu device cc device interconnect streamexecutor strength edge matrix tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc n n tensorflow core common runtime gpu gpu device cc n n tensorflow core common runtime gpu gpu device cc created tensorflow device device gpu mb memory physical gpu device name geforce gtx pci bus id compute capability tensorflow core common runtime gpu gpu device cc created tensorflow device device gpu mb memory physical gpu device name geforce gtx pci bus id compute capability traceback recent call last file train model py line classifier train input fn input fn file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python estimator estimator py line train loss self train model input fn hook saving listener file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python estimator estimator py line train model return self train model distributed input fn hook saving listener file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python estimator estimator py line train model distributed self config file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python training distribute py line call tower return self call tower fn args kwargs file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow contrib distribute python mirrored strategy py line call tower coord join thread file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python training coordinator py line join six reraise self exc info raise file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package six py line reraise raise value file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python training coordinator py line stop exception yield file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow contrib distribute python mirrored strategy py line call tower self merge args merge kwargs file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python training optimizer py line distributed apply self create slot var list file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python training adagrad py line create slot ops colocate v file home aeiq pyenv version lib python3 contextlib py line enter return next self gen file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python framework ops py line colocate gradient self colocate op ignore existing file home aeiq pyenv version lib python3 contextlib py line enter return next self gen file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python framework ops py line colocate op internal convert tensor indexed slice op ref true op file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python framework ops py line internal convert tensor indexed slice value dtype dtype name name ref ref file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow python framework ops py line internal convert tensor ret conversion func value dtype dtype name name ref ref file home aeiq local share virtualenvs echoiq hw9bcz4a lib python3 site package tensorflow contrib distribute python value py line tensor conversion assert ref assertionerror,2018-05-25 05:39:45,1527226785,resolved fixed,d0b51d7d9d50dd73c46ba2f2daaa9d26cc0666d0,1534532593,tensorflow\python\ops\variable_scope.py tensorflow\python\training\adagrad.py tensorflow\python\training\adagrad_test.py                                                        
79,20516,Cannot restore variables with Checkpoint because keys do not align,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu win10 tensorflow installed source binary binary tensorflow version use command tf nightly dev20180609 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory exact command reproduce get error thrown provide code reproduce basically happens class inherits checkpointable assigns variable make checkpointable also assigns optimizer save model restore calling assert consumed load status object restore dir session throw error key match variable try restore actually saved checkpoint different key one get enumerate self checkpoint object graph proto node describes good sorry able share code tried reproduce far believe bug call ckpt save immediately ckpt restore get exception output self checkpoint object proto id key line see key missing idk thesis one need restore output util serialize object graph self checkpoint none restore assert consumed node child node id local name model child node id local name save counter node child node id local name global step pretrain child node id local name embedding child node id local name cell child node id local name dense child node id local name optimizer child local name checkpoint node attribute name variable value full name initialize restore save counter checkpoint key save counter attributes variable value node attribute name variable value full name conditionedlstmgenerator2 conditioned lstm pretrain global step checkpoint key model global step pretrain attributes variable value node attribute name variable value full name conditionedlstmgenerator2 conditioned lstm embedding checkpoint key model embedding attributes variable value node child node id local name kernel child node id local name bias attribute name object config json checkpoint key model cell attributes object config json node child node id local name kernel child node id local name bias attribute name object config json checkpoint key model dense attributes object config json node child node id local name beta1 power child node id local name beta2 power slot variable original variable node id slot name slot variable node id slot variable original variable node id slot name slot variable node id slot variable original variable node id slot name slot variable node id slot variable original variable node id slot name slot variable node id slot variable original variable node id slot name slot variable node id slot variable original variable node id slot name v slot variable node id slot variable original variable node id slot name v slot variable node id slot variable original variable node id slot name v slot variable node id slot variable original variable node id slot name v slot variable node id slot variable original variable node id slot name v slot variable node id,2018-07-03 12:25:05,1530620705,resolved fixed,f46627f9ed9cd41b5a1ad9cebbdd4c240846c4e0,1530642736,tensorflow\python\training\checkpointable\base.py tensorflow\python\training\checkpointable\tracking_test.py tensorflow\python\training\checkpointable\util_test.py                                                        
80,21277,Using TensorFlow's Datasets API causes process to hang in session destructor,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos high sierra though also seen happen linux well believe tensorflow installed source binary source happens binary version well tensorflow version use command v1 g93bc2e2072 python version python v3 mar bazel version compiling source gcc compiler version compiling source apple llvm version clang cuda cudnn version n gpu model memory n exact command reproduce unfortunately issue easy reproduce without running application managed produce smaller test case describe problem summary using tensorflow datasets api specifically using tf data dataset generator create dataset based generator function python come garbage collect tf session object destructor make call tensorflow delete session tf session tf deletesession call hang trying execute tf py func function acquire python global interpreter lock function trying execute appears finalize function dataset look like bug tensorflow understanding able write code cause happen although clearly consequence specific use tensorflow see anything application details tf session object garbage collected python destructor del method hang indefinitely problem appears call basesession tf session tf deletesession self session running lldb show following stack trace thread queue com apple main thread stop reason signal sigstop frame libsystem kernel dylib psynch cvwait frame libsystem pthread dylib pthread cond wait frame libc dylib std condition variable wait std unique lock frame libtensorflow framework nsync nsync mu semaphore p deadline nsync nsync semaphore timespec frame libtensorflow framework nsync nsync cv wait deadline generic nsync nsync cv void void void void void timespec nsync nsync note frame libtensorflow framework nsync nsync cv wait nsync nsync cv nsync nsync mu frame pywrap tensorflow internal tensorflow notification waitfornotification frame pywrap tensorflow internal tensorflow capturedfunction runinstantiated std vector const std vector frame pywrap tensorflow internal tensorflow anonymous namespace generatordatasetop dataset iterator iterator frame pywrap tensorflow internal tensorflow anonymous namespace generatordatasetop dataset iterator iterator frame pywrap tensorflow internal tensorflow anonymous namespace flatmapdatasetop dataset iterator iterator frame pywrap tensorflow internal tensorflow anonymous namespace flatmapdatasetop dataset iterator iterator frame libc dylib std shared weak count release shared frame pywrap tensorflow internal tensorflow anonymous namespace iteratorresource iteratorresource frame pywrap tensorflow internal tensorflow anonymous namespace iteratorresource iteratorresource frame libtensorflow framework tensorflow resourcemgr dodelete std basic string std allocator const unsigned long long std basic string std allocator const std basic string std allocator const frame libtensorflow framework tensorflow resourcemgr dodelete std basic string std allocator const std type index std basic string std allocator const frame pywrap tensorflow internal tensorflow anonymous namespace oneshotiteratorop oneshotiteratorop frame pywrap tensorflow internal tensorflow anonymous namespace oneshotiteratorop oneshotiteratorop frame libtensorflow framework tensorflow opsegment item item frame libtensorflow framework tensorflow opsegment removehold std basic string std allocator const frame pywrap tensorflow internal tensorflow directsession directsession frame pywrap tensorflow internal tensorflow directsession directsession frame pywrap tensorflow internal tf deletesession frame pywrap tensorflow internal wrap tf deletesession object object frame python pycfunction fastcalldict frame python call function frame python pyeval evalframedefault frame python pyfunction fastcalldict frame python pyobject fastcalldict frame python pyobject call prepend frame python pyobject fastcalldict frame python slot tp finalize frame python collect frame python pygc collectifenabled frame python py finalizeex frame python py exit frame python handle system exit frame python pyerr printex frame python pyrun simplestringflags frame python py main frame python frame python appears session destructor waiting op complete culprit seems pyfuncop get past line py threadstate pygilstate ensure look like op trying acquire gil assumption py func finalize function dataset generatordataset assumption python call tf session tf deletesession self session gil released pyfuncop able acquire indeed write isolated test try reproduce see problem gil acquired successfully unfortunately mention unsuccessful writing isolated test case reproduce problem problem seems happen use application particular scenario able isolate exactly scenario cause problem,2018-07-31 13:23:01,1533043381,resolved fixed,8cd2d6fe9389e93a4182ae9287f2f8325913fe6c,1533159075,tensorflow\python\lib\core\py_func.cc                                                            
81,22013,tf.scatter_nd_update - Segmentation fault (core dumped),system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary source tensorflow version use command tf checkpoint built tmp tensorflow git log commit author unique tensorflower date sun aug compat update forward compatibility horizon piperorigin revid cat etc issue linux generic ubuntu smp wed mar utc x86 x86 x86 gnu linux version lts xenial xerus version id version codename xenial docker yes compiler c ubuntu copyright c free software foundation inc free software see source copying condition warranty even merchantability fitness particular purpose uname linux generic ubuntu smp wed mar utc x86 x86 x86 gnu linux check pip numpy protobuf tensorflow check virtualenv false tensorflow import tf version tf git version b unknown tf compiler version b unknown sanity check array dtype int32 env ld library path usr local cuda lib64 stub usr local cuda extra cupti lib64 usr local cuda lib64 stub usr local cuda lib64 stub usr local cuda extra cupti lib64 lib amd64 server usr lib jvm java openjdk amd64 jre lib amd64 server opt boost lib opt conda lib usr local cuda lib64 opt conda lib r lib usr local nvidia lib64 usr local nvidia lib lib x86 linux gnu usr local cuda extra cupti lib64 usr lib x86 linux gnu opt opencv lib dyld library path unset nvidia smi wed aug nvidia smi driver version gpu name persistence bus id disp volatile uncorr ecc fan temp perf pwr usage cap memory usage gpu util compute geforce gtx n p0 default processes gpu memory gpu pid type process name usage cuda libs usr local cuda target x86 linux lib libcudart usr local cuda target x86 linux lib libcudart static bazel version bazel version warning batch mode deprecated please instead explicitly shut bazel server using command bazel shutdown build label build target bazel k8 opt bin src main java com google devtools build lib bazel bazelserver deploy jar build time tue jul build timestamp build timestamp int cudnn version nvcc version nvcc nvidia r cuda compiler driver copyright c nvidia corporation built tue jun cdt cuda compilation tool release v9 gpu geforce gtx gigabyte aorus exact command reproduce future import absolute import future import division future import print function import tensorflow tf def scope print ds1 scope tf variable scope scope reuse tf auto reuse x tf get variable x initializer lambda tf zero shape dtype tf float32 dtype tf float32 trainable false use resource true print graph format x graph print scope format tf get variable scope name print name format x name print var format str x current scope tf get variable scope assign one tf assign x name x one def scope input label print initial scope format tf get variable scope name print ds1 scope tf variable scope scope reuse tf auto reuse tf variable scope current scope reuse tf auto reuse tf get variable x initializer lambda tf zero shape dtype tf float32 dtype tf float32 trainable false use resource true print graph format graph print scope format tf get variable scope name print name format name print var format str print print print input assign two tf assign tf add tf cast input dtype tf float32 name input plus assign two tf identity tf assign tf add tf cast input dtype tf float32 tf control dependency assign two tf control dependency tf scatter nd update return read value label return x label test original x mutable tf control dependency assign one dataset tf data dataset tensor slice map scope batch repeat return dataset tf variable scope scope dataset fn scope tf variable scope iterator define iterator string handle general useful kind iterator one want switch train validation within training loop iterator dataset fn make initializable iterator iterator handle tf placeholder tf string shape name iterator handle iterator tf data iterator string handle iterator handle iterator output type iterator output shape def get next item next elem iterator get next name next element x tf cast next elem tf float32 next elem tf cast next elem tf int32 return x tf session sess sess run tf global variable initializer tf local variable initializer handle sess run iterator string handle run data iterator initialisation sess run iterator initializer print sess graph get operation true try print sess run get next item feed dict iterator handle handle except tf error outofrangeerror print end training dataset break print print global var format tf global variable print local var format tf local variable print tf get default graph get name scope describe problem trying create function would modify tensor within pipeline dataset api scoping may seem weird minimal example show problem created project adding started get segmentation fault minimal example instead worked see tried disabling gpu config tf configproto device count gpu cuda visible devices result recompile tf overnight current master copt g try provide stacktrace tf build info container type gpu command bazel build config opt config cuda copt march native copt mfpmath copt mtune native copt g verbose failure cxxopt glibcxx use cxx11 abi job config mkl action env ld library path usr local cuda lib64 stub usr local cuda extra cupti lib64 usr local cuda lib64 stub usr local cuda lib64 stub usr local cuda extra cupti lib64 lib amd64 server usr lib jvm java openjdk amd64 jre lib amd64 server opt boost lib opt conda lib usr local cuda lib64 opt conda lib r lib usr local nvidia lib64 usr local nvidia lib lib x86 linux gnu usr local cuda extra cupti lib64 usr lib x86 linux gnu opt opencv lib tensorflow tool pip package build pip package source head source remote origin os linux kernel generic architecture x86 processor intel r core tm i7 cpu processor count memory total kb swap total kb bazel version build label java version python version gpp version g ubuntu swig version nvidia driver version cuda device count cuda device name geforce gtx ti primarycard cuda toolkit version v9 source code log ds1 scope graph scope scope scope name scope scope x var initial scope ds1 scope graph scope scope scope name scope scope x var tensor arg0 shape dtype int32 tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name geforce gtx ti major minor memoryclockrate ghz pcibusid totalmemory freememory tensorflow core common runtime gpu gpu device cc adding visible gpu device tensorflow core common runtime gpu gpu device cc device interconnect streamexecutor strength edge matrix tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc created tensorflow device job localhost replica task device gpu mb memory physical gpu device name geforce gtx ti pci bus id compute capability tensorflow core common runtime process util cc creating new thread pool default inter op setting tune using inter op parallelism thread best performance segmentation fault core dumped log run cpu cuda visible devices python3 bug py ds1 scope graph scope scope scope name scope scope x var initial scope ds1 scope graph scope scope scope name scope scope x var tensor arg0 shape dtype int32 e tensorflow stream executor cuda cuda driver cc failed call cuinit cuda error device cuda capable device detected tensorflow stream executor cuda cuda diagnostics cc retrieving cuda diagnostic information host tensorflow stream executor cuda cuda diagnostics cc hostname tensorflow stream executor cuda cuda diagnostics cc libcuda reported version tensorflow stream executor cuda cuda diagnostics cc kernel reported version tensorflow stream executor cuda cuda diagnostics cc kernel version seems match dso tensorflow core common runtime process util cc creating new thread pool default inter op setting tune using inter op parallelism thread best performance segmentation fault core dumped,2018-09-02 21:09:33,1535922573,resolved fixed,85f4f6b7ced7afab7e77e65c2b21448cfbf2d6f2,1539375327,tensorflow\core\framework\common_shape_fns.cc tensorflow\python\kernel_tests\scatter_nd_ops_test.py                                                          
82,22039,Session.run () takes a long time,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary source tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source cuda cudnn version gpu model memory geforce gtx960 exact command reproduce n describe problem time tensorflow performs session run target detection detection time first image long including initialization operation course detection time image normal suppose detect image certain path example ten image time detecting first image relatively long remaining nine image relatively short basically consistent however operation practical application follows session run called every detect picture hope detection time first one normal except long time however test guess exiting loop logic detection tensorflow redid series initialization operation next time detection done puzzled framework mxnet initial detection take longer detection time normal initialization anymore thought could tensorflow thing source code log w tensorflow core common runtime bfc allocator cc allocator gpu bfc ran memory trying allocate caller indicates failure may mean could performance gain memory available time time time time,2018-09-04 03:49:40,1536032980,resolved fixed,59166604c26b8ffde742389fcd99c8090bf8ec04,1576794961,tensorflow\compiler\mlir\lite\python\graphdef_to_tfl_flatbuffer.cc                                                            
83,22438,InvalidArgumentError when SparseTensorValue is not ordered by row then col,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac os mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v1 rc1 g656e7a2b34 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory exact command reproduce python bug py describe problem feed sparsetensorvalue tf data dataset tensor slice index lexicographically sorted row col get invalidargumenterror maybe could said doc error provide clearer message hard guess index order meant index provided lexicographic order finally saw explained sparsetensor doc feel said sparsetensorvalue doc well source code log scipy sparse import csr matrix import tensorflow tf import numpy np np array first observation two slicing operation provide different ordering csr matrix tocoo print row col csr matrix tocoo print row col entry np column stack row col data ordering np arange len data uncomment following line fix error ordering np lexsort col row sort row col x train tf sparsetensorvalue index entry ordering value entry ordering dense shape shape dataset tf data dataset tensor slice x train iterator dataset make initializable iterator x sample iterator get next tf session sess sess run iterator initializer print sess run x sample traceback recent call last file users jilljenn code vae venv lib python3 site package tensorflow python client session py line call return fn args file users jilljenn code vae venv lib python3 site package tensorflow python client session py line run fn option feed dict fetch list target list run metadata file users jilljenn code vae venv lib python3 site package tensorflow python client session py line call tf sessionrun run metadata tensorflow python framework error impl invalidargumenterror index order node serializemanysparse serializemanysparse dt int64 type dt variant device job localhost replica task device cpu tensor sparsetensor index tensor sparsetensor value tensor sparsetensor dense shape handling exception another exception occurred traceback recent call last file bug py line sess run iterator initializer file users jilljenn code vae venv lib python3 site package tensorflow python client session py line run run metadata ptr file users jilljenn code vae venv lib python3 site package tensorflow python client session py line run feed dict tensor option run metadata file users jilljenn code vae venv lib python3 site package tensorflow python client session py line run run metadata file users jilljenn code vae venv lib python3 site package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl invalidargumenterror index order node serializemanysparse serializemanysparse dt int64 type dt variant device job localhost replica task device cpu tensor sparsetensor index tensor sparsetensor value tensor sparsetensor dense shape caused op serializemanysparse defined file bug py line dataset tf data dataset tensor slice x train file users jilljenn code vae venv lib python3 site package tensorflow python data ops dataset ops py line tensor slice return tensorslicedataset tensor file users jilljenn code vae venv lib python3 site package tensorflow python data ops dataset ops py line init self tensor sparse serialize many sparse tensor tensor file users jilljenn code vae venv lib python3 site package tensorflow python data util sparse py line serialize many sparse tensor tensor nest flatten tensor file users jilljenn code vae venv lib python3 site package tensorflow python data util sparse py line tensor nest flatten tensor file users jilljenn code vae venv lib python3 site package tensorflow python ops sparse ops py line serialize many sparse type type file users jilljenn code vae venv lib python3 site package tensorflow python ops gen sparse ops py line serialize many sparse type type name name file users jilljenn code vae venv lib python3 site package tensorflow python framework op def library py line apply op helper op def op def file users jilljenn code vae venv lib python3 site package tensorflow python util deprecation py line new func return func args kwargs file users jilljenn code vae venv lib python3 site package tensorflow python framework ops py line create op op def op def file users jilljenn code vae venv lib python3 site package tensorflow python framework ops py line init self traceback tf stack extract stack invalidargumenterror see traceback index order node serializemanysparse serializemanysparse dt int64 type dt variant device job localhost replica task device cpu tensor sparsetensor index tensor sparsetensor value tensor sparsetensor dense shape,2018-09-21 07:00:58,1537513258,resolved fixed,eb625fb51a302dc812c97879697642db9aa8cfc1,1565287308,tensorflow\core\util\sparse\sparse_tensor.h tensorflow\core\util\sparse\sparse_tensor_test.cc                                                          
84,23083,Documentation for learning_rate_power in the FTRL optimizer,please make sure documentation issue per github policy address code doc bug performance issue feature request build installation issue github tag doc template system information tensorflow version doc link probably silly small issue doc ftrl optimizer describe interacts tried figure based source actually find learning rate power used code l2 shrinkage regularization strength detailed explanation equation something similar learning rate power would nice,2018-10-18 20:26:27,1539894387,resolved fixed,5097def5847270353d7d8a37eacbd0f85e98f2a0,1540428903,tensorflow\python\training\ftrl.py                                                            
85,23195,Segfault reading dataset more than once (`make_batched_features_dataset`),system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos mojave mobile device e g iphone pixel samsung galaxy issue happens mobile device na tensorflow installed source binary binary pip tensorflow version use command v1 rc2 gc19e29306c python version bazel version compiling source na gcc compiler version compiling source na cuda cudnn version na gpu model memory na gist full output tool tf env collect sh exact command reproduce wget python gistfile1 txt describe current behavior current behavior included script segfaults sigsegv describe expected behavior expected behavior segfault version segfault checked lower version code reproduce issue see full script reproduces issue along two different code path segfault occurs reading dataset second time first read work expected reference two code sample produce datasets cause segfault second read dataset make batched feature dataset file pattern data file batch size feature feature spec also dug make batched feature dataset minified repro tensorflow contrib data python ops import parsing ops tensorflow python data ops import reader dataset dataset tensor slice data file interleave reader tfrecorddataset cycle length batch batch size apply parsing ops parse example dataset feature spec please let know anything else provide help blocking u upgrading latest tensorflow version spotify spotify tensorflow,2018-10-23 20:21:54,1540326114,resolved fixed,95de98b58a35aaac2804716a70979e68596f3dae,1540949771,tensorflow\core\kernels\data\parse_example_dataset_op.cc tensorflow\python\data\experimental\kernel_tests\parse_example_dataset_test.py tensorflow\python\framework\test_util.py                                                        
86,23443,Python client link is broken,please make sure documentation issue per github policy address code doc bug performance issue feature request build installation issue github tag doc template system information tensorflow version unrelated using github ui viewing code doc link link give welcome contribution user able update submit pr use doc style guide fix doc issue,2018-11-01 23:45:42,1541115942,resolved fixed,09f82cbffdcaf5298bcbd4703c18b64ddd287aab,1541201957,tensorflow\contrib\crf\__init__.py tensorflow\contrib\framework\__init__.py tensorflow\contrib\layers\__init__.py tensorflow\contrib\learn\__init__.py tensorflow\contrib\rnn\__init__.py tensorflow\contrib\util\__init__.py tensorflow\lite\g3doc\convert\cmdline_examples.md tensorflow\python\client\client_lib.py tensorflow\python\debug\__init__.py tensorflow\python\lib\io\python_io.py tensorflow\python\ops\array_ops.py tensorflow\python\ops\check_ops.py tensorflow\python\ops\control_flow_ops.py tensorflow\python\ops\functional_ops.py tensorflow\python\ops\session_ops.py tensorflow\python\ops\sparse_ops.py tensorflow\python\ops\state_ops.py tensorflow\python\ops\string_ops.py                          
87,23449,Bug in tensorflow lite java wrapper,file line function output tensor length used instead inputtensors length,2018-11-02 07:25:15,1541143515,resolved fixed,816426f66a9b3edbbdf4203684f7753b2974866d,1541699007,tensorflow\lite\java\BUILD tensorflow\lite\java\src\main\java\org\tensorflow\lite\NativeInterpreterWrapper.java tensorflow\lite\java\src\test\java\org\tensorflow\lite\InterpreterFlexTest.java tensorflow\lite\java\src\test\java\org\tensorflow\lite\InterpreterTest.java                                                      
88,23748,tensorflow.keras Dense layers complain if the input is a sparse Input layer.,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu osx mojave mobile device e g iphone pixel samsung galaxy issue happens mobile device na tensorflow installed source binary binary tensorflow version use command v1 rc1 g656e7a2b34 python version bazel version compiling source na gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version python c import tensorflow tf print tf git version tf version describe current behavior see ran osx mojave macbook pro early ipython running python tensorflow tensorflow kera model import model anaconda envs dssm lib python3 importlib bootstrap py runtimewarning compiletime version module tensorflow python framework fast tensor util match runtime version return f args kwds tensorflow kera layer import input dense input sparse true dense attributeerror traceback recent call last dense anaconda envs dssm lib python3 site package tensorflow python kera engine base layer py call self input args kwargs check input assumption set layer building e g input rank self assert input compatibility input input list self dtype none try anaconda envs dssm lib python3 site package tensorflow python kera engine base layer py assert input compatibility self input spec min ndim none spec max ndim none x shape ndims none raise valueerror input str input index layer self name incompatible layer attributeerror sparsetensor object attribute shape describe expected behavior using normal keras expect error trying model compile subsequently without issue code reproduce issue see code snippet info log,2018-11-14 16:19:40,1542212380,resolved fixed,74195b50fb5e1f22eb95ffd1646b4b0ceca2ea9b,1581017927,tensorflow\python\client\session_test.py tensorflow\python\framework\sparse_tensor.py tensorflow\python\keras\engine\training.py tensorflow\python\keras\utils\composite_tensor_support_test.py tensorflow\python\keras\utils\tf_utils.py tensorflow\python\kernel_tests\sparse_ops_test.py tensorflow\python\ops\array_ops.py                                                
89,23878,Bug: instantiating dynamic_rnn with tf.int32 in input and state raises TypeError,system information os platform os x custom code tensorflow version python version describe current behavior tensorflow raise typeerror creating dynamic rnn tf int32 type input state changing type tf float32 error raised describe expected behavior ideally dynamic rnn support tf in32 type reason instantiating dynamic rnn tf int32 type input state allowed custom error raised code reproduce issue code reproduces error import tensorflow tf x tf placeholder tf int32 none cell tf nn rnn cell lstmcell dtype tf int32 output state tf nn dynamic rnn cell cell input x dtype tf int32 code import tensorflow tf x tf placeholder tf float32 none cell tf nn rnn cell lstmcell dtype tf float32 output state tf nn dynamic rnn cell cell input x dtype tf float32 note change dtype info log traceback typeerror traceback recent call last x tf placeholder tf int32 none cell tf nn rnn cell lstmcell dtype tf int32 output state tf nn dynamic rnn cell cell input x dtype tf int32 initial state state jonassucks3 lib python3 site package tensorflow python ops rnn py dynamic rnn cell input sequence length initial state dtype parallel iteration swap memory time major scope swap memory swap memory sequence length sequence length dtype dtype outputs dynamic rnn loop always shaped time batch depth jonassucks3 lib python3 site package tensorflow python ops rnn py dynamic rnn loop cell input initial state parallel iteration swap memory sequence length dtype parallel iteration parallel iteration maximum iteration time step swap memory swap memory unpack final output using output tuples jonassucks3 lib python3 site package tensorflow python ops control flow ops py loop cond body loop var shape invariant parallel iteration back prop swap memory name maximum iteration return structure ops add collection ops graphkeys context loop context result loop context buildloop cond body loop var shape invariant return structure maximum iteration none return result jonassucks3 lib python3 site package tensorflow python ops control flow ops py buildloop self pred body loop var shape invariant return structure ops get default graph mutation lock pylint disable protected access original body result exit var self buildloop pred body original loop var loop var shape invariant finally self exit jonassucks3 lib python3 site package tensorflow python ops control flow ops py buildloop self pred body original loop var loop var shape invariant flat sequence var body tensor array pre summary ops get collection ops graphkeys summary collection pylint disable protected access body result body packed var body post summary ops get collection ops graphkeys summary collection pylint disable protected access nest sequence body result jonassucks3 lib python3 site package tensorflow python ops control flow ops py lv cond lambda lv pylint disable g long lambda math ops logical maximum iteration orig cond lv body lambda lv orig body lv context executing eagerly jonassucks3 lib python3 site package tensorflow python ops rnn py time step time output ta state skip conditionals true else output new state call cell keras cell always wrap state list even single tensor jonassucks3 lib python3 site package tensorflow python ops rnn py kera rnn cell nest sequence state state state call cell lambda cell input state sequence length none jonassucks3 lib python3 site package tensorflow python ops rnn cell impl py call self input state scope args kwargs method see class docstring detail return base layer layer call self input state scope scope args kwargs jonassucks3 lib python3 site package tensorflow python layer base py call self input args kwargs actually call layer output super layer self call input args kwargs context executing eagerly jonassucks3 lib python3 site package tensorflow python kera engine base layer py call self input args kwargs deferred mode self call true output self call input args kwargs self call false output none jonassucks3 lib python3 site package tensorflow python ops rnn cell impl py call self input state sigmoid self w diag c prev self activation j else c sigmoid f self forget bias c prev sigmoid self activation j typeerror unsupported operand type tensor float,2018-11-20 11:31:19,1542713479,resolved fixed,36304bc4ceb6140e470420b65ce470092fc47ab2,1545087042,tensorflow\python\kernel_tests\rnn_test.py tensorflow\python\ops\rnn_cell_impl.py                                                          
90,23924,Memory leak when using tf.contrib.data.unbatch(),system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v1 ga6d8ffae09 python version python anaconda inc bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior memory usage continuously increase using tf contrib data unbatch describe expected behavior memory usage increase code reproduce issue absl import app absl import flag absl import logging import tensorflow tf flags flag flags flag define integer epoch flag define boolean use unbatch false def create dataset input holder dataset tf data dataset tensor slice input holder def generate random tensor size return tf random uniform size size dtype tf float32 dataset dataset map generate random tensor flags use unbatch dataset dataset apply tf contrib data unbatch else dataset dataset flat map lambda x tf data dataset tensor slice x output dataset becomes single element tuple w dataset dataset map lambda x x return dataset def main tf session sess size holder tf placeholder tf int32 shape none dataset create dataset size holder iterator dataset make initializable iterator get next iterator get next range flags epoch logging info epoch sess run iterator initializer feed dict size holder try true array sess run get next logging info generated array shape except tf error outofrangeerror pas name main app run main memory usage increase use unbatch nouse unbatch memory usage increase info log seems like call missing unbatchdatasetop,2018-11-22 14:45:32,1542897932,resolved fixed,bb425754adacc784c2ad50ed94307eaa03626b41,1543259339,tensorflow\core\kernels\data\unbatch_dataset_op.cc                                                            
91,23987,LARSOptimizer does not initialize _learning_rate_tensor and _momentum_tensor,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution linux ubuntu tensorflow installed binary tensorflow version tag python version cpu mode describe current behavior larsoptimizer object attribute learning rate tensor code reproduce issue tensorflow tensorflow contrib opt python training lars optimizer test py,2018-11-27 03:10:14,1543288214,resolved fixed,6d3d0de39f3eaecdbf7fbdb52a7a02b2539efeeb,1543288689,tensorflow\contrib\opt\python\training\lars_optimizer.py                                                            
92,24286,wrong command for cloning tensorflow in TF for microcontroller doc,please make sure documentation issue per github policy address code doc bug performance issue feature request build installation issue github tag doc template system information tensorflow version master doc link describe documentation issue getting started chapter command cloning tensorflos download tensorflow source git clone git clone welcome contribution user able update submit pr use doc style guide fix doc issue yes,2018-12-11 08:38:38,1544517518,resolved fixed,caf2d701d27bf5b2e9378db5dfa63e08054ff497,1545271635,tensorflow\lite\experimental\micro\README.md                                                            
93,24414,ppc64le: no_mkl_dnn_contraction_kernel define causes build failure,please make sure build installation issue per github policy address code doc bug performance issue feature request build installation issue github tag build template system information os platform distribution e g linux ubuntu ubuntu ppc64le mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary source tensorflow version master python version installed using virtualenv pip conda source bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory v100 recent commit changed default contraction kernel mkl based code added non intel platform avoid mkl error provide exact sequence command step executed running problem basic build bazel build tensorflow tool pip package build pip package info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached error home jenkins workspace tensorflow ppc64le gpu build tensorflow core kernel build illegal ambiguous match configurable attribute deps tensorflow core kernel eigen contraction kernel tensorflow linux ppc64le tensorflow core kernel mkldnn contraction kernel multiple match allowed unless one unambiguously specialized error analysis target tensorflow tool pip package build pip package failed build aborted home jenkins workspace tensorflow ppc64le gpu build tensorflow core kernel build illegal ambiguous match configurable attribute deps tensorflow core kernel eigen contraction kernel tensorflow linux ppc64le tensorflow core kernel mkldnn contraction kernel multiple match allowed unless one unambiguously specialized end multiple match select call defines select tensorflow android tensorflow arm tensorflow io tensorflow linux ppc64le mkldnn contraction kernel condition default tensorflow use custom contraction kernel tensorflow use mkldnn contraction kernel either arch specific entry select call removed mkldnn contraction kernel entry removed work follow proposed patch set,2018-12-18 06:06:14,1545113174,resolved fixed,1a26797203e62390623756fd67e69e7665b69389,1554051161,tensorflow\core\kernels\BUILD                                                            
94,24598,Potential tf.boolean_mask bug when the mask array is empty,system information os platform distribution windows tensorflow installed source binary binary tensorflow version use command python version cuda cudnn version v8 gpu model memory geforce gtx actually experiencing almost similar problem like thread want partition minibatch different part process parallel using different computation unit stitch back together however time used instead partition operation since latter run problem one partition empty code copy paste reproducible import tensorflow tf import numpy np def build conv layer input filter size num input channel num output channel name suffix ok conv weight tf variable tf truncated normal filter size filter size num input channel num output channel stddev dtype tf float32 ok conv bias tf variable tf constant shape num output channel dtype tf float32 conv tf nn conv2d input conv weight stride padding relu tf nn relu tf nn bias add conv conv bias pool tf nn max pool relu ksize stride padding return pool batch size child count channel count datatensor tf placeholder tf float32 shape none name datatensor index tensor tf placeholder name index tensor dtype tf int32 batch size tensor tf placeholder name batch size tensor dtype tf int32 condition index list partition list mask list child index range child count mask index tf reshape index tensor child index condition index tf boolean mask tf range batch size tensor mask index partition tf boolean mask datatensor mask index mask list append mask index condition index list append condition index partition list append partition transformed list build conv layer input part filter size num input channel num output channel part partition list squared list tf square part part partition list stitched conv transform tf dynamic stitch index condition index list data transformed list stitched square transform tf dynamic stitch index condition index list data squared list sum tf reduce sum stitched square transform grad tf gradient sum datatensor sess tf session sample np random uniform size batch size index arr np zero shape batch size child count dtype np int32 index arr index arr np array index arr np array feed dict datatensor sample batch size tensor batch size index tensor np argmax np random uniform size globalconstants eval batch size child count axis index tensor index arr output output extend mask list output extend transformed list output extend squared list output append stitched conv transform output append stitched square transform output append sum output append grad init tf global variable initializer sess run init range result sess run output feed dict feed dict assert np allclose result sample print runned format disappointment tf boolean mask run similar problem index arr contains reference least one partition produce empty array partition result loop end run correctly time program crash following error internalerror see traceback whereop could launch cub devicereduce sum count number true nonzero index temp storage byte status invalid configuration argument node boolean mask wheret dt int32 device job localhost replica task device gpu node dynamicstitch recvclient terminated false recv device job localhost replica task device cpu send device job localhost replica task device gpu send device incarnation tensor name edge dynamicstitch tensor type dt float device job localhost replica task device cpu think error underlying problem crash receives empty index array since could using mechanism cub library whatever cub error also occurs succesfull iteration like one could reason,2018-12-27 11:53:09,1545911589,resolved fixed,961e9f4505dff0c5a91d12b1f4e476b3cf2d295d,1545955857,tensorflow\core\kernels\where_op.cc tensorflow\core\kernels\where_op.h                                                          
95,24632,Interrupting tf.keras training while using the TensorBoard callback wreaks havoc,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac os x mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command version dev20181226 tf preview git version b v1 gc343196842 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior using tf kera jupyter python shell tensorboard callback problem occur interrupt training problem occur tf get exception call fit model tensorflow python framework error impl notfounderror resource localhost logdir log run1 n10tensorflow22summarywriterinterfacee exist op writescalarsummary name epoch loss workaround problem recompiling model also get exception interrupt training delete log directory try use tensorboard callback log directory tensorflow python framework error impl unknownerror event file log run1 event tfevents macmix local v2 disappeared failed flush event log run1 event tfevents macmix local v2 could flush event file op flushsummarywriter one severe sometimes recovers sometimes find way manually recover error restarting jupyter kernel python shell describe expected behavior expect tensorboard callback gracefully handle issue perhaps display warning force recompile kernel restart code reproduce issue import shutil import numpy np import tensorflow tf tensorflow import kera x train np random rand train np random rand model kera model sequential kera layer dense model compile loss mse optimizer sgd tensorboard cb kera callback tensorboard log run1 model fit x train train epoch callback tensorboard cb note must interrupt training ctrl c finish issue try model fit x train train epoch callback tensorboard cb issue try may need interrupt retry time shutil rmtree log model kera model sequential kera layer dense model compile loss mse optimizer sgd tensorboard cb kera callback tensorboard log run1 model fit x train train epoch callback tensorboard cb gist full session output,2018-12-30 16:10:30,1546186230,resolved fixed,826027dbd4277a2636fc2935ed245700fd01e7cd,1550871872,tensorflow\python\BUILD tensorflow\python\kernel_tests\BUILD tensorflow\python\kernel_tests\summary_ops_test.py tensorflow\python\ops\summary_ops_v2.py tensorflow\tools\api\golden\v2\tensorflow.summary.-summary-writer.pbtxt tensorflow\tools\api\golden\v2\tensorflow.summary.pbtxt                                                  
96,2523,Incorrect error message,error message date valueerror execute operation using run default session registered use default session sess pas explicit session run session sess far tell longer default session function instead one must call sess default,2016-05-26 22:15:15,1464300915,resolved fixed,3e7aae461b657fd7960ff49b64bad125eabfe1e3,1464364129,tensorflow\python\framework\ops.py                                                            
97,25262,Usage of tf_stack.extract_stack in registry.py breaks TensorFlow R client,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux fedora mobile device e g iphone pixel samsung galaxy issue happens mobile device na tensorflow installed source binary binary tensorflow version use command nightly python version bazel version compiling source na gcc compiler version compiling source na cuda cudnn version na gpu model memory na hi usage tf stack registry py stack tf stack extract stack user function stack break tensorflow r client point called r stack length element length analogous recently fixed thank jtkeeling would awesome could still fixed release aware workaround user want register custom gradient many thanks,2019-01-28 19:40:43,1548704443,resolved fixed,823b694639a3f49b6adbf9e73a08c529d583878e,1548755320,tensorflow\python\framework\registry.py                                                            
98,25426,"Segmentation Fault with tf.io.decode_csv , numpy record_defaults and tensor input",system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu lts windows linux subsystem mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command preview b v1 g7cfe43a11d python version python bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version python c import tensorflow tf print tf git version tf version describe current behavior segmentation fault core dumped describe expected behavior print result code reproduce issue import numpy np import tensorflow tf record default np zero parsed field tf io decode csv tf constant record default info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached fine either tf constant record default plain string decode eg parsed field tf io decode csv record default numpy version numpy py36 blas openblash1522bff blas openblas conda forge,2019-02-01 17:00:05,1549040405,resolved fixed,3ae3c3c9d43f870d6340cec529de03175e914595,1562991963,tensorflow\python\eager\pywrap_tfe_src.cc tensorflow\python\kernel_tests\decode_csv_op_test.py                                                          
99,25463,TensorFlow GCS access does not work from colab,system information using colab research google com describe current behavior hangs import tensorflow tf tf io gfile exists g tfds data public gcs bucket describe expected behavior hang,2019-02-03 02:46:03,1549161963,resolved fixed,a252fe83f4dc29c0614983046825ec75a3529cb9,1549514277,tensorflow\core\platform\cloud\google_auth_provider.cc tensorflow\core\platform\cloud\google_auth_provider.h tensorflow\core\platform\cloud\google_auth_provider_test.cc                                                        
100,2573,avg/max_pool3d description has a bug.,file tensorflow g3doc api doc python function class shard0 tf nn avg pool3d md tensorflow g3doc api doc python function class shard4 tf nn max pool3d md original list length tensor length size window dimension input tensor must think ksize ksize change ksize ksize according test file tensorflow tensorflow python kernel test pooling ops test py line ksize window window window,2016-05-29 20:57:37,1464555457,resolved fixed,1a5364efe43f76ab72a1f3651df394d6b121c915,1465322629,tensorflow\core\ops\nn_ops.cc                                                            
101,25844,[TF 2.0 API Docs] tf.lite.TFLiteConverter,system information tensorflow version doc link describe documentation issue links fixed incorrect correct description pr used convert tensorflow graphdef savedmodel either tflite flatbuffer graph visualization graphdef saved model tf kera model usage example pr line code repeated method open converted model tflite wb write tflite model parameters defined fixed missing parameter optimization representative dataset welcome contribution user able update submit pr use doc style guide fix doc issue yes,2019-02-18 16:17:32,1550506652,resolved fixed,39d1b3c7ee8a619b28832ac95e689ba34bac9500,1551034450,tensorflow\lite\python\lite.py                                                            
102,25882,tf.image.random_jpeg_quality only products images of single jpeg quality,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux debian tensorflow installed source binary pip install tensorflow version use command v1 ga6d8ffae09 python version cuda cudnn version gpu model memory geforce gtx ti mb describe current behavior tf image random jpeg quality generates random jpeg quality graph creation fixed describe expected behavior tf image random jpeg quality generates random jpeg quality image batch image passed code reproduce issue import numpy np import tensorflow tf img np random randint dtype np uint8 tf img tf placeholder tf uint8 jpeg augment tf image random jpeg quality tf img min jpeg quality max jpeg quality sess config tf configproto sess config gpu option allow growth true tf session config sess config sess sess run tf global variable initializer result range augmented sess run jpeg augment feed dict tf img img result append augmented result np array result first result result equal np first print equal format equal assert equal code causing located tensorflow tensorflow python ops image ops impl py line a6d8ffa jpeg quality np random randint min jpeg quality max jpeg quality,2019-02-19 09:14:34,1550567674,resolved fixed,d87710ed89e01cf479d2b6ba619a879c32ad77d9,1553204815,tensorflow\core\api_def\base_api\api_def_EncodeJpegVariableQuality.pbtxt tensorflow\core\api_def\java_api\api_def_EncodeJpegVariableQuality.pbtxt tensorflow\core\api_def\python_api\api_def_EncodeJpegVariableQuality.pbtxt tensorflow\core\kernels\encode_jpeg_op.cc tensorflow\core\ops\image_ops.cc tensorflow\go\op\wrappers.go tensorflow\python\ops\image_ops_impl.py tensorflow\python\ops\image_ops_test.py tensorflow\tools\api\golden\v1\tensorflow.raw_ops.pbtxt tensorflow\tools\api\golden\v2\tensorflow.raw_ops.pbtxt                                          
103,25985,reset_states() failure in a stateful network with initial_states set and training in batch - TypeError: 'NoneType' object is not subscriptable,system information written custom code opposed using stock example script provided tensorflow n os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command dev20190217 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory gtx describe current behavior manojrege said kera team kera use rnn case get exception traceback recent call last file usr local cellar python frameworks python framework versions lib python3 runpy py line run module main main mod spec file usr local cellar python frameworks python framework versions lib python3 runpy py line run code exec code run globals file users manoj desktop repos yane yane lstm manytomanylstm py line incremental train space file users manoj desktop repos yane yane lstm manytomanylstm py line incremental train model reset state file usr local lib python3 site package kera engine topology py line reset state layer reset state file usr local lib python3 site package kera layer recurrent py line reset state batch size self input spec shape typeerror nonetype object subscriptable another issue talking problem describe expected behavior throw exception code reproduce issue import tensorflow tf import pdb pdb set trace input tf kera layer input batch shape state h tf kera layer input batch shape state c tf kera layer input batch shape state state h state c decoder tf kera layer lstm stateful true input initial state state model tf kera model input state h state c decoder model reset state info log confirm pull request fix problem,2019-02-21 20:42:41,1550781761,resolved fixed,83df61b4d4ad11f3b8cf05ee98d29e6fb5e25506,1552150077,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py                                                          
104,26048,Check failure and silent failures with incorrect usage of tf.custom_gradient (in eager mode).,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos tensorflow installed source binary binary tensorflow version use command v1 g2ae06ca491 dev20190223 well python version python anaconda inc tf custom gradient used incorrectly case returned grad function return empty list script segfaults import tensorflow tf tf enable eager execution tf custom gradient def identity x def grad dy return return value wrong return x grad x tf variable tf gradienttape identity x gradient x gradient call fails f tensorflow c eager tape h check failed state op tape empty abort trap think preferable raise exception instead crashing instead return many value grad script run likely bug probably raise exception import tensorflow tf tf enable eager execution tf custom gradient def identity x def grad dy return many return value return x grad x tf variable tf gradienttape identity x gradient x fyi alextp,2019-02-24 02:14:09,1550974449,resolved fixed,710b322a8be78b8aff6b148575fcfe5301f42b64,1551805865,tensorflow\c\eager\tape.h tensorflow\python\eager\backprop_test.py tensorflow\python\ops\custom_gradient.py                                                        
105,26099,tf.one_hot crashes when indices is tf.uint8,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu windows tensorflow installed source binary official pip source tensorflow gpu tensorflow version use command python version cuda cudnn version gpu model memory describe current behavior tf one hot crash index tensor dtype tf uint8 error message show check failed new num element numelements info log also tested tf tf gpu different machine problem,2019-02-25 19:20:13,1551122413,resolved fixed,a311216a9f028eec9e6b0d2ef175f5d46dff19b7,1555993830,tensorflow\core\kernels\one_hot_op.cc tensorflow\python\kernel_tests\one_hot_op_test.py                                                          
106,26143,[TF2.0] Error Logging for GradientTape,hello everyone wondering option error logging could tf output error message gradient calculation example output none value current setting output correct gradient tf variables float type question could please add error message stating something like gradient calculation support float type best regards seung jae bang def forward b f b return b params tf variable tf variable tf gradienttape tape result forward params tape gradient result params system information linux tensorflow installed pip install u tf nightly preview dev20190226 python version ccing random forest,2019-02-26 21:12:27,1551215547,resolved fixed,764fdc6fb1a9ac377440e1b537ff8a6b7e9f2063,1554154559,tensorflow\python\eager\backprop.py                                                            
107,26394,Allow building TF + nvidia GPU targeting &lt; sm35 if XLA is not enabled,please make sure build installation issue per github policy address code doc bug performance issue feature request build installation issue github tag build template system information os platform distribution e g linux ubuntu gentoo tensorflow installed source binary source tensorflow version python version installed using virtualenv pip conda pip venv bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory gtx ti able successfully build tf source xla enabled compute capability however session created python interpreter exit complaining insufficient compute capability import tensorflow tf tf session tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow compiler xla service platform util cc streamexecutor cuda device insufficient compute capability required device f tensorflow stream executor lib statusor cc attempting fetch value instead handling error internal supported device found platform cuda reconfigure tf disabling xla rebuild compute capability tf work fine guess simple check compute capability xla enabled could least prevent building non functional tf,2019-03-06 12:08:17,1551874097,resolved fixed,8dc2d0eedac7760deb65254a8ef89878743299d7,1552380414,configure.py                                                            
108,26502,IDE cannot resolve module tf.keras,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary pip tensorflow version use command alpha python version describe current behavior import tensorflow tf pycharm resolve module tf kera report error find reference kera init py running program everything work well describe expected behavior tf kera imported successfully autocomplete pycharm code reproduce issue import tensorflow tf info log seems import command kera module init py tensorflow package added tensorflow python import kera init pymanually everything work well maybe problem package importing kera moved api python,2019-03-09 04:14:05,1552104845,resolved fixed,88ca0db75e6daf66c6fb21609ee4100126f1b727,1555742929,tensorflow\api_template.__init__.py tensorflow\api_template_v1.__init__.py tensorflow\compat_template.__init__.py tensorflow\compat_template_v1.__init__.py tensorflow\python\BUILD tensorflow\python\tools\BUILD   tensorflow\python\tools\module_util.py                                              
109,26533,[TF 2.0 API Docs] tf.argsort,please make sure documentation issue per github policy address code doc bug performance issue feature request build installation issue github tag doc template system information tensorflow version doc link describe documentation issue usage example usage example provided visuals applicable visuals included welcome contribution user able update submit pr use doc style guide fix doc issue,2019-03-10 12:42:15,1552221735,resolved fixed,bd37836156e5114f15544f984f34f08d38555d4d,1552898728,tensorflow\python\ops\sort_ops.py                                                            
110,26590,[tf.keras.layers.LSTM] Initializer fails with input_length parameter,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu generic ubuntu smp tue feb utc x86 x86 x86 gnu linux tensorflow installed source binary conda binary tensorflow version use command confirmed python version python anaconda inc default oct following irrelevant since even running session eager mode cuda cudnn version cuda gpu model memory geforce gtx titan x mwe import tensorflow tf lstm tf kera layer lstm input length current behavior python error message traceback recent call last file line file local anaconda envs tensorflow p36 lib python3 site package tensorflow python kera layer recurrent py line init kwargs file local anaconda envs tensorflow p36 lib python3 site package tensorflow python kera layer recurrent py line init super rnn self init kwargs file local anaconda envs tensorflow p36 lib python3 site package tensorflow python training checkpointable base py line method wrapper method self args kwargs file local anaconda envs tensorflow p36 lib python3 site package tensorflow python kera engine base layer py line init raise typeerror keyword argument understood kwarg typeerror keyword argument understood input length class inherits parameter described therefore constructor use parameter see code,2019-03-11 22:22:35,1552342955,resolved fixed,8fcf86ec70a2a91e33f222d2be85675f0b773581,1552416911,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py                                                          
111,26602,Partial function specified through keyword on first position in tf.function,wrapping tf function partial first argument specified def f x return x partial func functools partial f x tf func tf function partial func print tf func work python2 x tf inspect getfullargspec represent construct using argspec unfortunately also work python3 argspecs already capable representing typeerror tf f got multiple value argument x,2019-03-12 10:29:27,1552386567,resolved fixed,4e4943edc3d2409bffb5776f99b941987d6eda82,1554886212,tensorflow\core\protobuf\saved_object_graph.proto tensorflow\python\eager\def_function.py tensorflow\python\eager\def_function_test.py tensorflow\python\eager\function.py tensorflow\python\eager\function_test.py tensorflow\python\saved_model\function_deserialization.py tensorflow\python\saved_model\function_serialization.py tensorflow\python\saved_model\load_test.py                                              
112,26639,Nasnet models don't support custom image sizes even if include_top is set to False,general idea fine tuning pre trained model custom image size set include top parameter false loading model however seem working nasnet model tf kera far model including inception working fine note using tensorflow alpha sure problem believe maybe issue somewhere checking dimension size along include top flag might wrong following stack trace code executed nasnet tf kera application nasnet nasnetlarge include top false weight imagenet input shape error message valueerror traceback recent call last nasnet tf kera application nasnet nasnetlarge include top false weight imagenet input shape nasnet summary opt anaconda3 lib python3 site package tensorflow python kera application init py wrapper args kwargs kwargs model model kwargs utils utils return base fun args kwargs return wrapper opt anaconda3 lib python3 site package tensorflow python kera application nasnet py nasnetlarge args kwargs kera module injection def nasnetlarge args kwargs return nasnet nasnetlarge args kwargs opt anaconda3 lib python3 site package kera application nasnet py nasnetlarge input shape include top weight input tensor pooling class kwargs class class default size kwargs opt anaconda3 lib python3 site package kera application nasnet py nasnet input shape penultimate filter num block stem block filter skip reduction filter multiplier include top weight input tensor pooling class default size kwargs data format backend image data format require flatten true weight weight backend image data format channel last opt anaconda3 lib python3 site package kera application imagenet utils py obtain input shape input shape default size min size data format require flatten weight loading imagenet weight input shape str default shape return default shape input shape valueerror setting include top true loading imagenet weight input shape,2019-03-13 04:01:20,1552449680,resolved fixed,f7ee1bff1d90aa0ac0a5e16a71c3c60f7ad96fdb,1595140712,tensorflow\python\keras\applications\nasnet.py                                                            
113,26645,Testing guide page not exist (404),please make sure documentation issue per github policy address code doc bug performance issue feature request build installation issue github tag doc template system information tensorflow version doc link testing guide exist linked tf test page welcome contribution user able update submit pr use doc style guide fix doc issue know page originally exists,2019-03-13 05:28:54,1552454934,resolved fixed,13cca52d62148fb5e103c1265c95184b75f577f5,1582159968,tensorflow\python\platform\test.py                                                            
114,26665,"tensorflow 2.0, variable_scope(), TypeError: __call__() got an unexpected keyword argument 'partition_info'",convert cnn model tf1 x tf2 using tf upgrade v2 used converted model got error file home hsw virtual env tf2 lib python3 site package tensorflow python ops variable scope py line default variable creator import scope import scope distribute strategy distribute strategy file home hsw virtual env tf2 lib python3 site package tensorflow python ops variable py line call return super variablemetaclass cl call args kwargs file home hsw virtual env tf2 lib python3 site package tensorflow python ops resource variable ops py line init constraint constraint file home hsw virtual env tf2 lib python3 site package tensorflow python ops resource variable ops py line init args initial value init fn else initial value file home hsw virtual env tf2 lib python3 site package tensorflow python ops variable scope py line shape list dtype dtype partition info partition info typeerror call got unexpected keyword argument partition info seems like something wrong variable py converted model like tf compat v1 variable scope backbone reuse tf compat v1 auto reuse net tf compat v1 layer separable conv2d input activation tf nn elu depthwise initializer tf kera initializers glorot normal pointwise initializer tf kera initializers glorot normal name conv1 net tf compat v1 layer max pooling2d net padding net tf compat v1 layer separable conv2d net activation tf nn elu depthwise initializer tf kera initializers glorot normal pointwise initializer tf kera initializers glorot normal name conv2 solve problem,2019-03-13 12:30:53,1552480253,resolved fixed,a236ae23782c04a057d17a8ad845500c7f15c432,1552605858,tensorflow\tools\compatibility\tf_upgrade_v2.py tensorflow\tools\compatibility\tf_upgrade_v2_test.py                                                          
115,26684,Repeatedly allocating a graph and summary writer leaks memory,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary source tensorflow version use command v1 gf3954bf900 python version bazel version compiling source gcc compiler version compiling source apple llvm version clang cuda cudnn version n gpu model memory n describe current behavior repeatedly allocating graph making summary writer leak memory describe expected behavior memory freed graph leaf scope code reproduce issue usr bin env python3 import resource import tensorflow tf prev true peak resource getrusage resource rusage self ru maxrss print f peak memory peak peak prev prev peak tf graph default tf init scope tf contrib summary create file writer tmp tb info log output look like peak memory warning tensorflow contrib module included tensorflow information please see depend functionality listed please file issue peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory peak memory,2019-03-14 05:08:31,1552540111,resolved fixed,097fc1cdef5c56d4bb239a5a44bf950f0b1c4d37,1554003486,tensorflow\python\kernel_tests\summary_ops_test.py tensorflow\python\ops\summary_ops_v2.py                                                          
116,26808,[TF 2.0]unconnected_gradients = 'zero' does not work,system information os platform distribution macos tensorflow installed binary tensorflow version python version try get gradient w r model parameter though getting none value example import tensorflow tf import tensorflow kera layer layer model tf kera sequential model add layer dense input shape tf gradienttape tape loss tf random normal grad tape gradient loss model trainable variable unconnected gradient zero print grad none none expect value zero though,2019-03-17 17:41:40,1552844500,resolved fixed,a79ed9c304bf9c1971fe3df4f61a0d0ab515eff9,1553720326,tensorflow\python\eager\backprop.py tensorflow\python\eager\backprop_test.py tensorflow\python\eager\imperative_grad.py tensorflow\python\eager\pywrap_tfe.h tensorflow\python\eager\pywrap_tfe_src.cc                                                    
117,26902,tf_upgrade_v2 does not preserve file attributes and symbolic links,system information written custom code opposed using stock example script provided tensorflow n os platform distribution e g linux ubuntu archlinux mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command tf2 preview nightly yesterday python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n tf upgrade v2 change executable file non executable file expect executable file still executable upgrade tf upgrade v2 always change symbolic link regular file however expect place upgrade modify file link point symbolic link non place upgrade intree outtree used symbolic link point file within tree become symbolic link pointing new file outtree symbolic link point external file become regular file non place single file upgrade output regular file,2019-03-19 21:52:17,1553032337,resolved fixed,0fa0d44944abd86578fa076802f5a8a7490d5656,1564017075,tensorflow\tools\compatibility\ast_edits.py tensorflow\tools\compatibility\ast_edits_test.py                                                          
118,27202,Tflite JNI wraps seems failing to release int array.,hi seems current impl tflite jni overlooked ref release array current tflite really could make jni reference table overflow phone android api invoke resizeinput every time run interpreter even put int array see reference table booming version tried nightly relevant code strange thing code althrough deal release situation work fine int array,2019-03-27 15:42:29,1553701349,resolved fixed,009fde664530e6616e5aa1f882ff497e9e435924,1554511201,tensorflow\lite\java\src\main\native\nativeinterpreterwrapper_jni.cc                                                            
119,27282,/tensorflow/lite/experimental/c/c_api_types.h is not readable on Windows filesystem.,system information os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary source tensorflow version f089b31 python version installed using virtualenv pip conda bazel version compiling source gcc compiler version compiling source gcc cuda cudnn version gpu model memory describe problem tensorflow lite experimental c c api type h symbolic link tensorflow lite c c api internal h dos compatible file system replaced following text file c c api internal h provide exact sequence command step executed running problem clone repository make sure file tensorflow lite experimental c c api type h symbolic link windows info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-03-29 10:40:12,1553856012,resolved fixed,04e311bf7628eac8b0334a7419442f1009487d7f,1561160665,tensorflow\lite\c\BUILD tensorflow\lite\experimental\c\BUILD tensorflow\lite\experimental\c\c_api.h tensorflow\lite\experimental\c\c_api_test.cc   tensorflow\lite\experimental\objc\TensorFlowLiteObjC.podspec tensorflow\lite\tools\make\Makefile                                                
120,27292,keras.layers.RNN with contants,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu arch linux mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory ti describe current behavior typeerror concatenate list tuple list rnn build call rnn tensor constant describe expected behavior basically build function rnncellwithconstants called input shape code reproduce issue import tensorflow tf class rnncellwithconstants tf kera layer layer def init self kwargs self state size super rnncellwithconstants self init kwargs def build self input shape print input shape self built true def call self input state constant print input state constant return input input test basic case x tf kera input none c tf kera input cell rnncellwithconstants layer tf kera layer rnn cell layer x constant c works expected test basic case x tf zero dtype tf float32 c tf zero dtype tf float32 cell rnncellwithconstants layer tf kera layer rnn cell layer x constant c crash following error info log exception example traceback recent call last file bug py line layer x constant c file home matthias local lib python3 site package tensorflow python kera layer recurrent py line call return super rnn self call input kwargs file home matthias local lib python3 site package tensorflow python kera engine base layer py line call self maybe build input file home matthias local lib python3 site package tensorflow python kera engine base layer py line maybe build self build input shape file home matthias local lib python3 site package tensorflow python kera layer recurrent py line build self cell build step input shape constant shape typeerror concatenate list tuple list correct error temporarily come another problem input shape build call correct think mistake lie distinction kera tensor compute full input spec including state constant full input input additional input original input spec none since could nested tensor input update input spec match input full input spec none range len nest flatten input additional spec perform call temporarily replaced input spec self input spec full input spec output super rnn self call full input kwargs remove additional spec input spec keep rest important keep since input spec populated build reused stateful true self input spec self input spec len additional spec return output else initial state none kwargs initial state initial state constant none kwargs constant constant return super rnn self call input kwargs set kera tensor true everything behave expected,2019-03-29 14:25:33,1553869533,resolved fixed,3e8a80bce0f7ef0ab2ee49f3528a2652f26110f0,1555028038,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py tensorflow\python\keras\layers\wrappers_test.py                                                        
121,27305,Document stride parameter for XlaBuilder::Slice,doc link documentation xlabuilder slice mention stride parameter,2019-03-29 21:37:25,1553895445,resolved fixed,369a886aab96fc081ad6637d7b413a339382b758,1565374257,tensorflow\compiler\xla\g3doc\operation_semantics.md                                                            
122,2740,ExponentialMovingAverage.average duplicates the current scope name,using tensorflow nightly import tensorflow tf tf name scope scope x tf variable dtype tf float32 ema tf train exponentialmovingaverage decay apply op ema apply x average ema average x print average name scope scope variable exponentialmovingaverage print ema average name x scope variable exponentialmovingaverage,2016-06-08 21:58:55,1465423135,resolved fixed,a2b9788ce440c350d4e3fef53fe0c51ba1c10c1a,1467246837,tensorflow\python\training\moving_averages.py tensorflow\python\training\moving_averages_test.py tensorflow\python\training\slot_creator_test.py                                                        
123,27431,Using layer classes as attribute throw an exception,system information written custom code yes os platform distribution ubuntu tensorflow installed binary tensorflow version dev20190402 python version describe current behavior layer class used attribute code throw typeerror exception calling self gather child attribute appears layer class tracked describe expected behavior layer instance tracked class code reproduce issue import tensorflow tf class layer tf kera layer layer def init self super layer self init self layer fn tf kera layer dense layer layer print layer variable info log traceback recent call last file tf2 class py line print layer variable file tmp tf2 local lib python2 site package tensorflow python kera engine base layer py line variable return self weight file tmp tf2 local lib python2 site package tensorflow python kera engine base layer py line weight return self trainable weight self non trainable weight file tmp tf2 local lib python2 site package tensorflow python kera engine base layer py line trainable weight nested self gather child attribute trainable weight file tmp tf2 local lib python2 site package tensorflow python kera engine base layer py line gather child attribute getattr layer attribute layer nested layer typeerror property object iterable,2019-04-02 14:40:22,1554216022,resolved fixed,9d724a8e6034d321e97cdc9972d4d6e7adb3e3ca,1555006461,tensorflow\python\keras\engine\base_layer_test.py tensorflow\python\training\tracking\layer_utils.py                                                          
124,27455,TF2.0 gradient problem of using tf.nn.relu in tf.keras.Model.,system information os platform distribution linux ubuntu tensorflow installed binary tensorflow version alpha0 python version describe current behavior built kera model tf nn relu gradient seems none decorated tf function code reproduce issue tf nn relu tf kera model tf function case produce none gradient import tensorflow tf z tf kera input h tf nn relu z tf kera model z h tf function def f x tf function tf gradienttape watch x z x return gradient z x print f tf convert tensor none tf nn relu tf kera model without tf function def f x without tf function tf gradienttape watch x z x return gradient z x print f tf convert tensor tf tensor shape dtype float32 tf kera layer relu tf kera model tf function import tensorflow tf z tf kera input h tf kera layer relu z tf kera model z h tf function def f x tf function tf gradienttape watch x z x return gradient z x print f tf convert tensor tf tensor shape dtype float32 tf kera layer relu tf kera model without tf function def f x without tf function tf gradienttape watch x z x return gradient z x print f tf convert tensor tf tensor shape dtype float32 tf nn relu import tensorflow tf tf nn relu tf function def f x tf function tf gradienttape watch x z x return gradient z x print f tf convert tensor tf tensor shape dtype float32 think problem tf nn relu tf kera model besides tf nn tanh problem,2019-04-03 09:07:50,1554282470,resolved fixed,244cb0b925902a29c6a39c62fd1b80cb3797051b,1554846432,tensorflow\python\keras\engine\base_layer.py tensorflow\python\keras\layers\tensorflow_op_layer_test.py                                                          
125,27565,[TF==2.0.0a0] @tf.function raises ValueError when computing gradients,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu tensorflow version use command pip install tensorflow gpu python version describe current behavior code executes normally raise valueerror computing gradient tape gradient decorate training function tf function traceback follows valueerror traceback recent call last workspaces fgenl run py batch id range num batch epoch batch data data generator get data v2 loss output train one step batch data v2 loss output input sess run opt op loss output batch data loss metric none pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager def function py call self args kwds first call call initialize initializer map self initialize args kwds add initializers initializer map self created variable try pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager def function py initialize self args kwds add initializers self concrete stateful fn self stateful fn get concrete function internal garbage collected pylint disable protected access args kwds def invalid creator scope unused args unused kwds pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager function py get concrete function internal garbage collected self args kwargs self input signature args kwargs none none graph function self maybe define function args kwargs return graph function pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager function py maybe define function self args kwargs call context key self function cache missed self function cache missed add call context key graph function self create graph function args kwargs self function cache primary cache key graph function return graph function args kwargs pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager function py create graph function self args kwargs override flat arg shape arg name arg name override flat arg shape override flat arg shape capture value self capture value self function attribute pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework func graph py func graph py func name python func args kwargs signature func graph autograph autograph option add control dependency arg name op return value collection capture value override flat arg shape converted func func output python func func args func kwargs invariant func output contains tensors indexedslices pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager def function py wrapped fn args kwds wrapped allows autograph swap converted function give function weak reference avoid reference cycle return weak wrapped fn wrapped args kwds weak wrapped fn weakref ref wrapped fn pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework func graph py wrapper args kwargs optional feature autograph option force conversion true args kwargs wrapping around decorator allows check like tf inspect getargspec pyenv version anaconda3 envs tf lib python3 site package tensorflow python autograph impl api py converted call f owner option args kwargs return call unconverted f args kwargs result converted f effective args kwargs converted function closure simply inserted function tmp tmpx0xgcbu3 py tf train one step batch data output ag converted call model none ag conversionoptions recursive true verbose strip decorator tf function defun ag convert ag convert ag converted call force conversion false optional feature internal convert user code true batch data loss info ag converted call calculate loss loss object ag conversionoptions recursive true verbose strip decorator tf function defun ag convert ag convert ag converted call force conversion false optional feature internal convert user code true output batch data gradient ag converted call gradient tape ag conversionoptions recursive true verbose strip decorator tf function defun ag convert ag convert ag converted call force conversion false optional feature internal convert user code true loss model trainable variable update list grad var grad var ag converted call zip none ag conversionoptions recursive true verbose strip decorator tf function defun ag convert ag convert ag converted call force conversion false optional feature internal convert user code true gradient model trainable variable grad none ag converted call apply gradient optimizer ag conversionoptions recursive true verbose strip decorator tf function defun ag convert ag convert ag converted call force conversion false optional feature internal convert user code true update list pyenv version anaconda3 envs tf lib python3 site package tensorflow python autograph impl api py converted call f owner option args kwargs option force conversion conversion whitelisted graph f return call unconverted f args kwargs internal convert user code example turned issuing dynamic pyenv version anaconda3 envs tf lib python3 site package tensorflow python autograph impl api py call unconverted f args kwargs return f self call args kwargs return f args kwargs pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager backprop py gradient self target source output gradient unconnected gradient flat source output gradient output gradient unconnected gradient unconnected gradient self persistent pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager imperative grad py imperative grad tape target source output gradient unconnected gradient source output gradient compat str unconnected gradient value pyenv version anaconda3 envs tf lib python3 site package tensorflow python eager backprop py aggregate grad gradient indexed slice ops indexedslices grad math ops range grad shape constant op constant grad shape list indexed slice list append indexed slice pyenv version anaconda3 envs tf lib python3 site package tensorflow python ops math ops py range start limit delta dtype name ops name scope name range start limit delta name start ops convert tensor start dtype dtype name start limit ops convert tensor limit dtype dtype name limit delta ops convert tensor delta dtype dtype name delta pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework ops py convert tensor value dtype name preferred dtype dtype hint preferred dtype deprecation deprecated argument lookup dtype hint dtype hint preferred dtype preferred dtype return convert tensor v2 value dtype preferred dtype name pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework ops py convert tensor v2 value dtype dtype hint name name name preferred dtype dtype hint ref false pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework ops py internal convert tensor value dtype name ref preferred dtype ctx accept symbolic tensor ret none ret conversion func value dtype dtype name name ref ref ret notimplemented pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework constant op py constant tensor conversion function v dtype name ref ref false ref return constant v dtype dtype name name pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework constant op py constant value dtype shape name return constant impl value dtype shape name verify shape false allow broadcast true pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework constant op py constant impl value dtype shape name verify shape allow broadcast tensor util make tensor proto value dtype dtype shape shape verify shape verify shape allow broadcast allow broadcast dtype value attr value pb2 attrvalue type tensor value tensor dtype const tensor g create op pyenv version anaconda3 envs tf lib python3 site package tensorflow python framework tensor util py make tensor proto value dtype shape verify shape allow broadcast else value none raise valueerror none value supported dtype provided force numpy array type provided possible valueerror none value supported describe expected behavior code also execute normally using tf function code reproduce issue sorry simple snippet reproduce issue could find something traceback see please,2019-04-06 09:31:57,1554543117,resolved fixed,110f0610ed0cf52d256e414906cf91d4e9d657e7,1556845118,tensorflow\python\eager\backprop.py                                                            
126,27632,[doc/keras] incorrect comment in the example for `tf.keras.layers.Add`,doc link describe documentation issue see code example added kera layer add x1 x2 equivalent added kera layer add x1 x2 added kera layer add x1 x2 equivalent added kera layer add x1 x2,2019-04-08 12:17:33,1554725853,resolved fixed,e90399a37b7b3984e2f49a89d886d4dfd78d42db,1556656395,tensorflow\python\keras\layers\merge.py                                                            
127,27705,Keras subclassing and explicit dtype of Input,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu arch linux tensorflow version alpha0 description using keras subclassing apparent way defining dtype input node network case would neccecary use tf float16 instead find way adjust also trying set dtype using self dtype tf float16 permitted,2019-04-10 07:26:10,1554881170,resolved fixed,1b96e5212002b7ac5027a7538a8f6e5780b669f5,1556677839,tensorflow\python\keras\engine\base_layer.py tensorflow\python\keras\engine\network.py tensorflow\python\keras\engine\network_test.py tensorflow\python\keras\utils\generic_utils.py                                                      
128,27769,[TF 2.0 keras] Unable save and load weights for double nested models,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac tensorflow installed source binary binary tensorflow version use command python version describe current behavior load weight throw exception doubly nested model describe expected behavior load weight work problem happens two layer nested model non trainable weight reason save weight load weight handle nested model differently save weight call layer weight layer load weight recursively call model weight layer nested model code reproduce issue import tensorflow tf tensorflow kera import model tensorflow kera layer import input conv2d batchnormalization shape none none def bnmodel x input input shape x conv2d x x batchnormalization x return model input x x inner input input shape x bnmodel x x bnmodel x inner model model inner input x input input shape model model input inner model input inner model save weight test h5 inner model load weight test h5 work fine model save weight test h5 model load weight test h5 exception ax match array bug also reported upstream kera kera team kera detailed analysis happening kera team kera comment full exception file test py line model load weight test h5 exception ax match array file usr local anaconda3 lib python3 site package tensorflow python kera engine network py line load weight hdf5 format load weight hdf5 group f self layer file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line load weight hdf5 group layer weight value original kera version original backend file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line preprocess weight loading weight convert nested model weight file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line convert nested model original backend original backend file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line preprocess weight loading weight convert nested model weight file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line convert nested model original backend original backend file usr local anaconda3 lib python3 site package tensorflow python kera saving hdf5 format py line preprocess weight loading weight np transpose weight file usr local anaconda3 lib python3 site package numpy core fromnumeric py line transpose return wrapfunc transpose ax file usr local anaconda3 lib python3 site package numpy core fromnumeric py line wrapfunc return getattr obj method args kwds valueerror ax match array,2019-04-12 05:30:00,1555047000,resolved fixed,f42549a91a3759a9264ef4d44e9224be4ee3bdc3,1561077560,tensorflow\python\keras\saving\hdf5_format.py tensorflow\python\keras\saving\hdf5_format_test.py                                                          
129,27829,Cannot create a stateful RNN with recurrent dropout,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macosx mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command tf version version dev20190413 tf version git version v1 gc7ce6f4cd9 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior get exception trying use recurrent dropout stateful rnn tensorflow python ops resource variable ops py imul self unused def imul self unused raise runtimeerror variable value supported use var assign var value modify variable var var value get new tensor object runtimeerror variable value supported use var assign var value modify variable var var value get new tensor object full stacktrace describe expected behavior exception code reproduce issue tensorflow import kera model kera model sequential kera layer gru return sequence true stateful true batch input shape none recurrent dropout info log complete stacktrace runtimeerror traceback recent call last kera layer gru return sequence true stateful true batch input shape none recurrent dropout tensorflow python training tracking base py method wrapper self args kwargs self self setattr tracking false pylint disable protected access try result method self args kwargs finally self self setattr tracking previous value pylint disable protected access tensorflow python kera engine sequential py init self layer name layer layer layer self add layer property tensorflow python training tracking base py method wrapper self args kwargs self self setattr tracking false pylint disable protected access try result method self args kwargs finally self self setattr tracking previous value pylint disable protected access tensorflow python kera engine sequential py add self layer create node connecting current layer input layer created layer x set input true tensorflow python kera layer recurrent py call self input initial state constant kwargs initial state none constant none return super rnn self call input kwargs initial state constant specified keras tensorflow python kera engine base layer py call self input args kwargs base layer utils autoaddupdates self input auto updater output call fn input args kwargs auto updater set output output tensorflow python kera layer recurrent v2 py call self input mask training initial state input length timesteps time major self time major zero output mask self zero output mask dummy tensor testing purpose runtime runtime unknown tensorflow python kera backend py rnn step function input initial state go backwards mask constant unroll input length time major zero output mask value discarded output time zero step function input time zero initial state constant output ta tuple tensor array ops tensorarray tensorflow python kera layer recurrent v2 py step cell input cell state def step cell input cell state return self cell call cell input cell state kwargs last output output state k rnn tensorflow python kera layer recurrent py call self input state training self recurrent dropout h tm1 rec dp mask self reset tensorflow python ops resource variable ops py imul self unused def imul self unused raise runtimeerror variable value supported use var assign var value modify variable var var value get new tensor object runtimeerror variable value supported use var assign var value modify variable var var value get new tensor object,2019-04-14 07:26:47,1555226807,resolved fixed,6a6e8c2586dfd2aeeebe0d94d60dcca4604ab481,1559681816,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_v2.py tensorflow\python\keras\layers\recurrent_v2_test.py                                                        
130,27845,Wrong derivatives for complex second order derivatives.,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu osx mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command tensorflow python version collect information using environment capture script also obtain tensorflow version python c import tensorflow tf print tf git version tf version describe current behavior derivatives non holomorphic function incorrect compared ad finite difference describe expected behavior derivatives non holomorphic function becorrect code reproduce issue provide reproducible test case bare minimum necessary generate problem import numpy onp import autograd ag import autograd numpy anp import numpy onp import tensorflow tf inp anp array print input inp def ag fn x real anp co x imag anp sin x return anp ab real imag ag hess ag hessian ag fn print ag val ag fn inp print ag hess ag hess inp def tf fn x real tf co x imag tf sin x return tf ab tf complex real imag tf inp tf convert tensor inp tf inp tf placeholder shape tuple dtype onp float64 op tf fn tf inp tf grad tf gradient op tf inp tf hess tf hessian op tf inp sess tf session delta d0 tf ad sess run op tf grad tf hess feed dict tf inp inp d1 sess run op tf grad tf hess feed dict tf inp inp delta print tf numerical derivative d1 d0 delta print tf autodiff derivative tf ad input ag val ag hess tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tf numerical derivative tf autodiff derivative info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached additional information google jax,2019-04-15 02:59:25,1555297165,resolved fixed,2518fc3ef8b962b8487b930d9798d4696f0e53ee,1555956845,tensorflow\python\kernel_tests\cwise_ops_unary_test.py tensorflow\python\ops\math_grad.py                                                          
131,27847,BUG: tfdbg session cannot be used with SessionRunHooks,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu archlinux mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command b v1 rc2 g6612da8 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n following code coding utf file import numpy np import tensorflow tf tensorflow python import debug tf debug tf placeholder tf float32 b c b class hook tf train sessionrunhook def run self return tf train sessionrunargs fetch c class hook2 tf train sessionrunhook def run self return tf train sessionrunargs fetch b sess tf session sess tf debug localclidebugwrappersession sess class sessioncreator def create session self return sess final sess tf train monitoredsession session creator sessioncreator hook hook hook2 final sess run b feed dict np arange throws traceback recent call last file tfdbg py line final sess run b feed dict np arange file home wyx local lib python3 site package tensorflow python training monitored session py line run run metadata run metadata file home wyx local lib python3 site package tensorflow python training monitored session py line run run metadata run metadata file home wyx local lib python3 site package tensorflow python training monitored session py line run raise six reraise original exc info file usr lib python3 site package six py line reraise raise value file home wyx local lib python3 site package tensorflow python training monitored session py line run return self sess run args kwargs file home wyx local lib python3 site package tensorflow python training monitored session py line run run metadata run metadata file home wyx local lib python3 site package tensorflow python training monitored session py line run return self sess run args kwargs file home wyx local lib python3 site package tensorflow python debug wrapper framework py line run empty fetch nest flatten fetch file home wyx local lib python3 site package tensorflow python pywrap tensorflow internal py line flatten return pywrap tensorflow internal flatten nested typeerror supported instance hook str believe issue introduced year ago handle fetch created hook fix obtain smarter way,2019-04-15 03:56:42,1555300602,resolved fixed,e2d269edb9217411fc4119338df949e1a741432b,1556558805,tensorflow\python\debug\wrappers\framework.py tensorflow\python\debug\wrappers\local_cli_wrapper_test.py                                                          
132,28070,tf2.0a0 tf.nn.ctc_loss with AttributeError: Tensor.op is meaningless when eager execution is enabled.,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary pip install tensorflow gpu alpha tensorflow version use command alpha0 v1 g2c319fb python version bazel version compiling source gcc compiler version compiling source cuda cudnn version fogotten gpu model memory code reproduce issue provide reproducible test case bare minimum necessary generate problem running python loss py error raised see error txt detail maybe internal implementation error function namely tf nn ctc loss helper py author jiarenyf pylint disable invalid name pylint disable many local pylint disable missing docstring pylint disable redefined outer name import tensorflow tf def dense sparse tensor eos token eos token tf constant eos token tensor dtype index tf tf equal tensor eos token value tf gather nd tensor index shape tf shape tensor type tf int64 return tf sparsetensor index value shape loss py author jiarenyf pylint disable invalid name pylint disable many local pylint disable missing docstring pylint disable redefined outer name import tensorflow tf helper import dense sparse def ctc loss label logit label len logit len class prediction sparse tf cast tf nn ctc greedy decoder logit logit len merge repeated true tf int32 prediction tf sparse dense prediction sparse class label sparse dense sparse label class accuracy tf edit distance prediction sparse label sparse normalize true loss tf nn ctc loss label logit label len logit len blank index class return loss accuracy prediction loss dict ctc ctc loss name main frame class batch size label len tf one batch size tf int32 label tf one batch size tf int32 logit len tf zero batch size tf int32 logit tf zero frame batch size class print ctc loss label logit label len logit len class error txt traceback recent call last file loss py line print ctc loss label logit label len logit len class file loss py line ctc loss label logit label len logit len blank index class file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python ops ctc ops py line ctc loss v2 name name file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python ops ctc ops py line ctc loss dense return compute ctc loss args file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python framework function py line call ret op call self signature args kwargs file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python framework function py line call compute shape false file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python util deprecation py line new func return func args kwargs file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python framework ops py line create op input ops set op input file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python framework ops py line input ops set op input file home jiarenyf miniconda3 envs tensorflow lib python3 site package tensorflow python framework ops py line op tensor op meaningless eager execution enabled attributeerror tensor op meaningless eager execution enabled info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-04-23 09:48:26,1556012906,resolved fixed,778ca5c0bcf87c9e2df73fe9b8074bae5b8c3e58,1556324374,tensorflow\python\kernel_tests\ctc_loss_op_test.py tensorflow\python\ops\ctc_ops.py                                                          
133,28158,Keras ValueError stops autograph building,system information written custom code opposed using stock example script provided tensorflow tensorflow installed source binary pip tensorflow version use command dev20190424 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version cudatoolkit cudnn cuda10 gpu model memory geforce rtx ti describe current behavior calling kera layer without calling build automatically infers shape trainable variable work eager mode graph mode current alpha version however running provided code dev20190424 version give following error message w0425 tf logging py entity could transform ed executed feature e g tensor dependent conditionals loop may work expected erro r detail found log running env variable autograph verbosity please report autograph team cause valueerror conversion weights model sequential yet created weights c reated model first called input build called input shape describe expected behavior code reproduce issue import o import tensorflow tf tensorflow kera import layer model optimizers o environ tf cpp min log level model model sequential layer dense activation relu optimizer optimizers sgd line needed graph mode model build none tf function def update batch tf gradienttape tape output model batch grad tape gradient output model trainable variable optimizer apply gradient zip grad model trainable variable name main batch tf zero dtype tf float32 update batch,2019-04-25 19:18:29,1556219909,resolved fixed,008300cc7667da8f8a7d36806470c01a524153d0,1556566160,tensorflow\python\autograph\converters\directives.py tensorflow\python\autograph\converters\directives_test.py                                                          
134,28346,TrtGraphConverterV2 does not preserve output names in the signature_def,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary source tensorflow version use command master april python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory gtx ti describe current behavior use trtgraphconverterv2 convert function saved model use trt preserve output name signature def saved model saved function decorated tf function returned dict output output b b name output output b saved model conversion trtgraphconverterv2 changed default name output output describe expected behavior name output change break code load model relies correct name code reproduce issue take saved model contains function returning dict run conversion params trt convert default trt conversion params replace precision mode trt convert trtprecisionmode fp16 max batch size max workspace size byte trt converter trt convert trtgraphconverterv2 input saved model dir saved model input saved model signature key key conversion params conversion params trt converter convert trt converter save saved model use saved model cli inspect saved model,2019-05-02 22:11:23,1556835083,resolved fixed,e03ab548c4696efcdbe1cca599da1289c25093b4,1564420653,tensorflow\python\compiler\tensorrt\trt_convert.py tensorflow\python\compiler\tensorrt\trt_convert_test.py                                                          
135,28406,[tflite doc] CONV_2D_TRANSPOSE -&gt; TRANSPOSE_CONV,existing urls containing issue description issue need changing tensorflow r1 conv transpose op present tensorflow lite schema glimpsed toco source code tf nn conv2d transpose conv2dbackpropinput converted transpose conv updating tflite documentation replace conv transpose transpose conv would nice,2019-05-05 07:11:03,1557040263,resolved fixed,8651de2f625d6fcc63437b5964b5fffca98c411e,1559941557,tensorflow\lite\g3doc\guide\ops_compatibility.md                                                            
136,28495,Move the Dockerfiles to ubuntu-18.04,current dockerfile based better move corresponding version tf serving already using based ubuntu dockerfile,2019-05-08 00:27:46,1557275266,resolved fixed,6206385a0b8dcb0a71e716c3b019cca820062a06,1557874222,tensorflow\tools\dockerfiles\partials\ubuntu\devel-nvidia.partial.Dockerfile tensorflow\tools\dockerfiles\partials\ubuntu\nvidia.partial.Dockerfile tensorflow\tools\dockerfiles\partials\ubuntu\version.partial.Dockerfile                                                        
137,28585,The package org.tensorflow.lite.nnapi  does not exist,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution ubuntu mobile device pixel tensorflow installed source tensorflow version python version bazel version run demo found bug org tensorflow lite nnapi,2019-05-10 07:31:28,1557473488,resolved fixed,f0836d2a3bdc83b9487d703f30669723bd2662fb,1558025507,tensorflow\lite\delegates\nnapi\java\src\main\java\org\tensorflow\lite\nnapi\NnApiDelegate.java tensorflow\lite\java\BUILD                                                          
138,28614,Keras RNN example from docs does not support statefulness when multilayer,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu tensorflow installed source binary binary tensorflow version use command python version anaconda cuda cudnn version gpu model memory gtx ti modifying example code given lead following error traceback recent call last file tmp py line layer x file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera layer recurrent py line call return super rnn self call input kwargs file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera engine base layer py line call self maybe build input file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera engine base layer py line maybe build self build input shape file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera layer recurrent py line build self reset state file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera layer recurrent py line reset state tensor shape shape dim list file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera backend py line set value value np asarray value dtype dtype x file home davis software anaconda3 envs p36 lib python3 site package tensorflow python kera backend py line dtype return x dtype base dtype name attributeerror list object attribute dtype describe expected behavior code run error code reproduce issue cell tf kera layer lstmcell tf kera layer lstmcell x tf kera input batch shape none layer tf kera layer rnn cell stateful true layer x,2019-05-10 22:16:44,1557526604,resolved fixed,12250556493fe7757bd97f397e3483e7c0e022b1,1557846462,tensorflow\python\keras\backend.py tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py                                                        
139,28685,The cycle detection algorithm in the variable creation has bad performance,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu arch linux mobile device e g iphone pixel samsung galaxy issue happens mobile device know tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source used gcc compiler version compiling source used cuda cudnn version related gpu model memory related describe current behavior maybe related noticed slow variable creation happens initial value tensor complex dependency digging found may caused algorithm used cycle detection code tensorflow tensorflow python ops variable py lines d102214 def cycle op path detect cycle dependency initial value op name path return true path add op name op input op input cycle op input op path return true op control input op control input cycle op control input path return true path remove op name return false describe expected behavior creating variable completed within acceptable time code reproduce issue reproduce problem using following code import time import tensorflow tf def build tensor depth fibonacci tf zero shape tf one shape range depth fibonacci append fibonacci fibonacci return fibonacci def main depth range tf graph default tensor build tensor depth start time time perf counter tf variable initial value tensor end time time perf counter print depth time format depth end time start time name main main info log output running code depth time depth time depth time depth time depth time depth time depth time depth time depth time depth time notice time used creating variable grows exponentially cycle detection algorithm could optimized linear time complexity also algorithm avoid stack overflow initial value long dependency chain,2019-05-14 01:17:34,1557796654,resolved fixed,fc20e9fe8223336b491cedd4bc428867bf0e7daa,1559153303,tensorflow\python\kernel_tests\variables_test.py tensorflow\python\ops\variables.py                                                          
140,28725,Autograph fails for keyword-only arguments,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux tensorflow installed source binary pip install tf nightly gpu preview tensorflow version use command v1 gc095504 dev20190514 python version describe current behavior autograph complains compiling function keyword argument example output w0515 ag logging py entity could transformed executed feature e g tensor dependent conditionals loop may work expected error detail found log running env variable autograph verbosity please report autograph team cause unexpected error transforming believe due bug please set verbosity linux export autograph verbosity attach full output filing bug report caused inconsistent node none nonetype none nonetype describe expected behavior autograph work keyword argument code reproduce issue import tensorflow tf tf function def f return f,2019-05-15 01:46:51,1557884811,resolved fixed,22ba2ebfc9779ca61e574ddf6411ee5565381cec,1560440648,tensorflow\python\autograph\impl\BUILD tensorflow\python\autograph\impl\api_py3_test.py tensorflow\python\autograph\pyct\ast_util.py tensorflow\python\autograph\pyct\pretty_printer.py                                                      
141,28849,Python3 type annotation does not work with @tf.function + for loop -&gt; tf.while_loop conversion,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command alpha python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior use python3 type annotation x tf tensor tf constant aliased tf tensor various shape keep sanity reinforcement learning problem tf function function contains loop translated tf loop even use tensor annotated code fail turn eager execution describe expected behavior python3 type hinting fail code code reproduce issue tf function def tf tf break x tf tensor tf constant tf range x return x print tf tf break info log warning logging flag parsing go stderr w0519 tf logging py entity could transformed staged without change error detail found log running env variable autograph verbosity please report autograph team cause attributeerror conversion nonetype object attribute field traceback recent call last file home jackshi local lib python3 site package tensorflow python autograph impl conversion py line function graph node node graph node context file home jackshi local lib python3 site package tensorflow python autograph impl conversion py line node graph node converter standard analysis node context initial true file home jackshi local lib python3 site package tensorflow python autograph core converter py line standard analysis graph cfg build node file home jackshi local lib python3 site package tensorflow python autograph pyct cfg py line build visitor visit node file usr lib python3 ast py line visit return visitor node file home jackshi local lib python3 site package tensorflow python autograph pyct cfg py line visit functiondef self visit stmt file usr lib python3 ast py line visit return visitor node file usr lib python3 ast py line generic visit field value iter field node file usr lib python3 ast py line iter field field node field attributeerror nonetype object attribute field handling exception another exception occurred traceback recent call last file home jackshi local lib python3 site package tensorflow python autograph impl api py line converted call experimental partial type partial type file home jackshi local lib python3 site package tensorflow python autograph impl api py line graph arg value arg type file home jackshi local lib python3 site package tensorflow python autograph impl conversion py line entity graph node name n function graph program ctx arg value arg type file home jackshi local lib python3 site package tensorflow python autograph impl conversion py line function graph raise error internalerror conversion e tensorflow python autograph pyct error internalerror attributeerror conversion nonetype object attribute field handling exception another exception occurred traceback recent call last file home jackshi magneticaccelerator descrete optimization tf scratch py line print tf tf break file home jackshi local lib python3 site package tensorflow python eager def function py line call self initialize args kwds add initializers initializer map file home jackshi local lib python3 site package tensorflow python eager def function py line initialize args kwds file home jackshi local lib python3 site package tensorflow python eager function py line get concrete function internal garbage collected graph function self maybe define function args kwargs file home jackshi local lib python3 site package tensorflow python eager function py line maybe define function graph function self create graph function args kwargs file home jackshi local lib python3 site package tensorflow python eager function py line create graph function capture value self capture value file home jackshi local lib python3 site package tensorflow python framework func graph py line func graph py func func output python func func args func kwargs file home jackshi local lib python3 site package tensorflow python eager def function py line wrapped fn return weak wrapped fn wrapped args kwds file home jackshi local lib python3 site package tensorflow python framework func graph py line wrapper args kwargs file home jackshi local lib python3 site package tensorflow python autograph impl api py line converted call return call unconverted f args kwargs file home jackshi local lib python3 site package tensorflow python autograph impl api py line call unconverted return f args kwargs file home jackshi magneticaccelerator descrete optimization tf scratch py line tf tf break tf range file home jackshi local lib python3 site package tensorflow python framework ops py line iter tensor object iterable eager execution typeerror tensor object iterable eager execution enabled iterate tensor use tf map fn,2019-05-20 04:36:19,1558326979,resolved fixed,d3dd0726fc2a6be6235bc1e9c8825056278d3470,1563218514,tensorflow\python\autograph\pyct\static_analysis\activity.py tensorflow\python\autograph\pyct\static_analysis\activity_py3_test.py                                                          
142,29060,"""Cache iterator is in an invalid state"" error",system information os platform distribution macos high sierra tensorflow cpu installed pypi tensorflow version v1 rc2 g6612da8951 python version describe current behavior minimal working example import tensorflow tf tensorflow python framework error impl import outofrangeerror dataset tf data dataset range dataset dataset cache cache1 dataset dataset map lambda dataset dataset batch batch dataset make one shot iterator get next tf session sess true try re sess run batch print re except outofrangeerror print range break code properly iterates dataset first run cache exist load dataset cache file crash error tensorflow python framework error impl internalerror cache iterator invalid state perhaps getnext called end sequence node iteratorgetnext workaround happens map operation follows right cache start working expected dataset operation added cache map step example dataset tf data dataset range dataset dataset cache cache1 dataset dataset filter lambda x true fake filter added dataset dataset map lambda dataset dataset batch,2019-05-27 14:33:15,1558967595,resolved fixed,003e400902b85626d32727589142d12269306703,1560291955,tensorflow\core\kernels\data\cache_dataset_ops.cc tensorflow\python\data\kernel_tests\cache_test.py                                                          
143,29187,TF 2.0: Cannot use recurrent_dropout with LSTMs/GRUs,system information written custom code opposed using stock example script provided tensorflow one line modification stock example os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command tensorflow gpu alpha0 also fails every tf build explored python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version tried multiple gpu model memory tried multiple describe current behavior program crash typeerror typeerror op outside function building code passed graph tensor possible graph tensor leak function building context including tf init scope function building code example following function fail tf function def init scope constant tf constant tf init scope added constant graph tensor name encoder unified gru one like occurs trying backprop gradient lstm gru recurrent dropout enabled describe expected behavior error since problem show time training one need entire training pipeline dataset model etc setup demonstrate bug result used neural machine translation tutorial tensorflow modified model include entire code found colab notebook run code block way till block training model see bug info log x typeerror traceback recent call last batch inp targ enumerate dataset take step per epoch batch loss train step inp targ enc hidden total loss batch loss frame usr local lib python3 dist package tensorflow python eager def function py call self args kwds lifting succeeded variable initialized run stateless function return self stateless fn args kwds else canon args canon kwds self canonicalize function input args kwds usr local lib python3 dist package tensorflow python eager function py call self args kwargs calls graph function specialized input graph function args kwargs self maybe define function args kwargs return graph function filtered call args kwargs pylint disable protected access property usr local lib python3 dist package tensorflow python eager function py filtered call self args kwargs return self call flat nest flatten args kwargs isinstance ops tensor resource variable ops resourcevariable usr local lib python3 dist package tensorflow python eager function py call flat self args need override gradient graph mode output context executing eagerly self output output self inference function call ctx args else self register gradient usr local lib python3 dist package tensorflow python eager function py call self ctx args attrs executor type executor type config proto config ctx ctx replace empty list none output output none usr local lib python3 dist package tensorflow python eager execute py quick execute op name num output input attrs ctx name ops kera symbolic tensor x x input raise core symbolicexception raise e pylint enable protected access return tensor usr local lib python3 dist package tensorflow python eager execute py quick execute op name num output input attrs ctx name tensor pywrap tensorflow tfe py execute ctx handle device name op name input attrs num output except core notokstatusexception e name none typeerror op outside function building code passed graph tensor possible graph tensor leak function building context including tf init scope function building code example following function fail tf function def init scope constant tf constant tf init scope added constant graph tensor name encoder unified gru one like,2019-05-30 20:57:03,1559249823,resolved fixed,180f28a26660ca2e1ba27477f4f9592db5f9c4e8,1559662281,tensorflow\python\keras\layers\recurrent_v2.py tensorflow\python\keras\layers\recurrent_v2_test.py                                                          
144,29191,tf.function spuriously fails for branched super() calls,tf function fails spuriously python following example import tensorflow tf class base tf module def call self x return x class sub base def call self x return super call x true else tf function def test return sub tf constant print test colab produce following error runtimeerror converted code bug py test return sub tf constant bug py call return super call x true else runtimeerror super argument observations everything work correctly without tf function decoration branch call seems necessary trigger bug skipping branch trigger replacing true false trigger bug triggered even condition evaluates false example replacing true x x replacing tf constant trigger bug tested tensorflow nightly dev20190529 ubuntu python,2019-05-31 00:08:02,1559261282,resolved fixed,4d4f7ed0a4605975e45efe9ca1750653190aeedf,1564680613,tensorflow\python\autograph\converters\call_trees.py tensorflow\python\autograph\converters\function_scopes.py tensorflow\python\autograph\core\converter.py tensorflow\python\autograph\core\converter_testing.py tensorflow\python\autograph\core\function_wrappers.py tensorflow\python\autograph\core\function_wrappers_test.py tensorflow\python\autograph\impl\api.py tensorflow\python\autograph\impl\conversion.py tensorflow\python\autograph\operators\BUILD tensorflow\python\autograph\operators\py_builtins.py tensorflow\python\autograph\operators\py_builtins_py3_test.py tensorflow\python\autograph\operators\py_builtins_test.py                                      
145,29250,[TF 2.0 API Docs] tf.autograph.set_verbosity,url issue description issue need changing clear description description could clearer reference abseil logging format could referenced rather abseil user would hunt doc see logging output format referenced slight misspelling args alsologtostdout recommended set value large number like recommended set value large number like submit pull request yes,2019-06-01 16:02:49,1559404969,resolved fixed,61133370602a5fc7b3313ea7f8f745dae66b3c38,1559877196,tensorflow\python\autograph\utils\ag_logging.py                                                            
146,29270,tf.autograph.experimental.Feature,url issue description issue need changing clear description description provided parameters defined parameters undefined returns defined return value defined raises listed defined errors defined usage example usage example,2019-06-01 20:38:39,1559421519,resolved fixed,629e5a8a56653b16cb784a52009ff1ceaf3db73b,1560378377,tensorflow\python\autograph\core\converter.py                                                            
147,29277,[TF 2.0 API Docs] tf.nn.dropout,url issue description issue need changing usage example usages linked none detailed inline page,2019-06-01 20:52:40,1559422360,resolved fixed,951be80fc6873434b8ab2bef65d437b094037c86,1599851417,tensorflow\python\distribute\BUILD tensorflow\python\distribute\parameter_server_strategy_v2.py                                                          
148,29342,tf.config.set_soft_device_placement() seems to have no effect,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macosx mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command version dev20190527 git version v1 gc5b8e15064 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version cuda colab gpu instance gpu model memory tesla p4 describe current behavior tf config set soft device placement function seems effect create integer variable try place gpu still get exception describe expected behavior expect soft placement fallback using cpu error code reproduce issue import tensorflow tf tf config set soft device placement true tf device gpu f tf variable info log code cause following exception notfounderror traceback recent call last tf config set soft device placement true tf device gpu f tf variable frame usr local lib python3 dist package tensorflow python ops variable py call cl args kwargs return cl variable v1 call args kwargs elif cl variable return cl variable v2 call args kwargs else return super variablemetaclass cl call args kwargs usr local lib python3 dist package tensorflow python ops variable py variable v2 call cl initial value trainable validate shape caching device name variable def dtype import scope constraint synchronization aggregation shape synchronization synchronization aggregation aggregation shape shape def call cl args kwargs usr local lib python3 dist package tensorflow python ops variable py kw shape none call variable class useful force signature previous getter lambda kw default variable creator v2 none kw getter ops get default graph variable creator stack pylint disable protected access previous getter make getter getter previous getter usr local lib python3 dist package tensorflow python ops variable scope py default variable creator v2 next creator kwargs synchronization synchronization aggregation aggregation shape shape usr local lib python3 dist package tensorflow python ops variable py call cl args kwargs return cl variable v2 call args kwargs else return super variablemetaclass cl call args kwargs usr local lib python3 dist package tensorflow python ops resource variable ops py init self initial value trainable collection validate shape caching device name dtype variable def import scope constraint distribute strategy synchronization aggregation shape synchronization synchronization aggregation aggregation shape shape def repr self usr local lib python3 dist package tensorflow python ops resource variable ops py init args self initial value trainable collection caching device name dtype constraint synchronization aggregation shape shared name shared name name name graph mode self graph mode pylint disable protected access self graph mode initial value none usr local lib python3 dist package tensorflow python ops resource variable ops py eager safe variable handle initial value shape shared name name graph mode dtype initial value dtype base dtype return variable handle shape dtype shape dtype shared name name graph mode initial value usr local lib python3 dist package tensorflow python ops resource variable ops py variable handle shape dtype shape dtype shared name name graph mode extra handle data shared name shared name name name container container extra handle data none extra handle data handle usr local lib python3 dist package tensorflow python ops gen resource variable ops py var handle op dtype shape container shared name name else message e message six raise core status exception e code message none add node tensorflow graph dtype execute make type dtype dtype usr local lib python3 dist package six py raise value value notfounderror registered varhandleop opkernel gpu device compatible node node varhandleop opkernel found attribute match requested attributes container dtype dt int32 shape shared name cd2c89b7 ad83 registered device gpu dtype dt variant device gpu dtype dt int64 device gpu dtype dt complex128 device gpu dtype dt complex64 device gpu dtype dt bool device gpu dtype dt double device gpu dtype dt float device gpu dtype dt half device cpu device xla cpu device xla gpu op varhandleop name variable,2019-06-03 01:51:19,1559526679,resolved fixed,7360531c13113a19120d798278cd20bec2e5e0c3,1562196941,tensorflow\c\eager\c_api.cc tensorflow\c\eager\c_api_experimental_test.cc tensorflow\core\BUILD tensorflow\core\common_runtime\colocation_graph.cc tensorflow\core\common_runtime\colocation_graph.h tensorflow\core\common_runtime\eager\BUILD tensorflow\core\common_runtime\eager\context.cc tensorflow\core\common_runtime\eager\context.h tensorflow\core\common_runtime\eager\eager_operation.cc tensorflow\core\common_runtime\eager\eager_operation.h tensorflow\core\common_runtime\eager\execute.cc tensorflow\core\common_runtime\process_function_library_runtime.h tensorflow\core\distributed_runtime\eager\eager_service_impl.cc tensorflow\core\util\device_name_utils.cc tensorflow\core\util\device_name_utils.h tensorflow\python\eager\BUILD tensorflow\python\eager\device_placement_test.py                            
149,29393,[2.0alpha0 AutoGraph] tf.function does not automatically transform nested class methods,system information written custom code opposed using stock example script provided tensorflow yes tensorflow installed source binary binary tensorflow version use command python version describe current behavior define multiple method class decorate one tf function nested method automatically transformed error raise describe expected behavior need decorate outermost method code reproduce issue coding utf author lin lan ryan linlan gmail com future import absolute import future import division future import print function import tensorflow tf class foo tf kera model def init self super foo self init self dense tf kera layer dense self embeddings tf variable tf random normal dtype tf float32 tf function def call self input embeddings tf nn embedding lookup self embeddings input return self inner embeddings tf function def inner self embeddings batch tf shape embeddings ta tf tensorarray tf float32 size batch tf range batch self dense embeddings tf newaxis ta ta write return ta stack foo foo re foo info log typeerror tensor object iterable eager execution enabled iterate tensor use tf map fn also decorating method inner eliminate error,2019-06-04 14:02:21,1559656941,resolved fixed,665bd441195ce352b0d5ce74d5fd2dc19fa4a614,1560807966,tensorflow\python\autograph\impl\conversion.py tensorflow\python\autograph\impl\conversion_test.py tensorflow\python\autograph\pyct\inspect_utils.py                                                        
150,29406,[TF 2.0 API Docs] tf.data.experimental.make_saveable_from_iterator,url issue description issue need changing returns defined return section missing raises listed defined raises neither listed defined,2019-06-04 17:00:20,1559667620,resolved fixed,82ccb44214ae7d9019826f658dc27a87e37c89f3,1559763745,tensorflow\python\data\experimental\ops\iterator_ops.py                                                            
151,29439,Unittest and test_session interaction,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory environment capture available describe current behavior additional ghost test run skipped using unittest tensorflow testcase class behavior present upgrading test skipped entirely ghost test regard test session method within tensorflow python framework testutils unittest belief test actually test describe expected behavior ghost test run test work code reproduce issue import tensorflow tf import numpy np import unittest print tf version def get entry np index d1 index d2 batch size result np zero batch size range batch size result index d1 index d2 return result def get entry tf index d1 index d2 batch size index tf stack tf range batch size index d1 index d2 axis return tf gather nd index start region interest please enable disable region tensorflow behaviour seen try delattr tf test testcase test session except attributeerror pas class owntestcase tf test testcase pas end region interest class testcasetest tf test testcase def test get entry self success true range sample input batch size d1 d2 map int np random randint low high size test input np random random batch size d1 d2 test index d1 np random randint low high d1 size batch size test index d2 np random randint low high d2 size batch size evaluate numpy version test result get entry np test input test index d1 test index d2 batch size evaluate tensorflow version self cached session sess tf input tf constant test input dtype tf float32 tf index d1 tf constant test index d1 dtype tf int32 tf index d2 tf constant test index d2 dtype tf int32 tf result get entry tf tf input tf index d1 tf index d2 batch size tf result sess run tf result check output similar success success np allclose test result tf result self assertequal success true,2019-06-05 12:45:29,1559738729,resolved fixed,1e30076f57bf30838b5cb2e59f05e13deb944d1b,1573517899,tensorflow\python\framework\test_util.py                                                            
152,29501,tensorflow debugger `run -t` fails on keras,see description system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac os mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior exception thrown describe expected behavior run number iteration specified run command code reproduce issue see info log,2019-06-06 16:50:40,1559839840,resolved fixed,b2bdbfb9260fe58d9c5bfe9df11fc51535e5fef3,1560885429,tensorflow\python\debug\BUILD tensorflow\python\debug\examples\examples_test.sh tensorflow\python\debug\wrappers\framework.py tensorflow\python\debug\wrappers\local_cli_wrapper_test.py                                                      
153,29509,How to convert a tensorlfow SpaceToBatchND-Conv2D-BatchToSpaceND to a single Conv2D in tflite,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device na tensorflow installed source binary source tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf trying train deeplab model using code convert tflite target get model similar however model obtained contains operation like spacetobatchnd batchtospacend operation supported tflite opengles backend reduced model performance device hosted deeplab model three ops replaced depthwise conv v2 option set dilation factor would best solution sure convert spacetobatchnd conv2d batchtospacend singe depthwise conv v2 dilation fyi tried graph transforms tool tensorflow tool graph transforms flatten atrous conv upsampled kernel instead space batch batch space transform lead much computation afford describe expected behavior convert spacetobatchnd conv2d batchtospacend singe depthwise conv v2 dilation code reproduce issue provide reproducible test case bare minimum necessary generate problem try model deeplab model zoo example info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-06-06 18:47:01,1559846821,resolved fixed,f54bb6f5578b931d79884302768996ba1073f685,1580254366,tensorflow\compiler\mlir\lite\BUILD tensorflow\compiler\mlir\lite\tests\dilated-conv.mlir tensorflow\compiler\mlir\lite\transforms\dilated_conv.cc tensorflow\compiler\mlir\lite\transforms\dilated_conv.h tensorflow\compiler\mlir\lite\transforms\prepare_tf.cc                                                    
154,29656,Bug on `gather_nd` with gradient.,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary pip tensorflow version use command tf2 gpu beta python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior simple test code v tf variable np random uniform size dtype tf float32 tf gradienttape tape l tf gather nd v l tf reduce sum l grad tape gradient l v print grad give following error message lookuperror traceback recent call last l tf reduce sum l grad tape gradient l v print grad anaconda3 envs tf2 lib python3 site package tensorflow python eager backprop py gradient self target source output gradient unconnected gradient output gradient output gradient source raw flat source raw unconnected gradient unconnected gradient self persistent anaconda3 envs tf2 lib python3 site package tensorflow python eager imperative grad py imperative grad tape target source output gradient source raw unconnected gradient output gradient source raw compat str unconnected gradient value anaconda3 envs tf2 lib python3 site package tensorflow python eager backprop py gradient function op name attr tuple num input input output grad skip input index mock op mockop attr tuple input output op name skip input index grad fn ops gradient registry lookup op name pylint disable protected access grad fn none return none num input anaconda3 envs tf2 lib python3 site package tensorflow python framework registry py lookup self name else raise lookuperror registry entry self name name lookuperror gradient registry entry resourcegathernd describe expected behavior grad error occurs code reproduce issue provide reproducible test case bare minimum necessary generate problem info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-06-11 17:45:05,1560275105,resolved fixed,a7ef0da19be94d5f189c8a3af960f1da77e58b41,1560459809,tensorflow\python\kernel_tests\BUILD tensorflow\python\kernel_tests\resource_variable_ops_test.py tensorflow\python\ops\array_grad.py                                                        
155,29856,tf.keras.layers.UpSampling2D(interpolation='bilinear') has a smearing defect on the right & bottom edges,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow provided link colab notebook demonstrating issue comparing kera upsampling look like correct implementation seen tf image resize os platform distribution e g linux ubuntu google colab mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v2 beta0 g1d91213fe7 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n collect information using environment capture script also obtain tensorflow version tf tf describe current behavior upsampling using tf kera layer upsampling2d result unnatural smearing right bottom edge image problem amplified upsampling repeated describe expected behavior keras layer use sensible default behaviour smearing issue cause serious problem autoencoders gans cost month time correct behaviour seen tf image resize size size method tf image resizemethod bilinear keras upsampling use default instead current defective behaviour note tensorflow x tf image resize method align corner parameter toggled defective proper behaviour set false defective behaviour default tensorflow parameter removed correct behaviour align corner true behaviour default kera layer follow path colab notebook demonstrates issue info log,2019-06-17 01:49:41,1560736181,resolved fixed,15f6c30d7977c92ba452eb5c1873b8c9f0968a5f,1561604006,tensorflow\python\keras\backend.py tensorflow\python\ops\image_ops_impl.py                                                          
156,29881,The call method of DenseFeatures and SequenceFeatures use deprecated attribute _num_buckets,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos tensorflow installed source binary pip install tensorflow version use command v1 gf59745a381 beta0 python version v3 oct describe current behavior simply calling call method densefeatures sequencefeatures defined categorical column identity sequence categorical column identity feature column along embedding column get warning deprecated attribute num bucket used instead non deprecated num bucket guess also note code example third warning deprecated method add dispatch support wrapper arises understand instruction updating given warning see code describe expected behavior think get warning deprecated object calling deprecated method attribute etc think somewhere code call method densefeatures sequencefeatures use num bucket replaced num bucket following updating instruction third warning may enough get rid code reproduce issue import numpy np import tensorflow tf tensorflow feature column import categorical column identity embedding column sequence categorical column identity tensorflow kera layer import densefeatures tensorflow kera experimental import sequencefeatures print tf version git version tf version version nb feature emb dim fc categorical column identity feature1 nb feature emb fc embedding column fc emb dim layer densefeatures emb fc seq fc sequence categorical column identity feature2 nb feature emb seq fc embedding column seq fc emb dim seq layer sequencefeatures emb seq fc data1 np array range nb feature batch size sequence length raw data2 np array range nb feature data2 np reshape raw data2 batch size sequence length dict data feature1 data1 feature2 data2 print layer dict data print seq layer dict data produce following three warning warning logging flag parsing go stderr w0617 deprecation py users myusername documents tf2beta lib python3 site package tensorflow python feature column feature column v2 py identitycategoricalcolumn num bucket tensorflow python feature column feature column v2 deprecated removed future version instructions updating old featurecolumn apis deprecated please use new featurecolumn apis instead w0617 deprecation py users myusername documents tf2beta lib python3 site package tensorflow python feature column feature column v2 py add dispatch support wrapper tensorflow python ops array ops deprecated removed future version instructions updating use tf broadcast rule np w0617 deprecation py users myusername documents tf2beta lib python3 site package tensorflow python feature column feature column v2 py sequencecategoricalcolumn num bucket tensorflow python feature column feature column v2 deprecated removed future version instructions updating old featurecolumn apis deprecated please use new featurecolumn apis instead,2019-06-17 17:27:01,1560792421,resolved fixed,d7e858192d1de827bc03705ac62e1bd38daf06d8,1561253157,tensorflow\python\feature_column\feature_column_v2.py tensorflow\python\ops\array_ops.py                                                          
157,29989,Segmentation fault when saving checkpoints with saveable Dataset Iterator,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu centos mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source none gcc compiler version compiling source none cuda cudnn version none gpu model memory none tf version v1 g6612da8951 describe current behavior segmentation fault saving initializable dataset iterator entering tf train monitoredsession context manager describe expected behavior initializable iterator saved restored properly behaving one shot iterator code reproduce issue illustrate saveable dataset iterator import tensorflow tf dataset size save steps train step checkpoint dir tmp tf dataset saveable def test saveable test saveable graph tf graph graph default dataset tf data dataset range dataset size repeat dataset iterator dataset make one shot iterator dataset iterator dataset make initializable iterator dataset init dataset iterator initializer data dataset iterator get next saveable tf contrib data make saveable iterator dataset iterator tf add collection tf graphkeys saveable objects saveable global step tf train get create global step inc global step tf assign add global step critical saver tf train saver checkpoint dir checkpoint dir scaffold tf train scaffold saver saver checkpoint hook tf train checkpointsaverhook checkpoint dir checkpoint dir save step save steps scaffold scaffold hook checkpoint hook session creator tf train chiefsessioncreator scaffold scaffold checkpoint dir checkpoint dir tf train monitoredsession session creator session creator hook hook mon sess gstep mon sess run global step gstep mon sess run dataset init range train step print mon sess run global step data mon sess run inc global step name main test saveable info log tf py3 huwh1 huwh1 centos worksync python tf dataset saveable py warning tensorflow home huwh1 virtualenv tf py3 lib python3 site package tensorflow python data ops dataset ops py colocate tensorflow python framework ops deprecated removed future version instructions updating colocations handled automatically placer warning tensorflow contrib module included tensorflow information please see depend functionality listed please file issue warning tensorflow tf dataset saveable py make saveable iterator tensorflow contrib data python ops iterator ops deprecated removed future version instructions updating use tf data experimental make saveable iterator tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device segmentation fault core dumped tf py3 huwh1 huwh1 centos worksync,2019-06-20 02:46:50,1560998810,resolved fixed,51d1f486fcbe5bc8857586250fd5b10ca110d631,1563236909,tensorflow\core\kernels\data\iterator_ops.cc tensorflow\python\data\experimental\kernel_tests\serialization\serialization_integration_test.py                                                          
158,30028,Python package is missing ModuleSpec in tensorflow.__spec__ in tf 1.14.0,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux linuxkit x86 ubuntu bionic mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary preinstalled docker image tensorflow version use command v1 rc1 gaf24dc91b5 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior tf module spec tensorflow spec none import tensorflow print tensorflow spec none describe expected behavior different tf work expected import tensorflow print tensorflow spec modulespec name tensorflow loader origin usr local lib python3 dist package tensorflow init py submodule search location usr local lib python3 dist package tensorflow missing spec cause problem e g pkgutil fails trying find tensorflow note first call find loader successful fails tensorflow imported python default jan gcc experimental trunk revision linux type help copyright credit license information import pkgutil pkgutil find loader tensorflow import tensorflow pkgutil find loader tensorflow traceback recent call last file usr lib python3 pkgutil py line find loader spec importlib util find spec fullname file usr lib python3 importlib util py line find spec raise valueerror spec none format name valueerror tensorflow spec none exception direct cause following exception traceback recent call last file line file usr lib python3 pkgutil py line find loader raise importerror msg format fullname type ex ex ex importerror error finding loader tensorflow tensorflow spec none code reproduce issue see info log tested using official tf docker image tensorflow tensorflow py3 also using python docker image python tensorflow installed pip,2019-06-21 11:52:09,1561117929,resolved fixed,b789a3b37b59e6795f799645a6e8b1a6c70fc346,1561749790,tensorflow\python\util\deprecation_wrapper.py tensorflow\python\util\deprecation_wrapper_test.py tensorflow\tools\api\tests\BUILD tensorflow\tools\api\tests\deprecation_test.py tensorflow\tools\api\tests\module_test.py                                                    
159,30113,tf.image.encode_png doesn't support 16 bit and inconsistent behavior in eager mode,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu win mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command tested python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior creating numpy array uint16 datatype passing tf image encode png yield different result eager execution mode first time array passed somehow get transformed uint8 array following encoding work expected using tf session uint16 input always transformed uint8 describe expected behavior return bytestring png code reproduce issue provide reproducible test case bare minimum necessary generate problem import numpy np import tensorflow tf tf enable eager execution np random seed np random randint low high size dtype np uint16 reshape b copy np allclose b true eager execution encoded tf image encode png numpy b encoded tf image encode png b numpy print len encoded len b encoded print expected time assert encoded b encoded fails session mode encode tf image encode png encode b tf image encode png b tf session sess encoded sess run encode b encoded sess run encode b print len encoded len b encoded print expected assert encoded b encoded true info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-06-25 09:44:55,1561455895,resolved fixed,7807ec92bf8f44b5fd6de5b5342f041b168cf1f3,1574475305,tensorflow\python\eager\BUILD tensorflow\python\eager\pywrap_tfe_src.cc tensorflow\python\eager\pywrap_tfe_test.py tensorflow\python\framework\test_ops.cc                                                      
160,30149,"Autograph ""Failed to parse source code"" error when using lambda in for loop",system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macosx mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command version dev20190625 git version v1 g71241a6afd python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior get autograph error running following code see full stacktrace import tensorflow tf d tf data dataset range window shift drop remainder true window d flat map lambda window window batch print window numpy error valueerror failed parse source code describe expected behavior everything work fine define dataset previous line like import tensorflow tf d tf data dataset range window shift drop remainder true d d flat map lambda window window batch window d print window numpy code reproduce issue see info log full stack trace autograph verbosity tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device converted call args kwargs whitelisted default rule whitelisted default rule entity cached key file line subkey frozenset converting warning logging flag parsing go stderr e0625 ag logging py error converting traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl api py line graph return conversion convert entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert free nonglobal var name file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert cache entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert entity ast node name entity info convert func ast program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert func ast node source parser parse entity f future feature future feature file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity source n nbut work format source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line raise parse failure format entity source comment valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work error error converting traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl api py line graph return conversion convert entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert free nonglobal var name file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert cache entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert entity ast node name entity info convert func ast program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert func ast node source parser parse entity f future feature future feature file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity source n nbut work format source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line raise parse failure format entity source comment valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work error transforming entity traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity return parse str source preamble len len future feature source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse str module node gast parse src file users ageron miniconda3 envs tf2 lib python3 site package gast gast py line parse return ast gast ast parse args kwargs file users ageron miniconda3 envs tf2 lib python3 ast py line parse return compile source filename mode pycf ast file line window d flat map lambda window window batch syntaxerror unexpected eof parsing handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl api py line graph return conversion convert entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert free nonglobal var name file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert cache entity program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert entity ast node name entity info convert func ast program ctx file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl conversion py line convert func ast node source parser parse entity f future feature future feature file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line parse entity source n nbut work format source file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph pyct parser py line raise parse failure format entity source comment valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work handling exception another exception occurred traceback recent call last file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl api py line converted call experimental optional feature option optional feature file users ageron miniconda3 envs tf2 lib python3 site package tensorflow core python autograph impl api py line graph entity e class name str e tensorflow python autograph impl api conversionerror converting valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work w0625 ag logging py entity could transformed executed please report autograph team filing bug set verbosity linux export autograph verbosity attach full output cause converting valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work warning entity could transformed executed please report autograph team filing bug set verbosity linux export autograph verbosity attach full output cause converting valueerror failed parse source code python reported future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch lambda function error may avoided creating lambda standalone statement tried strip source future import absolute import future import division future import print function future import unicode literal window d flat map lambda window window batch work w tensorflow compiler jit mark compilation pas cc one time warning using xla cpu cluster envvar tf xla flags tf xla cpu global jit set want xla cpu either set envvar use experimental jit scope enable xla cpu confirm xla active pas vmodule xla compilation cache proper command line flag via tf xla flags set envvar xla flags xla hlo profile,2019-06-25 20:34:21,1561494861,resolved fixed,38df5d8ef43e884674f22670dbfd19ec26782f17,1562005130,tensorflow\python\autograph\pyct\parser.py                                                            
161,30165,TF 2.0 - Put Tensor into some Numpy functions continuously increases memory usage,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary pip package tensorflow beta1 tensorflow version use command v2 beta0 g8e423e3 beta1 python version cuda cudnn version gpu model memory titan xp describe current behavior memory leak put tensor numpy function ex np array np zero like following attached code continuously increase memory usage describe expected behavior memory usage explosion code reproduce issue import tensorflow tf import numpy np import time x tf random normal range int np array x time sleep,2019-06-26 08:01:16,1561536076,resolved fixed,d5b287d6c93332ba73b99b375bd21f81266e3112,1562579573,tensorflow\c\eager\c_api.cc tensorflow\c\eager\c_api_internal.h tensorflow\python\eager\pywrap_tensor.cc tensorflow\python\framework\ops.py tensorflow\python\lib\core\ndarray_tensor.cc tensorflow\python\lib\core\ndarray_tensor.h tensorflow\python\lib\core\py_func.cc tensorflow\python\ops\script_ops.py                                              
162,30248,tf.io.write_file not working in tf.function decorated function,system information os platform distribution e g linux ubuntu ubuntu windows tensorflow installed source binary binary tensorflow version use command beta1 python version describe current behavior tf io write file creates file eager execution produce output file decorated tf function describe expected behavior tf io write file create output file whether decorated tf function code reproduce issue import tensorflow tf tf function def writejpeg graph img decoded filename tf cast img decoded tf uint8 tf image encode jpeg quality tf io write file filename def writejpeg eager img decoded filename tf cast img decoded tf uint8 tf image encode jpeg quality tf io write file filename img tf fill example gray image writejpeg graph img tfwrite graph jpg tfwrite graph jpg created writejpeg eager img tfwrite eager jpg tfwrite eager jpg created,2019-06-29 15:10:02,1561821002,resolved fixed,3baef3b569344f0af6071950a5fc9d828a4ee6a6,1562061850,tensorflow\core\ops\io_ops.cc                                                            
163,30378,Problems with keras model saving when there's a loss added with add_loss,system information system window wsl ubuntu lts tensorflow version cpu mode default installed pip python version also happens real linux environment actually easy simulate error describe current behavior many problem saving loading kera model custom loss added add loss describe one scenario think related code reproduce issue inp tf kera input batch size shape tensor tf kera layer conv2d filter kernel size inp model tf kera model input inp output tensor model add loss tf kera loss mean absolute error tensor tensor model compile adam tf kera experimental export saved model model model tf using kera layer loss produce non valid json traceback recent call last file home nguerinjr documents deep coding project teste py line tf kera experimental export saved model model model tf file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line export saved model export model json model saved model path file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line export model json model json model json file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera engine network py line json model config default serialization get json type kwargs file usr lib python3 json init py line dump kw encode obj file usr lib python3 json encoder py line encode chunk self iterencode one shot true file usr lib python3 json encoder py line iterencode return iterencode file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python util serialization py line get json type raise typeerror json serializable obj typeerror json serializable b n x03add x12 x03add x1a x0fconv2d identity x1a x05add x07 n x01t x12 x020 x01 code us kera layer code reproduce issue inp tf kera input batch size shape tensor tf kera layer conv2d filter kernel size inp model tf kera model input inp output tensor lbd tf kera layer lambda lambda tf kera loss mean absolute error model add loss lbd tensor tensor model compile adam tf kera experimental export saved model model model tf traceback recent call last file home nguerinjr documents deep coding project teste py line tf kera experimental export saved model model model tf file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line export saved model input signature file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line save v1 format export mode mode key modekeys train saved var export args file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line export mode compile clone compile clone file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera model py line clone build model clone clone model model input tensor input tensor file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera model py line clone model model input tensor input tensor layer fn clone function file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera model py line clone functional model model insert layer ancillary layer relevant node relevant node file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera engine network py line insert layer node layer inbound node valueerror min arg empty sequence using kera layer loses inbound node debugged put apart layer loses information object question passing custom object param trying use non experimental save load code reproduce issue inp tf kera input batch size shape tensor tf kera layer conv2d filter kernel size inp model tf kera model input inp output tensor lbd tf kera layer lambda lambda tf kera loss mean absolute error model add loss lbd tensor tensor model compile adam model save model kera tf save format tf tf kera model load model model kera tf custom object lambda lbd first annoying thing based ext even though save tf2 put extension load verifies extension clear way working opinion maybe additional information file saved could make use extension traceback recent call last file home nguerinjr documents deep coding project teste py line tf kera model load model model kera tf custom object lambda lbd file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving save py line load model return saved model load saved model v2 filepath compile file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera saving saved model py line load saved model v2 model training config pylint disable protected access file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python training tracking base py line method wrapper result method self args kwargs file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera engine training py line compile self compile weight loss weighted metric file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python training tracking base py line method wrapper result method self args kwargs file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera engine training py line compile weight loss weighted metric self total loss self prepare total loss mask file home nguerinjr documents deep coding project venv lib python3 site package tensorflow python kera engine training py line prepare total loss raise valueerror model compiled valueerror model compiled loss optimize second related loading accept loss compile keras accepts see example accepts account non default loss added another saving loading bug experimental non experimental function seem problem saving loading think simulate custom scenario kera find bunch error worth take whole look specially considering keras default prototyping tool tf2 current situation thought simple easy way save kera model custom component list argument compile,2019-07-03 22:05:20,1562191520,resolved fixed,a377701899b71b5f6bb0f157be763c283c7ff7e9,1563485853,tensorflow\python\keras\distribute\distribute_strategy_test.py tensorflow\python\keras\engine\base_layer.py tensorflow\python\keras\engine\network.py tensorflow\python\keras\models.py tensorflow\python\keras\saving\hdf5_format_test.py                                                    
164,30474,[TF2.0] Bug allowing misuse of the batch dimension of a convolution layer,tensorflow rightfully complains following minimal example valueerror could broadcast input array shape shape tensorflow beta1 however happily run print import numpy np import tensorflow kera backend k tensorflow kera layer import input conv2d lambda tensorflow kera model import model def custom reshape input return k reshape input input input shape x lambda custom reshape input x conv2d x model model input input output x model compile loss mean squared error optimizer nadam print model summary batch size result model predict np one batch size batch size batch size print result shape per discussion seems bug tf,2019-07-08 05:57:13,1562565433,resolved fixed,37fcf0a0e04b2014864936397c25e6c398135772,1562985743,tensorflow\python\keras\engine\training_test.py tensorflow\python\keras\engine\training_utils.py                                                          
165,30574,Decode_wav sample rate output cannot be passed to tf.signal.linear_to_mel_weight_matrix,system information written custom code opposed using stock example script provided tensorflow combined output decode wav sample signal mfccs log mel spectrogram os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary conda binary tensorflow version use command dev20190702 git version unknown python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory surface book nvidia gpu describe current behavior output decode wav tuple wav data sample rate sample rate int32 linear mel weight matrix expects float32 sample rate sample rate cast using tf cast sample rate float32 typeerror thrown message typeerror using tf tensor python bool allowed use none instead test tensor defined use tensorflow ops tf cond execute subgraphs conditioned value tensor describe expected behavior sample rate output decode wav used input linear mel weight matrix code reproduce issue provide reproducible test case bare minimum necessary generate problem import tensorflow tf def load mel file path tensor pcm sample rate tf audio decode wav path tensor sr f tf cast sample rate tf float32 mismatch type output decode wav input linear mel weight matrix print pcm sample rate sr f point stft frame m overlap stfts tf signal stft pcm frame length frame step fft length spectrogram tf ab stfts warp linear scale spectrogram mel scale num spectrogram bin stfts shape lower edge hertz upper edge hertz num mel bin linear mel weight matrix tf signal linear mel weight matrix num mel bin num spectrogram bin sr f lower edge hertz upper edge hertz mel spectrogram tf tensordot spectrogram linear mel weight matrix mel spectrogram set shape spectrogram shape concatenate linear mel weight matrix shape compute stabilized log get log magnitude mel scale spectrogram log mel spectrogram tf math log mel spectrogram print log mel spectrogram return log mel spectrogram path d tf data dataset list file wav mel d path d map load mel file info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached typeerror traceback recent call last build datasets train d build data pair dir train dir test d build data pair dir test dir build data pair dir source dir convert mel clean mel d clean path d map load mel file num parallel call autotune noisy mel d noisy path d map load mel file num parallel call autotune c user benhe conda envs homl2 lib site package tensorflow core python data ops dataset ops py map self map func num parallel call return datasetv1adapter parallelmapdataset self map func num parallel call preserve cardinality false deprecation deprecated none use tf data dataset map c user benhe conda envs homl2 lib site package tensorflow core python data ops dataset ops py init self input dataset map func num parallel call use inter op parallelism preserve cardinality use legacy function self transformation name dataset input dataset use legacy function use legacy function self num parallel call ops convert tensor num parallel call dtype dtypes int32 name num parallel call c user benhe conda envs homl2 lib site package tensorflow core python data ops dataset ops py init self func transformation name dataset input class input shape input type input structure add graph use legacy function defun kwargs resource tracker tracking resourcetracker tracking resource tracker scope resource tracker self function wrapper fn get concrete function internal add graph self function add graph ops get default graph c user benhe conda envs homl2 lib site package tensorflow core python eager function py get concrete function internal self args kwargs bypasses error checking getting graph function graph function self get concrete function internal garbage collected args kwargs returning concrete function someone may keep reference funcgraph without keeping reference c user benhe conda envs homl2 lib site package tensorflow core python eager function py get concrete function internal garbage collected self args kwargs self input signature args kwargs none none graph function self maybe define function args kwargs return graph function c user benhe conda envs homl2 lib site package tensorflow core python eager function py maybe define function self args kwargs graph function self function cache primary get cache key none graph function none graph function self create graph function args kwargs self function cache primary cache key graph function return graph function args kwargs c user benhe conda envs homl2 lib site package tensorflow core python eager function py create graph function self args kwargs override flat arg shape arg name arg name override flat arg shape override flat arg shape capture value self capture value self function attribute c user benhe conda envs homl2 lib site package tensorflow core python framework func graph py func graph py func name python func args kwargs signature func graph autograph autograph option add control dependency arg name op return value collection capture value override flat arg shape converted func func output python func func args func kwargs invariant func output contains tensors compositetensors c user benhe conda envs homl2 lib site package tensorflow core python data ops dataset ops py wrapper fn args attribute defun kwargs def wrapper fn args pylint disable missing docstring ret wrapper helper args ret structure tensor list self output structure ret return ops convert tensor ret c user benhe conda envs homl2 lib site package tensorflow core python data ops dataset ops py wrapper helper args nested args nested args ret autograph tf convert func ag ctx nested args func return list tensor nest flatten ops convert tensor would conspire attempt stack c user benhe conda envs homl2 lib site package tensorflow core python autograph impl api py wrapper args kwargs except exception e pylint disable broad except hasattr e ag error metadata raise e ag error metadata exception type e else raise typeerror converted code load mel file linear mel weight matrix tf signal linear mel weight matrix c user benhe conda envs homl2 lib site package tensorflow core python ops signal mel ops py linear mel weight matrix lower edge hertz upper edge hertz dtype c user benhe conda envs homl2 lib site package tensorflow core python ops signal mel ops py validate argument sample rate c user benhe conda envs homl2 lib site package tensorflow core python framework ops py bool raise typeerror using tf tensor python bool allowed typeerror using tf tensor python bool allowed use none instead test tensor defined use tensorflow ops tf cond execute subgraphs conditioned value tensor,2019-07-10 18:05:41,1562781941,resolved fixed,03ff87bfdeec43b9d3a208746ae19ebf9c139c14,1568668050,tensorflow\python\kernel_tests\signal\mel_ops_test.py tensorflow\python\ops\signal\mel_ops.py                                                          
166,30642,scatter_nd_update doesn't work with string,reproduced issue newest tensorflow official docker image written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary tensorflow version use command python version model need maintain extremely long variable tensor several column many row dtype string every training step need update several individual row tensor tf scatter nd update meet requirement perfectly except work string fact contrast tf scatter nd work since document mention string think may bug describe expected behavior hope tf scatter nd update support string ref really need feature project fixed quickly walk around suggestion include modify source code also welcome code reproduce issue import tensorflow tf ref tf variable qq ww ee rr index tf constant update tf constant aa dd cc bb update tf scatter nd update ref index update tf session sess sess run tf initialize variable print sess run update info log traceback recent call last file line file usr local lib python2 dist package tensorflow python client session py line run run metadata ptr file usr local lib python2 dist package tensorflow python client session py line run feed dict tensor option run metadata file usr local lib python2 dist package tensorflow python client session py line run run metadata file usr local lib python2 dist package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl invalidargumenterror opkernel registered support op scatterndupdate used node scatterndupdate defined attrs class loc variable use locking true tindices dt int32 dt string registered device cpu xla cpu registered kernel device cpu dt bool tindices dt int64 device cpu dt bool tindices dt int32 device cpu dt complex128 tindices dt int64 device cpu dt complex128 tindices dt int32 device cpu dt complex64 tindices dt int64 device cpu dt complex64 tindices dt int32 device cpu dt double tindices dt int64 device cpu dt double tindices dt int32 device cpu dt float tindices dt int64 device cpu dt float tindices dt int32 device cpu dt bfloat16 tindices dt int64 device cpu dt bfloat16 tindices dt int32 device cpu dt half tindices dt int64 device cpu dt half tindices dt int32 device cpu dt int8 tindices dt int64 device cpu dt int8 tindices dt int32 device cpu dt uint8 tindices dt int64 device cpu dt uint8 tindices dt int32 device cpu dt int16 tindices dt int64 device cpu dt int16 tindices dt int32 device cpu dt uint16 tindices dt int64 device cpu dt uint16 tindices dt int32 device cpu dt int32 tindices dt int64 device cpu dt int32 tindices dt int32 device cpu dt int64 tindices dt int64 device cpu dt int64 tindices dt int32 scatterndupdate,2019-07-12 11:12:52,1562929972,resolved fixed,c3e32b03e187fc2854c34add42ee3d1fe1f17628,1568403940,tensorflow\core\kernels\scatter_nd_op.cc tensorflow\python\kernel_tests\scatter_nd_ops_test.py                                                          
167,30685,`TensorArray` objects used as `Dataset.reduce` state lose inferred shapes,system information tensorflow version use command python version describe current behavior tensorarray object passed accumulator dataset reduce lose inferred shape subsequent call tensorarray concat return fully unknown shape describe expected behavior element shape tensorarray partially known consistent behavior equivalent tf loop code reproduce issue tf function def compute arr tf tensorarray tf float32 dynamic size true def body arr real logits tf random normal arr arr write tf cast tf int32 real logits return arr def cond arr return arr tf loop cond body arr c arr concat tf print tensortarray concat shape c shape rank c shape rank return c tf function def compute d arr tf tensorarray tf float32 dynamic size true def body state arr state real logits tf random normal arr arr write tf cast tf int32 real logits return arr en d tf data dataset range enumerate arr en d reduce arr body c arr concat tf print tensortarray concat shape c shape rank c shape rank return c print tf loop compute print print tf dataset reduce compute d tf loop tensortarray concat shape tensorshape none rank tf dataset reduce tensortarray concat shape tensorshape none rank none,2019-07-13 18:49:53,1563043793,resolved fixed,6cd69820a7ec68363647bf918d312b5d10e0e07a,1563922618,tensorflow\python\data\util\structure_test.py tensorflow\python\ops\tensor_array_ops.py                                                          
168,31596,TFLiteConverter fails with tf.gather when the params argument is a layer attribute,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information os platform distribution e g linux ubuntu linux ubuntu lts tensorflow installed source binary conda tensorflow version use command dev20190807 python version cuda cudnn version gpu model memory x tesla p100 pcie describe current behavior able convert savedmodel flatbuffer using tfliteconverter corresponding tf kera model contains layer tf gather op params argument come variable initialized build method said layer params argument locally defined variable using tf nn embedding lookup instead tf gather everything work perfectly fine also applies tf gather nd describe expected behavior expect tf gather work case params argument attribute tf kera layer layer case mentioned code reproduce issue wrote toy example reproduce issue might clearer description import numpy np import tensorflow tf print tf version class embedding tf kera layer layer def init self vocab size hidden size super embedding self init self vocab size vocab size self hidden size hidden size def build self input shape self shared weight self add weight weight shape self vocab size self hidden size dtype tf float32 initializer tf random normal initializer mean stddev self hidden size def call self input return tf nn embedding lookup self shared weight input return tf gather tf zero shape self vocab size self hidden size input return tf gather self shared weight input class simplemodel tf kera model def init self vocab size hidden size super simplemodel self init self embedding layer embedding vocab size hidden size tf function input signature tf tensorspec shape none dtype tf int64 name input def call self input return self embedding layer input vocab size hidden size building model model simplemodel vocab size hidden size input tf random uniform shape dtype tf int64 maxval model input exporting savedmodel saved model dir simple model tf saved model save model saved model dir tflite conversion converter tf lite tfliteconverter saved model saved model dir tflite model converter convert info log traceback recent call last file home michael conda envs tf20 bin toco protos line sys exit main file home michael conda envs tf20 lib python3 site package tensorflow core lite toco python toco protos py line main app run main execute argv sys argv unparsed file home michael conda envs tf20 lib python3 site package tensorflow core python platform app py line run run main main argv argv flag parser parse flag tolerate undef file home michael conda envs tf20 lib python3 site package absl app py line run run main main args file home michael conda envs tf20 lib python3 site package absl app py line run main sys exit main argv file home michael conda envs tf20 lib python3 site package tensorflow core lite toco python toco protos py line execute enable mlir converter exception placeholder statefulpartitionedcall args specied input array,2019-08-13 22:26:37,1565735197,resolved fixed,252e6183523d226e50137c06a101df0aa5d4d5d9,1577144913,tensorflow\python\keras\saving\metrics_serialization_test.py                                                            
169,31952,[TF 2.0] tf.gather doesn't work alongside @tf.function,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu darwin kernel version mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command dev20190730 python version python anaconda inc bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior seems tf gather called tf function gradient calculated example code blow show bug code raise following error message assertionerror expected args tensors variables got compositetensor code work remove tf function decorator put tf gather line inside tf funtion graph code reproduce issue import numpy np import tensorflow tf x tf cast np random randn tf float32 z tf cast np random randn tf float32 layer tf kera layer dense tf function removing code work fine def fun x layer layer x return tf gradienttape tape fun x layer tf gather put line inside function work fine loss tf norm z grad tape gradient loss layer trainable variable,2019-08-25 09:51:25,1566726685,resolved fixed,d5ee347de231b55f8ef7c11402db1673ff111d53,1575328576,tensorflow\python\eager\backprop_test.py tensorflow\python\eager\function.py                                                          
170,32029,tensorflow.keras.Model.compute_output_shape gives wrong results,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary conda tensorflow version use command tried python version describe current behavior using kera model stored variable mm tensorflow kera would like calculate output shape given input work correctly first time call mm compute output shape subsequent result calling function different shape inconsistent using standard kera method get different consistent result example problem implemented tf bug py script find zip call without parameter load fully convolutional model json file provided zip import json import tensorflow kera kera open model tf bug json r fi kk json load fi mm kera model model json json dump kk n range s n print s mm compute output shape input shape s result displaying input corresponding output shape line kept relevant line see first line correct starting input shape output shape decrease start produce erratic behavior fully convolutional model increase monotonously input size describe expected behavior running script argument kera us vanilla kera version case output shape increase expected note get correct result tf kera well clear model output shape cache compute output shape running script argument clear us modified loop follows n range s n len sys argv sys argv clear mm output shape cache clear print s mm compute output shape input shape s result correct expected looking function mm compute output shape found compared kera changed cache key generation kera cache key join str x x input shape tf kera cache key generic utils object list uid input shape appears cache key tf kera confuses different input shape return wrong result cache code reproduce issue find script model output file zip tf compute output shape bug zip,2019-08-28 00:13:46,1566951226,resolved fixed,3ba8bd697faf4b831f78c3fa547d7956f1b1a0aa,1582239182,tensorflow\python\keras\engine\network.py tensorflow\python\keras\engine\network_test.py tensorflow\python\keras\utils\generic_utils.py                                                        
171,32049,Creating a boolean constant prints a deprecation warning,system information written custom code yes os platform distribution ubuntu tensorflow installed binary tensorflow version python version describe current behavior creating boolean constant print deprecation warning w0828 deprecation py lib python3 site package tensorflow core python framework constant op py eagertensorbase cpu tensorflow python framework ops deprecated removed future version instructions updating use tf identity instead describe expected behavior deprecation warning code reproduce issue import tensorflow tf tf zero dtype tf bool,2019-08-28 13:57:06,1567000626,resolved fixed,8d4ecb0f24c4f9fc18c248838d2496b8410961f6,1567638466,tensorflow\python\framework\constant_op.py                                                            
172,32162,[lite doc] broken link in`TensorFlow Lite and TensorFlow operator compatibility`,link page broken,2019-09-03 03:21:37,1567480897,resolved fixed,50f0bb045ca2483c516938a867df806d12b6ee49,1568075796,tensorflow\lite\g3doc\guide\ops_compatibility.md                                                            
173,32487,[TF -2] Multi gpu training error,trying train kera model two k80 written custom code os platform distribution e g linux ubuntu smp debian tensorflow version use command rc0 python version cuda cudnn version gpu model memory tesla k80 kera model trying fit import tensorflow tf import numpy np class sparseslice tf kera layer layer def init self feature column super sparseslice self init self fc feature column def build self input shape self kernel self add weight kernel format self fc name shape self fc num bucket dtype tf float32 def call self input id self fc transform input tensor input return tf expand dims tf gather self kernel id value axis strategy tf distribute mirroredstrategy strategy scope batch size sparse col tf feature column categorical column hash bucket sparse col dtype tf int64 dense col tf feature column numeric column dense col dtype tf float32 example spec tf feature column make parse example spec sparse col dense col sparse input tf kera layer input name sparse col name shape none batch size batch size sparse true dtype tf int64 dense input dense col name tf kera layer input name dense col name shape dtype tf float32 sparse sparseslice sparse col sparse input output tf kera layer dense activation sigmoid sparse num tf kera layer densefeatures dense col dense input concats tf kera layer concatenate output num output tf kera layer dense activation sigmoid concats model tf kera model dense input sparse output sparse input output model compile optimizer adam loss mse np random random feature dense col name tf constant np random random batch size feature update sparse col name tf sparse sparsetensor index range batch size value np random randint batch size dense shape batch size y tf constant np random rand batch size dtype tf float32 dataset tf data dataset tensor slice feature y batch batch size model fit x dataset epoch getting following error tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name tesla k80 major minor memoryclockrate ghz pcibusid tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name tesla k80 major minor memoryclockrate ghz pcibusid tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcudart tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcublas tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcufft tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcurand tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcusolver tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcusparse tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcudnn tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc adding visible gpu device tensorflow core common runtime gpu gpu device cc device interconnect streamexecutor strength edge matrix tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc n tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc created tensorflow device device gpu mb memory physical gpu device name tesla k80 pci bus id compute capability tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc created tensorflow device device gpu mb memory physical gpu device name tesla k80 pci bus id compute capability unknown steptraceback recent call last file opt conda lib python3 site package ipython core interactiveshell py line run code exec code obj self user global n self user n file line epoch file home cdalmaso local lib python3 site package tensorflow core python kera engine training py line fit use multiprocessing use multiprocessing file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 py line fit total epoch epoch file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 py line run one epoch batch out execution function iterator file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 utils py line execution function distributed function input fn file home cdalmaso local lib python3 site package tensorflow core python eager def function py line call self initialize args kwds add initializers initializer map file home cdalmaso local lib python3 site package tensorflow core python eager def function py line initialize args kwds file home cdalmaso local lib python3 site package tensorflow core python eager function py line get concrete function internal garbage collected graph function self maybe define function args kwargs file home cdalmaso local lib python3 site package tensorflow core python eager function py line maybe define function graph function self create graph function args kwargs file home cdalmaso local lib python3 site package tensorflow core python eager function py line create graph function capture value self capture value file home cdalmaso local lib python3 site package tensorflow core python framework func graph py line func graph py func func output python func func args func kwargs file home cdalmaso local lib python3 site package tensorflow core python eager def function py line wrapped fn return weak wrapped fn wrapped args kwds file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 utils py line distributed function model input iterator mode file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 utils py line prepare feed value input target sample weight get input iterator input file home cdalmaso local lib python3 site package tensorflow core python kera engine training v2 utils py line get input iterator next element next iterator file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line next return self get next file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line get next global value replica get next optional self self strategy file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line get next optional iterator iterators get next list new name pylint disable protected access file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line get next list lambda dummy tensor fn data value structure file home cdalmaso local lib python3 site package tensorflow core python util deprecation py line new func return func args kwargs file home cdalmaso local lib python3 site package tensorflow core python ops control flow ops py line cond return cond v2 cond v2 pred true fn false fn name file home cdalmaso local lib python3 site package tensorflow core python ops cond v2 py line cond v2 op return value pred file home cdalmaso local lib python3 site package tensorflow core python framework func graph py line func graph py func func output python func func args func kwargs file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line lambda dummy tensor fn data value structure file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line dummy tensor fn result append create dummy tensor feature shape feature type file home cdalmaso local lib python3 site package tensorflow core python distribute input lib py line create dummy tensor dim feature shape dims typeerror nonetype object iterable everything run fine exclude strategy scope,2019-09-13 06:50:22,1568357422,resolved fixed,144e0ebb1c9ede81886e215904a4e4598cd8b0b0,1570061052,tensorflow\core\common_runtime\copy_tensor.cc tensorflow\python\distribute\BUILD tensorflow\python\distribute\input_lib.py tensorflow\python\distribute\input_lib_test.py                                                      
174,32501,Error when using stateful RNN with multiple inputs,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory gtx ti describe current behavior stock example rnns multiple input produce error set seems problem multi input rnn stateful true describe expected behavior error multi input rnns stateful true work stateful false preserving state code reproduce issue note code copied exception changed line rnn tf kera layer rnn cell rnn tf kera layer rnn cell stateful true import collection import tensorflow tf nestedinput collection namedtuple nestedinput feature1 feature2 nestedstate collection namedtuple nestedstate state1 state2 class nestedcell tf kera layer layer def init self unit unit unit kwargs self unit unit self unit unit self unit unit self state size nestedstate state1 unit state2 tf tensorshape unit unit self output size unit tf tensorshape unit unit super nestedcell self init kwargs def build self input shape expect input shape contain item batch i1 batch i2 i3 input input shape feature1 input input input shape feature2 self kernel self add weight shape input self unit initializer uniform name kernel self kernel self add weight shape input input self unit self unit initializer uniform name kernel def call self input state input batch input batch input input state shape batch unit batch unit unit input input tf nest flatten input s1 s2 state output tf matmul input self kernel output tf einsum bij ijkl bkl input self kernel state s1 output state s2 output output output output new state nestedstate state1 state state2 state return output new state unit unit unit input input input batch size num batch timestep cell nestedcell unit unit unit rnn tf kera layer rnn cell stateful true inp tf kera input none input inp tf kera input none input input output rnn nestedinput feature1 inp feature2 inp model tf kera model model inp inp output model compile optimizer adam loss mse metric accuracy info log traceback recent call last file tmp2 py line output rnn nestedinput feature1 inp feature2 inp file site package tensorflow core python kera layer recurrent py line call return super rnn self call input kwargs file site package tensorflow core python kera engine base layer py line call self maybe build input file site package tensorflow core python kera engine base layer py line maybe build self build input shape file site package tensorflow core python kera layer recurrent py line build self reset state file site package tensorflow core python kera layer recurrent py line reset state spec shape none self input spec none else self input spec shape attributeerror nestedinput object attribute shape,2019-09-13 15:55:45,1568390145,resolved fixed,38b748907e04fb212c1183b4999425d768de0233,1568748377,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py                                                          
175,32543,RNN layer does not reset dropout masks of RNNCell,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos mojave tensorflow installed source binary binary tensorflow version use command v1 gf3c7314d83 rc0 python version describe current behavior rnn layer rnncell reset state dropout mask compared layer implementation cell thus behavior tf kera layer gru tf kera layer rnn tf kera layer grucell especially problematic keras rnn api tutorial state approach mathematically equivalent describe expected behavior rnn layer check type rnncell subclass dropoutrnncellmixin reset dropout mask call calling cell reset recurrent dropout mask cell reset dropout mask partially copied future import absolute import division print function import numpy np import tensorflow tf tf enable eager execution tf enable eager execution print tf version data np random normal astype np float32 rnn tf kera layer gru unit dropout recurrent dropout print set rnn data training true numpy range rnn cell tf kera layer grucell unit dropout recurrent dropout rnn tf kera layer rnn rnn cell print set rnn data training true numpy range output warning tensorflow check dropout py name tf enable eager execution deprecated please use tf compat v1 enable eager execution instead rc0 different dropout mask used call dropout mask used call,2019-09-15 16:26:56,1568564816,resolved fixed,2eb6dc0f2e7f5455d368c59c35458709eef03a55,1569442398,tensorflow\python\keras\layers\convolutional_recurrent.py tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py tensorflow\python\keras\layers\recurrent_v2.py                                                      
176,32570,Assertion error when using mask with unrolled stacked LSTM,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary source tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory gpu gb ram collect information using environment capture script also obtain tensorflow version tf tf describe current behavior receive assertion error creating forward pas unrolled multi layer lstm using mask describe expected behavior assertion error least better explanation cause code reproduce issue import tensorflow tf input tf placeholder tf float32 mask tf placeholder tf bool single cell tf kera layer lstmcell range multi cell tf kera layer stackedrnncell cell single cell lstm tf kera layer rnn cell multi cell unroll true output state lstm input input mask mask assertion error occurs info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-09-17 01:59:08,1568685548,resolved fixed,4d011793076f6c62a560085b8fe03fbf732d67e6,1569446217,tensorflow\python\keras\backend.py tensorflow\python\keras\layers\lstm_test.py                                                          
177,32586,RNN does not forward the training flag to StackedRNNCells,system information written custom code yes os platform distribution ubuntu tensorflow installed binary tensorflow version python version describe current behavior using tf kera layer stackedrnncells tf kera layer rnn rnn layer forward training flag cell rnn code check cell explictly defines training flag argument tf kera layer stackedrnncells describe expected behavior training flag passed tf kera layer stackedrnncells stacked cell code reproduce issue code raise assertionerror import tensorflow tf class cellwrapper tf kera layer abstractrnncell def init self cell super cellwrapper self init self cell cell property def state size self return self cell state size property def output size self return self cell output size def get initial state self input none batch size none dtype none return self cell get initial state input input batch size batch size dtype dtype def call self input state training none kwargs assert training none cell tf kera layer lstmcell cell cellwrapper cell cell tf kera layer stackedrnncells cell rnn tf kera layer rnn cell input tf random uniform rnn input training true,2019-09-17 12:35:38,1568723738,resolved fixed,df2b252fa380994cd9236cc56b06557bcf12a9d3,1568758017,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py tensorflow\tools\api\golden\v1\tensorflow.keras.layers.-stacked-r-n-n-cells.pbtxt tensorflow\tools\api\golden\v2\tensorflow.keras.layers.-stacked-r-n-n-cells.pbtxt                                                      
178,32755,"Bincount Op test ""test_negative"" fails with TF 2.0",system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command rc1 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version gpu model memory rtx ti describe current behavior test negative test tensorflow python kernel test bincount op test py fails bincount call negative value throw invalidargumenterror behavior might result op called gpu cpu call expected throw error per comment setting cuda visible devices empty force op run cpu test pass invalid argument error successfully thrown passing use gpu false option session wrapper effect describe expected behavior test negative test pas call bincount negative input value expected throw invalidargumenterror code reproduce issue run python test tensorflow python kernel test bincount op test py,2019-09-24 02:09:01,1569290941,resolved fixed,9b5f9aabd84b0d1db782286143c560792d711449,1570163941,tensorflow\python\kernel_tests\BUILD tensorflow\python\kernel_tests\bincount_op_test.py                                                          
179,3277,Broadcast 0-rank tensors when computing gradients for tf.nn.relu,environment info operating system osx macos cpu version perhaps desired behavior would much appreciated descriptive warning least would saved much debugging found small reproducible case code originally found bug error raised variable trained leaving scratching head linear rectified variable trained issue also occurs tf nn softplus perhaps method well steps reproduce import tensorflow tf sess tf session x tf variable tf nn relu x loss optimizer tf train adamoptimizer learning rate train op optimizer minimize loss sess run tf initialize variable sess run train op invalidargumenterror traceback recent call last users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py call self fn args try return fn args except error operror e users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py run fn session feed dict fetch list target list option run metadata feed dict fetch list target list status run metadata users andrew anaconda envs tf dev lib python3 contextlib py exit self type value traceback try next self gen except stopiteration users andrew anaconda envs tf dev lib python3 site package tensorflow python framework error py raise exception ok status compat text pywrap tensorflow tf message status pywrap tensorflow tf getcode status finally invalidargumenterror handle tensor dims node gradient relu grad relugrad relugrad dt float device job localhost replica task cpu gradient pow grad tuple control dependency relu handling exception another exception occurred invalidargumenterror traceback recent call last sess run train op users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py run self fetch feed dict option run metadata try result self run none fetch feed dict option ptr run metadata ptr run metadata proto data tf session tf getbuffer run metadata ptr users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py run self handle fetch feed dict option run metadata mover self update mover feed dict string feed map result self run handle target list unique fetch feed dict string option run metadata user may fetched tensor multiple time users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py run self handle target list fetch list feed dict option run metadata handle none return self call run fn self session feed dict fetch list target list option run metadata else return self call prun fn self session handle feed dict users andrew anaconda envs tf dev lib python3 site package tensorflow python client session py call self fn args except keyerror pas raise type e node def op message def extend graph self invalidargumenterror handle tensor dims node gradient relu grad relugrad relugrad dt float device job localhost replica task cpu gradient pow grad tuple control dependency relu caused op gradient relu grad relugrad defined file users andrew anaconda envs tf dev lib python3 runpy py line run module main main mod spec file users andrew anaconda envs tf dev lib python3 runpy py line run code exec code run globals file users andrew anaconda envs tf dev lib python3 site package ipykernel main py line app launch new instance file users andrew anaconda envs tf dev lib python3 site package traitlets config application py line launch instance app start file users andrew anaconda envs tf dev lib python3 site package ipykernel kernelapp py line start ioloop ioloop instance start file users andrew anaconda envs tf dev lib python3 site package zmq eventloop ioloop py line start super zmqioloop self start file users andrew anaconda envs tf dev lib python3 site package tornado ioloop py line start handler func fd obj event file users andrew anaconda envs tf dev lib python3 site package tornado stack context py line null wrapper return fn args kwargs file users andrew anaconda envs tf dev lib python3 site package zmq eventloop zmqstream py line handle event self handle recv file users andrew anaconda envs tf dev lib python3 site package zmq eventloop zmqstream py line handle recv self run callback callback msg file users andrew anaconda envs tf dev lib python3 site package zmq eventloop zmqstream py line run callback callback args kwargs file users andrew anaconda envs tf dev lib python3 site package tornado stack context py line null wrapper return fn args kwargs file users andrew anaconda envs tf dev lib python3 site package ipykernel kernelbase py line dispatcher return self dispatch shell stream msg file users andrew anaconda envs tf dev lib python3 site package ipykernel kernelbase py line dispatch shell handler stream idents msg file users andrew anaconda envs tf dev lib python3 site package ipykernel kernelbase py line execute request user expression allow stdin file users andrew anaconda envs tf dev lib python3 site package ipykernel ipkernel py line execute shell run cell code store history store history silent silent file users andrew anaconda envs tf dev lib python3 site package ipython core interactiveshell py line run cell interactivity interactivity compiler compiler result result file users andrew anaconda envs tf dev lib python3 site package ipython core interactiveshell py line run ast node self run code code result file users andrew anaconda envs tf dev lib python3 site package ipython core interactiveshell py line run code exec code obj self user global n self user n file line train op optimizer minimize loss file users andrew anaconda envs tf dev lib python3 site package tensorflow python training optimizer py line minimize grad loss grad loss file users andrew anaconda envs tf dev lib python3 site package tensorflow python training optimizer py line compute gradient colocate gradient ops colocate gradient ops file users andrew anaconda envs tf dev lib python3 site package tensorflow python ops gradient py line gradient grad aslist grad fn op grad file users andrew anaconda envs tf dev lib python3 site package tensorflow python ops nn grad py line relugrad return gen nn ops relu grad grad op output file users andrew anaconda envs tf dev lib python3 site package tensorflow python ops gen nn ops py line relu grad feature feature name name file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework op def library py line apply op op def op def file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework ops py line create op original op self default original op op def op def file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework ops py line init self traceback extract stack originally created op relu defined file users andrew anaconda envs tf dev lib python3 runpy py line run module main main mod spec elided identical line previous traceback file users andrew anaconda envs tf dev lib python3 site package ipython core interactiveshell py line run code exec code obj self user global n self user n file line tf nn relu x file users andrew anaconda envs tf dev lib python3 site package tensorflow python ops gen nn ops py line relu result op def lib apply op relu feature feature name name file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework op def library py line apply op op def op def file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework ops py line create op original op self default original op op def op def file users andrew anaconda envs tf dev lib python3 site package tensorflow python framework ops py line init self traceback extract stack tried problem resolved expanding dimension x import tensorflow tf sess tf session x tf variable tf nn relu tf expand dims x loss optimizer tf train adamoptimizer learning rate train op optimizer minimize loss sess run tf initialize variable sess run train op run fine wonder would possible automatically,2016-07-11 22:00:32,1468274432,resolved fixed,5d5db35ed2e9e90b95ab27f8b37898fd4543457f,1468365479,tensorflow\core\framework\numeric_op.h tensorflow\python\kernel_tests\relu_op_test.py                                                          
180,32923,No documentation for tf.strings.reduce_join,thank submitting tensorflow documentation issue per github policy address code doc bug performance issue feature request build installation issue github tensorflow doc open source get involved read documentation contributor guide url issue description issue need changing add documentation method clear description correct link link source code correct parameters defined parameter defined formatted correctly returns defined return value defined raises listed defined error defined example usage example usage example request visuals applicable currently visuals clarify content submit pull request planning also submit pull request fix issue see doc contributor guide doc style guide,2019-09-30 18:13:33,1569867213,resolved fixed,de38438ba192145ec7d5a04257e0935b96b2053f,1570600292,tensorflow\python\ops\string_ops.py                                                            
181,33094,Tensorflow 2.0.0 / tf.keras.layers.TimeDistributed layer can't be save to saved Model,system information written custom code opposed using stock example script provided tensorflow os platform distribution colaboratory gpu runtime tensorflow version python version describe current behavior model defined tf kera layer timedistributed layer save model save function show error valueerror traceback recent call last usr lib python3 inspect py getfullargspec func skip bound arg false sigcls signature except exception ex frame valueerror signature found builtin exception direct cause following exception typeerror traceback recent call last usr lib python3 inspect py getfullargspec func else fully backwards compatible catch possible exception reraise typeerror raise typeerror unsupported callable ex args typeerror unsupported callable describe expected behavior tensorflow supposed model save model default saved savedmodel format code reproduce issue def get data datasets d info tfds load name mnist info true supervised true mnist train mnist test datasets train datasets test buffer size batch size per replica batch size batch size per replica mirrored strategy num replica sync def scale image label image tf cast image tf float32 image return image label train dataset mnist train map scale cache shuffle buffer size batch batch size eval dataset mnist test map scale batch batch size return train dataset eval dataset def get model mirrored strategy scope model tf kera sequential tf kera layer conv2d activation relu input shape tf kera layer maxpooling2d tf kera layer flatten tf kera layer timedistributed tf kera layer dense activation softmax tf kera layer timedistributed tf kera layer dense activation softmax tf kera layer dense activation softmax model compile loss sparse categorical crossentropy optimizer tf kera optimizers adam metric accuracy return model model get model model save test save info log reproduce colaboratory also normal ubuntu machien installed tensorflow gpu,2019-10-06 23:45:43,1570405543,resolved fixed,66b9b602af695fddb76c113d823d2fa4d0646c04,1572028077,tensorflow\python\keras\saving\saved_model\saved_model_test.py tensorflow\python\keras\saving\saved_model\utils.py                                                          
182,33148,Masking LSTM: OP_REQUIRES failed at cudnn_rnn_ops.cc:1498 : Unknown: CUDNN_STATUS_BAD_PARAM,system information written custom code yes os platform distribution e g linux ubuntu linux ubuntu lts tensorflow installed source binary binary pip tensorflow version use command v2 rc2 g64c3d38 python version python cuda cudnn version cuda cudnn gpu model memory quadro rtx major minor memoryclockrate ghz describe problem seems issue cudnn lstm implementation using tf kera layer masking layer batch size num tsteps num feature num unit model tf kera sequential tf kera layer inputlayer input shape num tsteps num feature batch size batch size tf kera layer masking mask value input shape num tsteps num feature tf kera layer lstm num unit batch input shape batch size num tsteps num feature return sequence true stateful false tf kera layer timedistributed tf kera layer dense tf kera layer activation sigmoid similar receive error training strictly right padded data trimming right padding manually however contrast issue confirmed input containing zero via following snippet e enumerate d train re f l x numpy x e j range f shape f j re append else re append fin re e re e fin fin append e print format fin result remove masking layer error occur confirmed running complete epoch batch however training probably pretty pointless including padded data pitfall missing could cause issue source code log python output epoch warning tensorflow early stopping conditioned metric val loss available available metric cancellederrortraceback recent call last fit train true w tf vol local model lstm py fit self train verbose self model fit d train epoch num epoch verbose verbose shuffle false validation data d val validation step none callback cbs self model save sess hdf5 path self model save weight self sess h5 path posix w miniconda3 lib python3 site package tensorflow core python kera engine training py fit self x batch size epoch verbose callback validation split validation data shuffle class weight sample weight initial epoch step per epoch validation step validation freq max queue size worker use multiprocessing kwargs max queue size max queue size worker worker use multiprocessing use multiprocessing def evaluate self w miniconda3 lib python3 site package tensorflow core python kera engine training v2 py fit self model x batch size epoch verbose callback validation split validation data shuffle class weight sample weight initial epoch step per epoch validation step validation freq kwargs mode modekeys train training context training context total epoch epoch cbks make log model epoch log training result modekeys train w miniconda3 lib python3 site package tensorflow core python kera engine training v2 py run one epoch model iterator execution function dataset size batch size strategy step per epoch num sample mode training context total epoch step step mode mode size current batch size batch log try batch out execution function iterator except stopiteration error outofrangeerror todo kaftan file bug tf function error outofrangeerror w miniconda3 lib python3 site package tensorflow core python kera engine training v2 utils py execution function input fn numpy translates tensors value eager mode return nest map structure non none constant value distributed function input fn return execution function w miniconda3 lib python3 site package tensorflow core python eager def function py call self args kwds tracing count self get tracing count result self call args kwds tracing count self get tracing count self call counter called without tracing w miniconda3 lib python3 site package tensorflow core python eager def function py call self args kwds lifting succeeded variable initialized run stateless function return self stateless fn args kwds else canon args canon kwds w miniconda3 lib python3 site package tensorflow core python eager function py call self args kwargs calls graph function specialized input graph function args kwargs self maybe define function args kwargs return graph function filtered call args kwargs pylint disable protected access property w miniconda3 lib python3 site package tensorflow core python eager function py filtered call self args kwargs isinstance ops tensor resource variable ops baseresourcevariable self captured input def call flat self args captured input cancellation manager none w miniconda3 lib python3 site package tensorflow core python eager function py call flat self args captured input cancellation manager executing eagerly flat output forward function call ctx args cancellation manager cancellation manager else gradient name self delayed rewrite function register w miniconda3 lib python3 site package tensorflow core python eager function py call self ctx args cancellation manager input args attrs executor type executor type config proto config ctx ctx else output execute execute cancellation w miniconda3 lib python3 site package tensorflow core python eager execute py quick execute op name num output input attrs ctx name else message e message six raise core status exception e code message none except typeerror e kera symbolic tensor w miniconda3 lib python3 site package six py raise value value cancellederror derived recvasync cancelled node metric accuracy broadcast weight assert broadcastable assertguard else assert data loss activation loss weighted loss broadcast weight assert broadcastable valid shape else valid nonscalar shape invalid dims concat op inference distributed function function call stack distributed function command line log w tensorflow core grappler optimizers implementation selector cc skipping optimization due error loading function library invalid argument functions inference backward cudnn lstm fallback inference backward cudnn lstm fallback specialized statefulpartitionedcall inference distributed function implement lstm dce676f4 acdd e8dd57573aba signature match tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcublas tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcudnn w tensorflow core framework op kernel cc op requires failed cudnn rnn ops cc unknown cudnn status bad param tensorflow stream executor cuda cuda dnn cc cudnnsetrnndatadescriptor data desc get data type layout max seq length batch size data size seq length array void padding fill w tensorflow core common runtime base collective executor cc basecollectiveexecutor startabort unknown cudnn status bad param tensorflow stream executor cuda cuda dnn cc cudnnsetrnndatadescriptor data desc get data type layout max seq length batch size data size seq length array void padding fill node cond cudnnrnnv3 w tensorflow core common runtime base collective executor cc basecollectiveexecutor startabort cancelled derived recvasync cancelled node metric accuracy broadcast weight assert broadcastable assertguard else assert data loss activation loss weighted loss broadcast weight assert broadcastable valid shape else valid nonscalar shape invalid dims concat w tensorflow core common runtime base collective executor cc basecollectiveexecutor startabort cancelled derived recvasync cancelled node metric accuracy broadcast weight assert broadcastable assertguard else assert data,2019-10-08 15:25:27,1570548327,resolved fixed,4d582a660b4e84fb283eba598127ae40fdd8d1ed,1594700831,tensorflow\python\keras\layers\gru_v2_test.py tensorflow\python\keras\layers\lstm_v2_test.py tensorflow\python\keras\layers\recurrent_v2.py                                                        
183,33340,Significant prediction slowdown after model.compile(),system information os platform distribution e g linux ubuntu windows tensorflow installed source binary pip install tensorflow tensorflow version python version cuda cudnn version cuda cudnn gpu model memory gtx describe current behavior prediction speed slowed lot model compile call describe expected behavior speed affected predict function used user assuming work fast use time production cause surprise user,2019-10-14 15:13:52,1571066032,resolved fixed,42f469be0f3e8c36624f0b01c571e7ed15f75faf,1579060907,tensorflow\python\keras\engine\training.py                                                            
184,33365,No float64 support with batch normalization in Tensorflow 2.0?,stock ubuntu cuda tensorflow installed via pip3 python gtx1060 float64 valued dataset simple conv2d network includes tf kera layer batchnormalization error thrown think first set issue warning tensorflow layer conv2d casting input tensor dtype float64 layer dtype float32 new behavior tensorflow layer dtype float32 dtype default floatx intended run layer float32 safely ignore warning doubt warning likely issue porting tensorflow x model tensorflow change layer dtype float64 default call tf kera backend set floatx float64 change layer pas dtype float64 layer constructor setting tf kera backend set floatx float64 next set error traceback recent call last file home aj ga py line encoder make encoder model z dim file home aj ga py line make encoder model x tf kera layer batchnormalization x file usr local lib python3 dist package tensorflow core python kera engine base layer py line call output call fn cast input args kwargs file usr local lib python3 dist package tensorflow core python kera layer normalization py line call output self fused batch norm input training training file usr local lib python3 dist package tensorflow core python kera layer normalization py line fused batch norm training fused batch norm training fused batch norm inference file usr local lib python3 dist package tensorflow core python kera utils tf utils py line smart cond pred true fn true fn false fn false fn name name file usr local lib python3 dist package tensorflow core python framework smart cond py line smart cond name name file usr local lib python3 dist package tensorflow core python util deprecation py line new func return func args kwargs file usr local lib python3 dist package tensorflow core python ops control flow ops py line cond return cond v2 cond v2 pred true fn false fn name file usr local lib python3 dist package tensorflow core python ops cond v2 py line cond v2 op return value pred file usr local lib python3 dist package tensorflow core python framework func graph py line func graph py func func output python func func args func kwargs file usr local lib python3 dist package tensorflow core python kera layer normalization py line fused batch norm training data format self data format file usr local lib python3 dist package tensorflow core python ops nn impl py line fused batch norm name name file usr local lib python3 dist package tensorflow core python ops gen nn ops py line fused batch norm v3 name name file usr local lib python3 dist package tensorflow core python framework op def library py line apply op helper param name input name file usr local lib python3 dist package tensorflow core python framework op def library py line satisfiestypeconstraint join dtypes dtype x name x allowed list typeerror value passed parameter x datatype float64 list allowed value float16 bfloat16 float32 perhaps another hopefully drop method batch normalization support float64 want go hacking allowed list,2019-10-15 03:37:06,1571110626,resolved fixed,2ebc291f6a94163c49fc835d3afc93892e645e45,1583873211,tensorflow\python\keras\layers\normalization.py tensorflow\python\keras\layers\normalization_test.py                                                          
185,33376,importing tensorflow inside a function/object causes a memory leak,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu osx mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary pip install tensorflow tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior importing tensorflow function object import statement somehow keep reference function increasing reference count full import stacktrace never freed making impossible object anything referenced object function freed memory describe expected behavior possible free function calling import tensorflow issue import like import logger code reproduce issue import gc class tfimporter def init self name self name name print f tfimporter init self name def get tf self print f import tensorflow self name import tensorflow print tensorflow version version def get module self print f import logging self name import logging logging info message def del self print f tfimporter delete self name def main importer1 tfimporter importer1 get module del importer1 print importer1 deleted importer2 tfimporter importer2 get tf del importer2 print importer2 deleted importer3 tfimporter importer3 get tf del importer3 print importer3 deleted print f garbage collection gc collect print f waiting input input main output users jan miniconda envs foo bin python users jan code tensorflow error py tfimporter init import logging tfimporter delete importer1 deleted tfimporter init import tensorflow importer2 deleted tfimporter init import tensorflow tfimporter delete importer3 deleted garbage collection waiting input foo tfimporter delete process finished exit code importer2 freed python application finish neither gc collect deleting object cause released python issue toy example importer2 could reference large number object take considerable space memory reality also happens first import importer3 freed without issue tf env txt,2019-10-15 13:32:32,1571146352,resolved fixed,413d0fa9d75e99e02b74bb079465bea728eb3a44,1576618841,tensorflow\python\framework\test_util.py                                                            
186,33425,"Tensorflow eager execution not working with tf.math.unsorted_segment_max, Gradient output is null",system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu windows professional edition mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary installed using conda tensorflow version use command unknown python version cuda cudnn version gpu model memory t1000 vram describe current behavior using tf math unsorted segment max tensorflow eager execution gradient tape source code see produce following error traceback recent call last file c projects iotmap py segmented max error py line grad tape gradient loss value model trainable weight file c programdata anaconda3 lib site package tensorflow python eager backprop py line gradient unconnected gradient unconnected gradient file c programdata anaconda3 lib site package tensorflow python eager imperative grad py line imperative grad compat str unconnected gradient value file c programdata anaconda3 lib site package tensorflow python eager backprop py line gradient function return grad fn mock op grad file c programdata anaconda3 lib site package tensorflow python ops math grad py line unsortedsegmentmaxgrad return unsortedsegmentminormaxgrad op grad file c programdata anaconda3 lib site package tensorflow python ops math grad py line unsortedsegmentminormaxgrad gatherdropnegatives op output op input typeerror nonetype object subscriptable operations tf math segment max tf math segment mean tf math unsorted segment mean working ok though need unsorted version complex code base using several segmented aggregation concatenating need fixed size describe expected behavior work without throwing error code info log exception thrown mentioned,2019-10-16 12:25:29,1571228729,resolved fixed,cb9319253d81374e6c9b0dc27c28fe8f5ba2ebb1,1572316448,tensorflow\python\eager\pywrap_tfe_src.cc                                                            
187,33526,Error while trying to use tf.broadcast_weights,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux google colab mobile device e g iphone pixel samsung galaxy issue happens mobile device google colab tensorflow installed source binary binary tensorflow version use command python version x bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior unable import tf broadcast weight tf describe expected behavior able import tf broadcast weight tf code reproduce issue provide reproducible test case bare minimum necessary generate problem method plain python tf import tensorflow tf version tf broadcast weight throw attributeerror module tensorflow attribute broadcast weight method codelab found error recent tf keras tutorial search broadcast weight codelab run cell modify code update state update state sample weight run cell throw attributeerror module tensorflow attribute broadcast weight info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-10-19 06:22:11,1571466131,resolved fixed,5dd0b6a589f4f2c66b66a0d022a3d753588bca80,1588616740,tensorflow\python\keras\metrics.py                                                            
188,33572,[tflite] Support INT8 quantization for PACK with TFLITE_BUILTINS_INT8 OpsSet,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary binary tensorflow version use command python version similar unpack node issue new tfliteconverter post training quantisation flow described support quantization pack stack operation integer operation requested output model conversion attempted following error reported runtimeerror quantization yet supported op pack code reproduce issue example script import tensorflow tf import numpy np def representative dataset gen input np one dtype np float32 input np one dtype np float32 range yield input input tf graph input foo tf compat v1 placeholder float32 bar tf compat v1 placeholder float32 stacked tf stack foo bar axis tf compat v1 session sess tf io write graph tf compat v1 get default graph pack pb text false input name placeholder placeholder output name stack tflite model name int8 pack tflite converter tf lite tfliteconverter frozen graph pack pb input name output name converter optimization tf lite optimize default converter target ops tf lite opsset tflite builtins int8 converter representative dataset representative dataset gen tflite model converter convert open tflite model name wb write tflite model load tflite model allocate tensor interpreter tf lite interpreter tflite model name interpreter allocate tensor get input output tensor input detail interpreter get input detail output detail interpreter get output detail test model random input data input shape input detail shape input data np array np random random sample input shape dtype np float32 interpreter set tensor input detail index input data interpreter invoke produce error follows tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device tensorflow core grappler device cc number eligible gpus core count compute capability note tensorflow compiled cuda support tensorflow core grappler cluster single machine cc starting new session info initialized tensorflow lite runtime traceback recent call last file pack example py line tflite model converter convert file home jaszha02 work venvs audio lib python3 site package tensorflow lite python lite py line convert inference output type file home jaszha02 work venvs audio lib python3 site package tensorflow lite python lite py line calibrate quantize model inference output type allow float file home jaszha02 work venvs audio lib python3 site package tensorflow lite python optimize calibrator py line calibrate quantize np dtype output type numpy dtype num allow float file home jaszha02 work venvs audio lib python3 site package tensorflow lite python optimize tensorflow lite wrap calibration wrapper py line quantizemodel return tensorflow lite wrap calibration wrapper calibrationwrapper quantizemodel self input py type output py type allow float runtimeerror quantization yet supported op pack ktfliteuint8 ktfliteint8 version pack operator already implemented tflite see pack cc straightforward support pack well tflite converter,2019-10-21 13:18:38,1571663918,resolved fixed,d8668d9e03b65c4a6d9ecb08e74b0b67798fbbab,1574452162,tensorflow\lite\tools\optimize\operator_property.cc                                                            
189,33724,Infinite loop with generators wrapping a dataset in tf.function,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v2 rc2 g64c3d38 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory titan xp collect information using environment capture script also obtain tensorflow version tf tf describe current behavior use case use tqdm track progress training loop tf data dataset tf function def train one epoch model dataset x tqdm dataset train step model x however function train one epoch wrapped tf function autograph stuck infinite loop describe expected behavior expected behavior would using tf function result behavior eager mode current issue autograph recognize tqdm dataset tf data dataset normal however iterating infinitely dataset autograph weird happen maybe give exception maybe easiest fix would prevent dataset iter called inside tf function loop x dataset would fine x tqdm dataset code reproduce issue import tensorflow tf class iterable def init self iterable self iterable iterable def iter self obj self iterable yield obj tf function def f dataset x iterable dataset print x dataset tf data dataset range f dataset minimal iterable class replaced tqdm tqdm import tqdm yield result info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached without tf function wrapped dataset iterable dataset iterated eager mode tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 tf function autograph mode recognize wrapped iterable dataset tf data dataset try iterate python trace graph however look like iterable dataset iter infinitely yield next element named iteratorgetnext result infinite iteration dataset tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64 tensor iteratorgetnext shape dtype int64,2019-10-25 15:33:43,1572017623,resolved fixed,eba45c548371e29cd141c32d367b582b9ca656be,1579871089,tensorflow\python\autograph\g3doc\reference\common_errors.md tensorflow\python\autograph\g3doc\reference\control_flow.md tensorflow\python\autograph\g3doc\reference\functions.md tensorflow\python\autograph\operators\control_flow.py tensorflow\python\autograph\operators\control_flow_test.py                                                    
190,33776,LSTMCell name is ignored in trainable_variables when wrapped in keras.layers.RNN,created model several lstmcell cell wrapped kera layer rnn print trainable variable cell name ignored result duplicate variable name several recurrent kernel etc confuses tensorboard example collab notebook reproduce environment tensorflow release,2019-10-28 09:26:19,1572254779,resolved fixed,91bdf64a8b3778d70213446418b2a3d2d7a04a68,1580774064,tensorflow\python\keras\integration_test.py tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_v2.py tensorflow\python\keras\layers\rnn_cell_wrapper_v2_test.py tensorflow\python\keras\saving\save_test.py                                                    
191,33888,Bug in saving model in hdf5 format,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos mojave version mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior try save model kera format get following error valueerror unable create group name already exists happens model three layer name tf op layer pad padding tf op layer pad padding tf op layer pad name cause error kera described kera team kera describe expected behavior model saving fail code reproduce issue import tensorflow tf tensorflow import kera x kera input shape none dtype int32 name input tf shape x pad tf pad x pad model kera model input x output model save model h5 fix checked kera day ago seems kera team kera seems tf copy hdf5 saving seems fix also made,2019-10-31 16:23:59,1572539039,resolved fixed,0e884391beabe2fadb6398b1fc5f48a9662c333c,1580255585,tensorflow\python\keras\saving\hdf5_format.py tensorflow\python\keras\saving\hdf5_format_test.py                                                          
192,33974,assert_shapes broken code in documentation,url issue description issue need changing source code example incorrect tf assert shape x n q n param q scalar tf assert shape x n q n param q scalar note allowed python form tuples,2019-11-04 13:27:34,1572874054,resolved fixed,beef1a7bc10883e142813dfbd68da113a94cd6b7,1573494339,tensorflow\python\ops\check_ops.py                                                            
193,34020,Checkpoint.restore doesn't restore Dataset iterator state when Dataset contains shuffle(),system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command v2 rc2 g64c3d38 python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version installed gpu model memory gpu describe current behavior code end result following output tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device host default version tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 saved tmp x ckpt tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 restored tmp x ckpt tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 describe expected behavior restoring checkpoint expect iterator return element saving checkpoint e tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service executing computation platform host devices tensorflow compiler xla service service cc streamexecutor device host default version tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 saved tmp x ckpt tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 restored tmp x ckpt tf tensor shape dtype int64 tf tensor shape dtype int64 tf tensor shape dtype int64 code reproduce issue import tensorflow tf d tf data dataset range shuffle seed reshuffle iteration false iter d ckpt tf train checkpoint foo mgr tf train checkpointmanager ckpt tmp x max keep range print next mgr save print saved format mgr latest checkpoint range print next ckpt restore mgr latest checkpoint print restored format mgr latest checkpoint range print next fwiw get expected result remove shuffle info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-11-05 21:51:18,1572990678,resolved fixed,53d244502fe0de438c939438d00e86f0409b2cb5,1573176458,tensorflow\core\kernels\data\shuffle_dataset_op.cc                                                            
194,34055,model.reset_states() does not work for bidirectional-RNNs in tf.keras.,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos tensorflow installed source binary binary tensorflow version use command python version gpu model memory none macbook pro core i5 iris graphics gb describe current behavior state handling rnns bidirectional wrapper changed tf kera kera tf x old kera tf x using stateful true bidi rnn effect e bidi rnn model behaved stateful false therefore model reset state anything new tf kera stateful true bidi rnn effect fwd rnn stateful bwd rnn stateful good change imo even though stateful bidi rnns unusual best way implement however tf kera model reset state anything bidi rnn model simplernn gru lstm describe expected behavior minimal example script provided output fwd non stateful stateful delta bwd non stateful stateful delta fwd non stateful stateful delta bwd non stateful stateful delta reseting states stateful model fwd non stateful stateful delta bwd non stateful stateful delta result state reset first set result e last third set result produce result stateful non stateful model first set result code reproduce issue import numpy np tf2 true tf2 currently bug tf kera model reset state work tensorflow kera layer import input dense simplernn gru lstm bidirectional tensorflow kera model import model else old kera bidi rnns stateful true behave smae stateful false kera layer import input dense simplernn gru lstm bidirectional kera model import model sequence length feature dim feature input batch shape sequence length feature dim rnn bidirectional simplernn activation none use bias false return sequence true return state false stateful false feature stateless model model input feature output rnn stateful rnn bidirectional simplernn activation none use bias false return sequence true return state false stateful true feature stateful model model input feature output stateful rnn toy weight np asarray dtype np float32 np asarray dtype np float32 np asarray dtype np float32 np asarray dtype np float32 stateless model set weight toy weight stateful model set weight toy weight x np zero sequence length x x x reshape sequence length feature dim def print bidi non stateful stateful fb fwd bwd range print fb print f non stateful non stateful print f stateful stateful print f delta stateful non stateful non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful print n reseting states stateful model n stateful model reset state non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful,2019-11-07 00:34:22,1573086862,resolved fixed,7cea9a4edfd181771da97db944e89551b62195ce,1574127492,tensorflow\python\keras\layers\wrappers.py tensorflow\python\keras\layers\wrappers_test.py                                                          
195,34124,[Docs] Doc example of DeviceSpec doesn't work with tf 2.0,doc link import tensorflow tf device spec tf devicespec job p device type cpu device index tf device device spec pas got error keyerror traceback recent call last usr local lib python3 dist package tensorflow core python eager context py enter self try new device name new device spec device parsing cache cache key except typeerror keyerror handling exception another exception occurred valueerror traceback recent call last frame usr local lib python3 dist package tensorflow core python eager context py enter self isinstance new device name six string type raise valueerror expecting string device name got type new device name new device name device spec pydev devicespec string new device name old device name valueerror expecting string device name got system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior describe expected behavior code reproduce issue provide reproducible test case bare minimum necessary generate problem info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-11-09 16:07:33,1573315653,resolved fixed,5006295cf7a20de9ef9087127569e9d58b28022d,1573495094,tensorflow\python\framework\device_spec.py                                                            
196,34165,tf.keras.backend.sqrt(tf.constant(-1.0)) is 0 which is misleading and tf.sqrt(tf.constant(-1.0)) is 'nan' which is the way it should be.,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary source tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory run cpu describe current behavior tf kera backend sqrt tf constant return clip value done source code highly misleading seen source function document whereas tf sqrt tf constant return nan expected behavior sqrt function cause bug difficult track describe expected behavior make sqrt function return expected behavior remove clip value code reproduce issue import tensorflow tf tf enable eager execution tf kera backend sqrt tf constant numpy tf sqrt tf constant numpy info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-11-11 19:06:57,1573499217,resolved fixed,8134c918424e5f99683617ca5afa8303e5c90642,1602093561,tensorflow\python\keras\backend.py                                                            
197,34194,tf.size() has no documentation,example returns number element tensor equal length flattened tensor,2019-11-12 09:56:51,1573552611,resolved fixed,b70b3e7032cfbbd6d237dc01cdbd1399378b8351,1574102335,tensorflow\python\ops\array_ops.py                                                            
198,34297,tf.function hangs on ragged tensor input,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu tensorflow installed source binary colab tensorflow version use command python version gpu model memory none describe current behavior using tf function number loop raggedtensor function call hang stopped waiting half hour running function directly tf function decorator function executes immediately converting ragged tensor dense tensor function executes immediately pinpoint exact combination operation cause autograph behavior tried reduce code simplest combination still cause behavior struggled hour code trying get tf function work figured due ragged tensor loop tf function hanging kernel observed similar behavior machine colab machine well describe expected behavior execute comparable time dense tensor code reproduce issue tensorflow version x import tensorflow tf import numpy np inp tf ragged constant np arange dtype np float32 reshape tf function using tf function run well def ragged example r tensor tf constant tf range inner r tensor x inner b tf reduce sum x b return inp inp tensor uncommented run well ragged example inp hang observation also noted large memory footprint result growing,2019-11-15 01:59:48,1573783188,resolved fixed,75af7b4750cd757cd82b32896eb98414e1b38898,1574379480,tensorflow\python\autograph\operators\control_flow.py tensorflow\python\autograph\operators\control_flow_test.py                                                          
199,34701,"std::uniform_int_distribution&lt;int8_t&gt; is undefined in the C++17 standard, but TFLite violates this limitation.",c reference mentioned std uniform int distribution undefined c therefore microsoft visual c give following build error code includes benchmark tflite model cc l496 fact recent tflite model benchmark build window ci environment show bazel build c opt verbose failure tensorflow lite tool benchmark benchmark model c program files x86 microsoft visual studio enterprise vc tools msvc include random error c2338 invalid template argument uniform int distribution n4659 rand req genl requires one short int long long long unsigned short unsigned int unsigned long unsigned long long tensorflow lite tool benchmark benchmark tflite model cc note see reference class template instantiation std uniform int distribution compiled c program files x86 microsoft visual studio enterprise vc tools msvc include random error c2338 note char signed char unsigned char int8 uint8 allowed would like modify benchmark tflite model cc,2019-11-29 10:57:55,1575025075,resolved fixed,c16614ef36b990ce9633e25aa00467ea4ce85844,1575313006,tensorflow\lite\tools\benchmark\benchmark_tflite_model.cc tensorflow\lite\tools\benchmark\benchmark_tflite_model.h                                                          
200,34789,GRUCell is not compatible with its own initial state,system information written custom code yes os platform distribution ubuntu tensorflow installed binary tensorflow version python version describe current behavior initial state returned tf kera layer grucell get initial state passed first cell call without error raise invalidargumenterror error describe expected behavior rnn cell accept initial state code reproduce issue import tensorflow tf batch size cell tf kera layer grucell initial state cell get initial state batch size batch size dtype tf float32 output state cell tf random uniform batch size initial state info log traceback recent call last file test gru incompat py line output state cell tf random uniform batch size initial state file lib python3 site package tensorflow core python kera engine base layer py line call output self call cast input args kwargs file lib python3 site package tensorflow core python kera layer recurrent py line call matrix inner k dot h tm1 self recurrent kernel file lib python3 site package tensorflow core python kera backend py line dot math ops matmul x file lib python3 site package tensorflow core python util dispatch py line wrapper return target args kwargs file lib python3 site package tensorflow core python ops math ops py line matmul b transpose transpose transpose b transpose b name name file lib python3 site package tensorflow core python ops gen math ops py line mat mul ops raise ok status e name file lib python3 site package tensorflow core python framework ops py line raise ok status six raise core status exception e code message none file line raise tensorflow python framework error impl invalidargumenterror matrix instead shape op matmul name gru cell matmul,2019-12-03 10:07:02,1575367622,resolved fixed,48b920246f9f06a645a9b864c39171c5b0c2c4ef,1578446986,tensorflow\python\keras\layers\gru_test.py tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\simplernn_test.py                                                        
201,34873,Using GPU delegate causes app to crash,system information os platform distribution e g linux ubuntu windows tensorflow installed source binary binary tensorflow version github sha source org tensorflow tensorflow lite gpu nightly command used run converter code using python api model tf kera model load model conv h5 converter tf lite tfliteconverter kera model model converter optimization tf lite optimize default converter target spec supported type tf float16 tflite model converter convert open custom cnn f16 tflite wb write tflite model output converter invocation successfully convert model tflite f16 also please include link saved model graphdef link model simple cnn take grayscale image output probability class failure detail want run float16 version model using tflite gpu samsung s10 however using gpu delegate model cause app crash tested device model crash phone running gpu info log debug debug build fingerprint xxxxxxxxxxxxxxxx release key debug revision debug abi arm64 debug pid tid name inference com test app debug signal sigsegv code segv maperr fault addr debug cause null pointer dereference debug x0 x1 x2 x3 debug x4 x5 x6 x7 debug x8 x9 x10 x11 debug x12 x13 x14 x15 debug x16 x17 x18 x19 debug x20 x21 x22 x23 debug x24 x25 x26 x27 debug x28 x29 debug sp lr pc debug backtrace debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite gpu jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite gpu jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite gpu jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni debug pc data app com test app edfq7adoagblvng1917lag lib arm64 libtensorflowlite jni java org tensorflow lite nativeinterpreterwrapper applydelegate debug pc system lib64 libart art quick generic jni trampoline debug pc system lib64 libart art quick invoke static stub debug pc system lib64 libart art artmethod invoke art thread unsigned int unsigned int art jvalue char const debug pc system lib64 libart art interpreter artinterpretertocompiledcodebridge art thread art artmethod art shadowframe unsigned short art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokestaticrange debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik class dex extracted memory data app com test app edfq7adoagblvng1917lag base apk deleted org tensorflow lite nativeinterpreterwrapper applydelegates debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokedirect debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik class dex extracted memory data app com test app edfq7adoagblvng1917lag base apk deleted org tensorflow lite nativeinterpreterwrapper init debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokedirectrange debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik class dex extracted memory data app com test app edfq7adoagblvng1917lag base apk deleted org tensorflow lite nativeinterpreterwrapper debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokedirect debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik class dex extracted memory data app com test app edfq7adoagblvng1917lag base apk deleted org tensorflow lite interpreter debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokedirect debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik classes2 dex extracted memory data app com test app edfq7adoagblvng1917lag base apk classes2 dex deleted com test app tflite classifier runmodel debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokevirtual debug pc system lib64 libart executemterpimpl debug pc dev ashmem dalvik classes2 dex extracted memory data app com test app edfq7adoagblvng1917lag base apk classes2 dex deleted com test app home homefragment run run debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokeinterface debug pc system lib64 libart executemterpimpl debug pc system framework boot framework vdex android o handler handlecallback debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokestatic debug pc system lib64 libart executemterpimpl debug pc system framework boot framework vdex android o handler dispatchmessage debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokevirtual debug pc system lib64 libart executemterpimpl debug pc system framework boot framework vdex android o looper loop debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart art interpreter artinterpretertointerpreterbridge art thread art codeitemdataaccessor const art shadowframe art jvalue debug pc system lib64 libart bool art interpreter docall art artmethod art thread art shadowframe art instruction const unsigned short art jvalue debug pc system lib64 libart mterpinvokestatic debug pc system lib64 libart executemterpimpl debug pc system framework boot framework vdex android o handlerthread run debug pc system lib64 libart zn3art11interpreterl7executeepns llvm debug pc system lib64 libart artquicktointerpreterbridge debug pc system lib64 libart art quick interpreter bridge debug pc system lib64 libart art quick invoke stub debug pc system lib64 libart art artmethod invoke art thread unsigned int unsigned int art jvalue char const debug pc system lib64 libart art anonymous namespace invokewithargarray art scopedobjectaccessalreadyrunnable const art artmethod art anonymous namespace argarray art jvalue char const debug pc system lib64 libart art invokevirtualorinterfacewithjvalues art scopedobjectaccessalreadyrunnable const jobject jmethodid jvalue debug pc system lib64 libart art thread createcallback void debug pc system lib64 libc pthread start void debug pc system lib64 libc start thread include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2019-12-05 16:14:44,1575562484,resolved fixed,f48446d6d301d261f4fa7d73baa80e593e965abf,1576107633,tensorflow\lite\delegates\gpu\common\model_builder.cc                                                            
202,34975,[TF 2.0 API Docs] `tf.keras.callbacks.LearningRateScheduler` (Very small update),url issue please provide link documentation entry example doc link code link description issue need changing parameters next api scheduler parameter learningratescheduler take parameter epoch lr learning rate instead epoch evident epoch begin learningratescheduler method documentation method still outdated doc example code still show scheduler function take epoch instead epoch lr think doc updated reflect new api proposed change doc update description scheduler schedule function take epoch index input integer indexed current learning rate return new learning rate output float copied doc kera io update example usage include scheduler utilize current learning rate well hope helpful happy contribute needed submit pull request yes updated planning also submit pull request fix issue see doc contributor guide doc api guide doc style guide,2019-12-09 21:42:36,1575927756,resolved fixed,ec684ae119051481f4435ecfa7d0cc7c06eb0fa8,1585873479,tensorflow\python\keras\callbacks.py                                                            
203,35100,Error occurred when finalizing GeneratorDataset iterator,system information os platform distribution arch linux arch1 arch tensorflow installed binary tensorflow version keras version tf python version gpu model memory gtx ti describe current behavior executing tensorflow mnist handwriting example produce error error dissapears code use onedevicestrategy mirroredstrategy w tensorflow core kernel data generator dataset op cc error occurred finalizing generatordataset iterator cancelled operation cancelled code reproduce issue import tensorflow tf import tensorflow datasets tfds import time tensorflow kera optimizers import adam def build model filter unit kernel size learning rate model tf kera sequential tf kera layer conv2d filter filter kernel size kernel size kernel size activation relu input shape tf kera layer maxpooling2d tf kera layer flatten tf kera layer dense unit activation relu tf kera layer dense activation softmax model compile loss sparse categorical crossentropy optimizer adam learning rate metric accuracy return model datasets info tfds load name mnist info true supervised true mnist train mnist test datasets train datasets test num train example info split train num example num test example info split test num example strategy tf distribute onedevicestrategy device gpu buffer size batch size def scale image label image tf cast image tf float32 image return image label train dataset mnist train map scale shuffle buffer size repeat batch batch size prefetch buffer size tf data experimental autotune eval dataset mnist test map scale repeat batch batch size prefetch buffer size tf data experimental autotune strategy scope model build model epoch start time perf counter model fit train dataset validation data eval dataset step per epoch num train example epoch validation step num test example epoch epoch epoch elapsed time perf counter start print elapsed format elapsed,2019-12-13 22:06:00,1576274760,resolved fixed,b6edd34c5858ab0ab4380da774e7e2fd81a92da0,1576801282,tensorflow\core\kernels\data\captured_function.cc tensorflow\core\kernels\data\captured_function.h tensorflow\core\kernels\data\generator_dataset_op.cc tensorflow\core\kernels\data\iterator_ops.h                                                      
204,35306,A possible bug in ConvRNN2D __call__,referring convrnn2d call l308 kwargs initial state initial state l317 kwargs constant constant added else block l340 current situation contradicts use full input l337 sure simply replicate code parent rnn call went ahead tried loading saved model weight complete new python session result validation data match would appreciate quick fix local edit least thanks,2019-12-20 11:38:08,1576841888,resolved fixed,74c9e141067c804bb9a5f94df9342d270cc01f75,1582157324,tensorflow\python\keras\layers\convolutional_recurrent.py tensorflow\python\keras\layers\convolutional_recurrent_test.py                                                          
205,35335,Dataset scan loses variable modifications,system information written custom code opposed using stock example script provided tensorflow yes providing source os platform distribution e g linux ubuntu mac os likely irrelevant tensorflow installed source binary binary pip tensorflow version use command v1 g9798f84fa9 dev20191221 installed via pip install tf nightly python version cuda cudnn version using cpu describe current behavior writing unit test created function iterates tf data dataset accumulates value local variable worked fine using eager mode noticed returned result zero using tf function produced small simple code reproduces problem particular returning accumulator variable produce result accessing variable directly work fine also using tf print accumulator iterating dataset show correct value printing iteration still within method show suggesting perhaps kind scoping problem please see attached source understand better mean describe expected behavior result using eager mode tf function also using tf function result returning variable accessing directly tf function variable py txt,2019-12-22 01:32:27,1576978347,resolved fixed,c4ec9389364cb8d1bff451ab8baf55d25cabdd1f,1579804551,tensorflow\python\data\kernel_tests\iterator_test.py tensorflow\python\data\kernel_tests\reduce_test.py tensorflow\python\data\ops\dataset_ops.py                                                        
206,35379,Cannot export keras model to SavedModel if mixed-precision policy is enabled,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux debian tensorflow installed source binary binary tensorflow version use command starting nightly version tested python version describe current behavior kera mixed precision policy mixed float16 use save kera model savedmodel format method kera model model save without specific signature seems like mismatch input signature inferred model auto casted input valueerror python input incompatible input signature input input signature tensorspec shape none none none none dtype tf float32 name none although use graph rewrite mixed precision training method bypass autocasting issue graph rewrite working case e g train subclassed model tf gradienttape thus recommended tensorflow official guide flexibility hope use mixed precision policy mixed precision training directly exporting mixed precision trained model savedmodel deployment straightforward production pipeline code reproduce issue reproduce bug using official image classification training example test mixed precision policy model saving import logging import o absl import app absl app import tensorflow tf official vision image classification resnet model import resnet50 def main argv tf compat v1 enable eager execution setup mixed precision policy policy enables autocasting behavior kera layer policy tf kera mixed precision experimental policy mixed float16 loss scale tf kera mixed precision experimental set policy policy model resnet50 model dir temp saved model test o path isdir model dir o makedirs model dir model save model dir save format tf logging info exported trained model directory format model dir name main absl app run main,2019-12-24 06:21:18,1577168478,resolved fixed,cd6184047e9e497955c473b88387b54818ff23a0,1577411887,tensorflow\python\keras\mixed_precision\experimental\keras_test.py tensorflow\python\keras\mixed_precision\experimental\test_util.py tensorflow\python\keras\saving\saved_model\save_impl.py                                                        
207,35547,Cloud TPU console spam on every TensorFlow import,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu glinux like debian mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command v1 g2e8d5e5 dev20200102 python version python bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior importing tensorflow print unnecessary unhelpful warning warning tensorflow falling back tensorflow client recommended install cloud tpu client directly pip install cloud tpu client describe expected behavior importing tensorflow print message cloud tpus normal desktop installation anything tpus need code reproduce issue python c import tensorflow diff u dev null info log likely introduced,2020-01-02 18:27:18,1577989638,resolved fixed,3ff0960fee4927db7baea2f354e60c3328b066fe,1578083716,tensorflow\python\distribute\cluster_resolver\tpu_cluster_resolver.py tensorflow\python\distribute\cluster_resolver\tpu_cluster_resolver_test.py                                                          
208,35551,TFLite expermimental_new_converter error with tf.keras Bidirectional Wrapper or attribute go_backwards=True,system information os platform distribution linux ubuntu tensorflow installed source binary tensorflow version github sha source used build model used run converter dev20191227 command used run converter code using python api import tensorflow tf import o o environ cuda visible devices print tf version model tf kera model load model home amish pycharmprojects myproject script temp h5 model summary converter tf lite tfliteconverter kera model model converter target spec supported ops tf lite opsset tflite builtins tf lite opsset select tf ops converter experimental new converter true add line tflite model converter convert output converter invocation warning tensorflow falling back tensorflow client recommended install cloud tpu client directly pip install cloud tpu client dev20191227 tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcuda e tensorflow stream executor cuda cuda driver cc failed call cuinit cuda error device cuda capable device detected tensorflow stream executor cuda cuda diagnostics cc retrieving cuda diagnostic information host enigma tensorflow stream executor cuda cuda diagnostics cc hostname enigma tensorflow stream executor cuda cuda diagnostics cc libcuda reported version tensorflow stream executor cuda cuda diagnostics cc kernel reported version tensorflow stream executor cuda cuda diagnostics cc kernel version seems match dso tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service initialized platform host guarantee xla used devices tensorflow compiler xla service service cc streamexecutor device host default version model sequential layer type output shape param masking masking none bidirectional bidirection none dropout dropout none dense dense none total params trainable params non trainable params tensorflow core grappler device cc number eligible gpus core count compute capability tensorflow core grappler cluster single machine cc starting new session tensorflow core grappler optimizers meta optimizer cc optimization result grappler item graph optimize tensorflow core grappler optimizers meta optimizer cc function optimizer graph size node edge time tensorflow core grappler optimizers meta optimizer cc function optimizer graph size node edge time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional forward lstm body tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional forward lstm cond tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional backward lstm body tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional backward lstm cond tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler optimizers meta optimizer cc function optimizer function optimizer nothing time tensorflow core grappler device cc number eligible gpus core count compute capability tensorflow core grappler cluster single machine cc starting new session tensorflow core grappler optimizers meta optimizer cc optimization result grappler item graph optimize tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional backward lstm body frozen tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional forward lstm body frozen tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional backward lstm cond frozen tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc optimization result grappler item sequential bidirectional forward lstm cond frozen tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time tensorflow core grappler optimizers meta optimizer cc constant folding graph size node edge time traceback recent call last file convert py line tflite model converter convert file home amish anaconda3 lib python3 site package tensorflow core lite python lite py line convert converter kwargs file home amish anaconda3 lib python3 site package tensorflow core lite python convert py line toco convert impl enable mlir converter enable mlir converter file home amish anaconda3 lib python3 site package tensorflow core lite python convert py line toco convert protos raise convertererror see console info n n n stdout stderr tensorflow lite python convert convertererror see console info warning tensorflow falling back tensorflow client recommended install cloud tpu client directly pip install cloud tpu client w tensorflow compiler mlir lite python graphdef tfl flatbuffer cc ignored output format w tensorflow compiler mlir lite python graphdef tfl flatbuffer cc ignored drop control dependency tensorflow core platform cpu feature guard cc cpu support instruction tensorflow binary compiled use avx2 fma tensorflow core platform profile utils cpu utils cc cpu frequency hz tensorflow compiler xla service service cc xla service initialized platform host guarantee xla used devices tensorflow compiler xla service service cc streamexecutor device host default version tensorflow stream executor platform default dso loader cc successfully opened dynamic library libcuda e tensorflow stream executor cuda cuda driver cc failed call cuinit cuda error device cuda capable device detected tensorflow stream executor cuda cuda diagnostics cc retrieving cuda diagnostic information host enigma tensorflow stream executor cuda cuda diagnostics cc hostname enigma tensorflow stream executor cuda cuda diagnostics cc libcuda reported version tensorflow stream executor cuda cuda diagnostics cc kernel reported version tensorflow stream executor cuda cuda diagnostics cc kernel version seems match dso loc callsite sequential bidirectional backward lstm reversev2 home amish anaconda3 lib python3 site package tensorflow core python eager def function py callsite home amish anaconda3 lib python3 site package tensorflow core python eager def function py callsite home amish anaconda3 lib python3 site package tensorflow core lite python lite py convert py error tfl reverse v2 op operand must tensor bit float bit integer bit integer bit integer value got tensor traceback recent call last file home amish anaconda3 bin toco protos line sys exit main file home amish anaconda3 lib python3 site package tensorflow core lite toco python toco protos py line main app run main execute argv sys argv unparsed file home amish anaconda3 lib python3 site package tensorflow core python platform app py line run run main main argv argv flag parser parse flag tolerate undef file home amish anaconda3 lib python3 site package absl app py line run run main main args file home amish anaconda3 lib python3 site package absl app py line run main sys exit main argv file home amish anaconda3 lib python3 site package tensorflow core lite toco python toco protos py line execute enable mlir converter exception home amish anaconda3 lib python3 site package tensorflow core python eager def function py error tfl reverse v2 op operand must tensor bit float bit integer bit integer bit integer value got tensor self initialize args kwargs add initializers initializers home amish anaconda3 lib python3 site package tensorflow core python eager def function py note called concrete self get concrete function garbage collected args kwargs home amish anaconda3 lib python3 site package tensorflow core lite python lite py note called concrete func func get concrete function convert py note called converter tf lite tfliteconverter kera model model issue caused due bidirectional wrapper also error occurs go backwards true lstm layer please tell workaround temporarily fix,2020-01-02 21:33:26,1578000806,resolved fixed,e8f6431f53f49f8cab7e15bef24ab2ee775f2ed9,1578444448,tensorflow\compiler\mlir\lite\ir\tfl_ops.td tensorflow\lite\kernels\register.cc tensorflow\lite\kernels\reverse.cc tensorflow\lite\testing\op_tests\reverse_v2.py tensorflow\lite\toco\tflite\op_version.cc tensorflow\lite\tools\versioning\op_version.cc                                                  
209,35765,Autograph failure with `\`,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v2 rc2 ge5bf8de python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory nvidia rtx describe current behavior tensorflow show warning failure autograph warning tensorflow autograph could transform run please report tensorflow team filing bug set verbosity linux export autograph verbosity attach full output cause expected exactly one node node found warning seems caused backslash describe expected behavior warning code reproduce issue import tensorflow tf class c object def f self error disappear following line removed return obj c tf function def func mem obj f return mem def main print func name main main,2020-01-11 06:54:34,1578725674,resolved fixed,8e3adf77b2a148fb2c6fea8fea2d0217bca3339f,1579528035,tensorflow\python\autograph\pyct\parser.py tensorflow\python\autograph\pyct\parser_test.py                                                          
210,35980,Tensorflow predict call crashes when loading a model with gevent enabled,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos also tried docker container nvidia cuda cudnn7 runtime tensorflow installed source binary binary tensorflow version use command v2 rc2 ge5bf8de410 python version mac python anaconda inc docker cuda cudnn version n gpu model memory n describe current behavior tensorflow crash calling predict model happens gevent also describe expected behavior tensorflow crash code reproduce issue gevent import monkey monkey patch import numpy np import tensorflow tf classifier tf kera model load model tensorflow model dir classifier predict np array np zero info log traceback recent call last file opt conda envs py36 lib python3 site package tensorflow core python kera backend py line eager learning phase scope graph learning phases dummy eager graph value file opt conda envs py36 lib python3 weakref py line setitem self data ref key self remove value typeerror create weak reference gevent local local object handling exception another exception occurred traceback recent call last file script gevent load classifier py line np zero file opt conda envs py36 lib python3 site package tensorflow core python kera engine training py line predict use multiprocessing use multiprocessing file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 py line predict worker worker use multiprocessing use multiprocessing kwargs file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 py line model iteration total epoch file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 py line run one epoch batch out execution function iterator file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 utils py line execution function distributed function input fn file opt conda envs py36 lib python3 site package tensorflow core python eager def function py line call result self call args kwds file opt conda envs py36 lib python3 site package tensorflow core python eager def function py line call self initialize args kwds add initializers initializers file opt conda envs py36 lib python3 site package tensorflow core python eager def function py line initialize args kwds file opt conda envs py36 lib python3 site package tensorflow core python eager function py line get concrete function internal garbage collected graph function self maybe define function args kwargs file opt conda envs py36 lib python3 site package tensorflow core python eager function py line maybe define function graph function self create graph function args kwargs file opt conda envs py36 lib python3 site package tensorflow core python eager function py line create graph function capture value self capture value file opt conda envs py36 lib python3 site package tensorflow core python framework func graph py line func graph py func func output python func func args func kwargs file opt conda envs py36 lib python3 site package tensorflow core python eager def function py line wrapped fn return weak wrapped fn wrapped args kwds file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 utils py line distributed function per replica function args args file opt conda envs py36 lib python3 site package tensorflow core python distribute distribute lib py line experimental run v2 return self extended call replica fn args args kwargs kwargs file opt conda envs py36 lib python3 site package tensorflow core python distribute distribute lib py line call replica return self call replica fn args kwargs file opt conda envs py36 lib python3 site package tensorflow core python distribute distribute lib py line call replica return fn args kwargs file opt conda envs py36 lib python3 site package tensorflow core python autograph impl api py line wrapper return func args kwargs file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 utils py line predict batch result predict batch model x file opt conda envs py36 lib python3 site package tensorflow core python kera engine training v2 utils py line predict batch backend eager learning phase scope file opt conda envs py36 lib python3 contextlib py line enter return next self gen file opt conda envs py36 lib python3 site package tensorflow core python kera backend py line eager learning phase scope del graph learning phases dummy eager graph file opt conda envs py36 lib python3 weakref py line delitem del self data ref key typeerror create weak reference gevent local local object,2020-01-17 11:07:41,1579259261,resolved fixed,75286a79e7cdf9fdc27b15919f453786eee8936d,1580238571,tensorflow\python\keras\backend.py                                                            
211,36067,saved_model_cli breaks nightly packages,house nightly build broken since auditwheel try repair nightly package reason hood seems incorrect link recent change adding xla support install latest nightly navigate directory tensorflow core compiler aot ldd pywrap tfcompile linux vdso libtensorflow framework usr local lib python3 dist package tensorflow core compiler aot libtensorflow framework pywrap tensorflow internal found libdl lib x86 linux gnu libdl libpthread lib x86 linux gnu libpthread libm lib x86 linux gnu libm libstdc usr lib x86 linux gnu libstdc libgcc lib x86 linux gnu libgcc libc lib x86 linux gnu libc lib64 ld linux x86 librt lib x86 linux gnu librt obviously link pywrap tensorflow internal found relative path ps using auditwheel produce manylinux2014 build official tf nightly us older version fails catch pps directly using saved model cli give error pywrap tensorflow internal seems preloaded pretty sure bug need fix ping ebrevdo mihaimaruseac,2020-01-20 14:38:28,1579531108,resolved fixed,0a57a64a022a180abf7a95584a9570e9f126c42e,1579545577,tensorflow\compiler\aot\BUILD tensorflow\python\BUILD tensorflow\python\tfcompile_wrapper.cc tensorflow\python\tools\saved_model_cli.py                                                      
212,36198,model.summary() Does not Work in Some Cases,tf version suggested reedwm filing bug please see last comment issue detail cc reedwm,2020-01-25 06:10:44,1579932644,resolved fixed,bb2e09ad7207c504296962192fa5f1b7ec53a659,1607021674,tensorflow\python\keras\tests\model_subclassing_test.py tensorflow\python\keras\utils\layer_utils.py                                                          
213,3624,Basic Element-wise Complex Number Calculations Not Available On GPU,basic element wise addition subtraction multiplication division tensor type tf complex64 implemented gpu environment info operating system centos el7 x86 installed version cuda cudnn cuda cudnn v4 rw r r root root jul usr local cuda lib libcudadevrt lrwxrwxrwx root root jul usr local cuda lib libcudart libcudart lrwxrwxrwx root root jul usr local cuda lib libcudart libcudart rwxr xr x root root jul usr local cuda lib libcudart rw r r root root jul usr local cuda lib libcudart static tensorflow installed source commit hash bazel information build label ca36b06 build target bazel local fastbuild bin src main java com google devtools build lib bazel bazelserver deploy jar build time fri jul build timestamp build timestamp int steps reproduce add subtract multiply divide tensor type tf complex64 code example shown element wise addition import tensorflow tf name main tf device gpu n tf complex tf random normal n tf random normal n b tf complex tf random normal n tf random normal n c b tf session sess c sess run c code return following output run gpu work well cpu tensorflow stream executor dso loader cc successfully opened cuda library libcublas locally tensorflow stream executor dso loader cc successfully opened cuda library libcudnn locally tensorflow stream executor dso loader cc successfully opened cuda library libcufft locally tensorflow stream executor dso loader cc successfully opened cuda library libcuda locally tensorflow stream executor dso loader cc successfully opened cuda library libcurand locally tensorflow core common runtime gpu gpu init cc found device property name tesla k40c major minor memoryclockrate ghz pcibusid total memory free memory w tensorflow stream executor cuda cuda driver cc creating context one currently active existing tensorflow core common runtime gpu gpu init cc found device property name geforce gt major minor memoryclockrate ghz pcibusid total memory free memory tensorflow core common runtime gpu gpu init cc enable peer access device ordinal device ordinal tensorflow core common runtime gpu gpu init cc enable peer access device ordinal device ordinal tensorflow core common runtime gpu gpu init cc dma tensorflow core common runtime gpu gpu init cc n tensorflow core common runtime gpu gpu init cc n tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name tesla k40c pci bus id tensorflow core common runtime gpu gpu device cc ignoring gpu device device name geforce gt pci bus id cuda compute capability minimum required cuda capability e tensorflow core client tensor c api cc assign device node add could satisfy explicit device specification device gpu supported kernel gpu device available node add add dt complex64 device device gpu complex complex traceback recent call last file test div gpu prob py line c sess run c file usr lib python2 site package tensorflow python client session py line run run metadata ptr file usr lib python2 site package tensorflow python client session py line run feed dict string option run metadata file usr lib python2 site package tensorflow python client session py line run target list option run metadata file usr lib python2 site package tensorflow python client session py line call raise type e node def op message tensorflow python framework error invalidargumenterror assign device node add could satisfy explicit device specification device gpu supported kernel gpu device available node add add dt complex64 device device gpu complex complex caused op u add defined file test div gpu prob py line c b file usr lib python2 site package tensorflow python ops math ops py line binary op wrapper return func x name name file usr lib python2 site package tensorflow python ops gen math ops py line add result op def lib apply op add x x name name file usr lib python2 site package tensorflow python framework op def library py line apply op op def op def file usr lib python2 site package tensorflow python framework ops py line create op original op self default original op op def op def file usr lib python2 site package tensorflow python framework ops py line init self traceback extract stack tried implementation using builtin tensorflow function work real imaginary part separated see code import numpy np import tensorflow tf def complex add x xr xi tf real x tf imag x yr yi tf real tf imag return tf complex xr yr xi yi def complex sub x xr xi tf real x tf imag x yr yi tf real tf imag return tf complex xr yr xi yi def complex mul x xr xi tf real x tf imag x yr yi tf real tf imag return tf complex xr yr xi yi xr yi xi yr def complex div x xr xi tf real x tf imag x yr yi tf real tf imag tf square yr tf square yi return tf complex xr yr xi yi xi yr xr yi name main tf device gpu n tf complex tf random normal n tf random normal n b tf complex tf random normal n tf random normal n tf session sess b c sess run b complex add b assert np allclose c b b c sess run b complex sub b assert np allclose c b b c sess run b complex mul b assert np allclose c b b c sess run b complex div b assert np allclose c b would nice function transparent built cpu implementation,2016-08-03 15:32:28,1470238348,resolved fixed,53af29cb8503c7ed55a23d22090dd39ce0056a7a,1473895885,tensorflow\core\kernels\cwise_op_add.cc tensorflow\core\kernels\cwise_op_gpu_add.cu.cc tensorflow\python\kernel_tests\cwise_ops_test.py                                                        
214,36268,tf.debugging.assert_shapes() does not work for SparseTensor,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu mac os x tensorflow installed source binary binary tensorflow version use command python version describe current behavior tf debugging assert shape used sparse tensor describe expected behavior tf debugging assert shape allow mix match dense sparse tensor checking dimensional consistency code reproduce issue import tensorflow tf tf range tf debugging assert shape work raise valueerror attempt convert value unsupported type tensor tf debugging assert shape tf sparse dense,2020-01-28 02:49:22,1580179762,resolved fixed,11fc1489d01822a2e728103c3af998976b4e7cd1,1601495634,RELEASE.md tensorflow\python\kernel_tests\check_ops_test.py tensorflow\python\ops\check_ops.py                                                        
215,36394,file_io.get_matching_files indefinitely hangs,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu gcp cloud shell mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary comes pre installed gcp cloud shell tensorflow version use command tf python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n describe current behavior file io get matching file indefinitely hang describe expected behavior file io get matching file hang code reproduce issue note first command gsutil cp readme cloudshell txt g test bug txt gsutil cp readme cloudshell txt g test bug txt creates weird folder test folder open python tensorflow python lib io import file io file io get matching file g test bug txt hang delete folder would work fine one training job hung tf somehow created folder model output directory,2020-02-01 01:57:51,1580522271,resolved fixed,7bfbd3f7be0725ee9c220047fe85032cf126d92b,1590098925,tensorflow\core\platform\cloud\gcs_file_system.cc tensorflow\core\platform\cloud\gcs_file_system_test.cc                                                          
216,36462,Autograph is incompatible with typeguard,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory gpu collect information using environment capture script also obtain tensorflow version tf tf describe current behavior import tensorflow tf typeguard import typechecked tf function autograph true typechecked def add tf tensor b tf tensor tf tensor return b print add tf one tf zero nameerror traceback recent call last return b print add tf one tf zero frame usr local lib python3 dist package tensorflow core python eager def function py call self args kwds xla context exit else result self call args kwds tracing count self get tracing count usr local lib python3 dist package tensorflow core python eager def function py call self args kwds first call call initialize initializers self initialize args kwds add initializers initializers finally point know initialization complete le usr local lib python3 dist package tensorflow core python eager def function py initialize self args kwds add initializers self concrete stateful fn self stateful fn get concrete function internal garbage collected pylint disable protected access args kwds def invalid creator scope unused args unused kwds usr local lib python3 dist package tensorflow core python eager function py get concrete function internal garbage collected self args kwargs args kwargs none none self lock graph function self maybe define function args kwargs return graph function usr local lib python3 dist package tensorflow core python eager function py maybe define function self args kwargs self function cache missed add call context key graph function self create graph function args kwargs self function cache primary cache key graph function return graph function args kwargs usr local lib python3 dist package tensorflow core python eager function py create graph function self args kwargs override flat arg shape arg name arg name override flat arg shape override flat arg shape capture value self capture value self function attribute tell concretefunction clean graph go usr local lib python3 dist package tensorflow core python framework func graph py func graph py func name python func args kwargs signature func graph autograph autograph option add control dependency arg name op return value collection capture value override flat arg shape converted func func output python func func args func kwargs invariant func output contains tensors compositetensors usr local lib python3 dist package tensorflow core python eager def function py wrapped fn args kwds wrapped allows autograph swap converted function give function weak reference avoid reference cycle return weak wrapped fn wrapped args kwds weak wrapped fn weakref ref wrapped fn usr local lib python3 dist package tensorflow core python framework func graph py wrapper args kwargs except exception e pylint disable broad except hasattr e ag error metadata raise e ag error metadata exception e else raise nameerror converted code usr local lib python3 dist package typeguard init py wrapper check argument type memo usr local lib python3 dist package typeguard init py check argument type argname expected type memo type hint item usr local lib python3 dist package tensorflow core python autograph operator control flow py stmt return py stmt iter extra test body get state set state init var usr local lib python3 dist package tensorflow core python autograph operator control flow py py stmt extra test none extra test state tmp tmpnaoua4 l py extra test return ag return nameerror free variable return referenced assignment enclosing scope describe expected behavior tf tensor shape dtype float32 code reproduce issue provide reproducible test case bare minimum necessary generate problem import tensorflow tf typeguard import typechecked tf function autograph true typechecked def add tf tensor b tf tensor tf tensor return b print add tf one tf zero see colab notebook info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-02-04 13:55:11,1580824511,resolved fixed,a962580295172539a3a6ae5b02836aac1cabf100,1582856286,tensorflow\python\autograph\converters\break_statements.py tensorflow\python\autograph\converters\control_flow.py tensorflow\python\autograph\converters\control_flow_deprecated_py2.py tensorflow\python\autograph\converters\return_statements.py tensorflow\python\autograph\pyct\anno.py tensorflow\python\autograph\pyct\cfg.py tensorflow\python\autograph\pyct\static_analysis\activity.py tensorflow\python\autograph\pyct\templates.py                                              
217,36624,LSTM return_state=True fail with tf.keras.Sequencial model,written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos tensorflow installed source binary binary tensorflow version use command v2 rc2 ge5bf8de410 python version v3 oct describe current behavior call method tf kera sequential object fails throw error one layer instance tf kera layer lstm class constructed return state true given error message believe output call method lstm layer list instead tensor call method sequential know list describe expected behavior think call method sequential know tensor output lstm first element list return state true code reproduce issue setting import tensorflow tf import numpy np print using tensorflow version git version format tf version version tf version git version batch size t input dim nump np arange example batch size t input dim dtype np float32 reshape batch size t input dim dataset tf data dataset tensor slice nump batch batch size x dataset print x shape return state true output using tensorflow version git version v2 rc2 ge5bf8de410 error sequential model seq tf kera sequential tf kera layer lstm return state return state x dataset print model seq x output attributeerror traceback recent call last model seq tf kera sequential tf kera layer lstm return state return state x dataset print model seq x path python3 site package tensorflow core python kera engine base layer py call self input args kwargs base layer utils autocast context manager self compute dtype output self call cast input args kwargs self handle activity regularization input output self set mask metadata input output input mask path python3 site package tensorflow core python kera engine sequential py call self input training mask output input next layer input output mask output kera mask return output attributeerror list object attribute kera mask work constructing model functional api def lstm model return state t input dim inp tf kera input shape t input dim tf kera layer lstm return state return state inp return tf kera model input inp output model func lstm model return state t input dim x dataset print model func x output tf tensor shape dtype float32 numpy array dtype float32 tf tensor shape dtype float32 numpy array dtype float32 tf tensor shape dtype float32 numpy array dtype float32 related question functional api example lstm modelfails use inp tf kera input shape t none instead providing explicit input dimension error message get typeerror traceback recent call last return tf kera model input inp output model func lstm model return state t input dim x dataset lstm model return state t input dim def lstm model return state t input dim inp tf kera input shape t none tf kera layer lstm return state return state inp return tf kera model input inp output path python3 site package tensorflow core python kera layer recurrent py call self input initial state constant kwargs initial state none constant none return super rnn self call input kwargs initial state constant specified keras path python3 site package tensorflow core python kera engine base layer py call self input args kwargs build layer applicable build method overridden self maybe build input cast input self maybe cast input input path python3 site package tensorflow core python kera engine base layer py maybe build self input operation tf utils maybe init scope self self build input shape must set self built since user defined build function constrained set self built path python3 site package tensorflow core python kera layer recurrent py build self input shape isinstance self cell layer self cell built self cell build step input shape set validate state spec path python3 site package tensorflow core python kera utils tf utils py wrapper instance input shape input shape none input shape convert shape input shape tuples true output shape fn instance input shape return shape fn tensorshapes output shape none path python3 site package tensorflow core python kera layer recurrent py build self input shape regularizer self kernel regularizer constraint self kernel constraint caching device default caching device self recurrent kernel self add weight shape self unit self unit path python3 site package tensorflow core python kera engine base layer py add weight self name shape dtype initializer regularizer trainable constraint partitioner use resource synchronization aggregation kwargs synchronization synchronization aggregation aggregation caching device caching device backend track variable variable path python3 site package tensorflow core python training tracking base py add variable custom getter self name shape dtype initializer getter overwrite kwargs getter dtype dtype initializer initializer kwargs getter set initializer variable processed tracking path python3 site package tensorflow core python kera engine base layer utils py make variable name shape dtype initializer trainable caching device validate shape constraint use resource collection synchronization aggregation partitioner synchronization synchronization aggregation aggregation shape variable shape variable shape else none path python3 site package tensorflow core python ops variable py call cl args kwargs def call cl args kwargs cl variablev1 return cl variable v1 call args kwargs elif cl variable return cl variable v2 call args kwargs path python3 site package tensorflow core python ops variable py variable v1 call cl initial value trainable collection validate shape caching device name variable def dtype expected shape import scope constraint use resource synchronization aggregation shape synchronization synchronization aggregation aggregation shape shape def variable v2 call cl path python3 site package tensorflow core python ops variable py kwargs shape none call variable class useful force signature previous getter lambda kwargs default variable creator none kwargs getter ops get default graph variable creator stack pylint disable protected access previous getter make getter getter previous getter path python3 site package tensorflow core python ops variable scope py default variable creator next creator kwargs synchronization synchronization aggregation aggregation shape shape else return variable refvariable path python3 site package tensorflow core python ops variable py call cl args kwargs return cl variable v2 call args kwargs else return super variablemetaclass cl call args kwargs path python3 site package tensorflow core python ops resource variable ops py init self initial value trainable collection validate shape caching device name dtype variable def import scope constraint distribute strategy synchronization aggregation shape aggregation aggregation shape shape distribute strategy distribute strategy def init args self path python3 site package tensorflow core python ops resource variable ops py init args self initial value trainable collection caching device name dtype constraint synchronization aggregation distribute strategy shape ops name scope initializer device context manager none initial value ops convert tensor initial value init fn else initial value name initial value dtype dtype shape none path python3 site package tensorflow core python kera engine base layer utils py type init ops initializer type init ops v2 initializer initializer initializer init val lambda initializer shape dtype dtype variable dtype dtype base dtype use resource none path python3 site package tensorflow core python ops init ops v2 py call self shape dtype scale max fan else scale max fan fan self distribution truncated normal constant scipy stats truncnorm std b loc scale typeerror unsupported operand type nonetype int normal,2020-02-10 14:48:15,1581346095,resolved fixed,619ca02f2d9ff61aedf7de6e6b43116e859f6913,1581726099,tensorflow\python\keras\engine\sequential.py tensorflow\python\keras\engine\sequential_test.py                                                          
218,36700,tf2 isn't enabled in tensorflow_core.python.keras.layers.__init__,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary pip install tensorflow tensorflow version use command python version cuda cudnn version used gpu model memory used collect information using environment capture script also obtain tensorflow version tf tf describe current behavior whenever import layer using path tensorflow python kera layer import layer using tensorflow x behavior case use tensorflow kera layer issue every network tf kera application resnet densenet use import lead severe bug e g batchnormalization describe expected behavior importing tensorflow python kera layer tensorflow kera layer exactly behavior x code reproduce issue tensorflow python kera layer import batchnormalization buggy bn tensorflow kera layer import batchnormalization good bn print good bn use v2 behavior true print buggy bn use v2 behavior false info log think issue could fix changing tensorflow core python tf2 def enabled returns true iff tensorflow behavior enabled force enable none return o getenv tf2 behavior else return force enable def enabled returns true iff tensorflow behavior enabled force enable none return o getenv tf2 behavior else return force enable make tf2 behavior enabled default,2020-02-12 16:35:26,1581525326,resolved fixed,35a382295ad81f7080d306c9b09b0edaa451fcfc,1585159125,tensorflow\api_template.__init__.py                                                            
219,37230,tf.function second derivative error,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos mojave mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary tensorflow version use command binary v2 rc2 python version bazel version compiling source python gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior custom function need use slicing loop first order derivative working properly second order derivative give error error occurs function decorated tf function simplified code reproduce error describe expected behavior standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf x tf random uniform minval maxval seed dtype tf float32 tf function def x return x tf function def g x z sum tf constant dtype tf float32 tf range x shape z sum tf add z sum x return z sum tf gradienttape watch x tf gradienttape tt tt watch x loss g x jac tt gradient loss x hess gradient jac x info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached invalidargumenterror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python framework ops py get attr self name c api util tf buffer buf c api tf operationgetattrvalueproto self c op name buf data c api tf getbuffer buf invalidargumenterror operation gradient grad grad attr named xlacompile handling exception another exception occurred valueerror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py maybecompile scope op func grad fn try xla compile op get attr xlacompile xla separate compiled gradient op get attr anaconda3 envs bys lib python3 site package tensorflow core python framework ops py get attr self name convert valueerror backwards compatibility raise valueerror str e x attr value pb2 attrvalue valueerror operation gradient grad grad attr named xlacompile handling exception another exception occurred invalidargumenterror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python framework ops py get attr self name c api util tf buffer buf c api tf operationgetattrvalueproto self c op name buf data c api tf getbuffer buf invalidargumenterror operation gradient tensorlistpushback grad tensorlistpopback attr named xlacompile handling exception another exception occurred valueerror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py maybecompile scope op func grad fn try xla compile op get attr xlacompile xla separate compiled gradient op get attr anaconda3 envs bys lib python3 site package tensorflow core python framework ops py get attr self name convert valueerror backwards compatibility raise valueerror str e x attr value pb2 attrvalue valueerror operation gradient tensorlistpushback grad tensorlistpopback attr named xlacompile handling exception another exception occurred valueerror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python framework op def library py apply op helper op type name name keywords ref input arg ref preferred dtype default dtype except typeerror err anaconda3 envs bys lib python3 site package tensorflow core python framework ops py convert tensor value dtype name ref preferred dtype dtype hint ctx accepted result type ret none ret conversion func value dtype dtype name name ref ref anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant tensor conversion function v dtype name ref ref return constant v dtype dtype name name anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant value dtype shape name return constant impl value dtype shape name verify shape false allow broadcast true anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant impl value dtype shape name verify shape allow broadcast value dtype dtype shape shape verify shape verify shape allow broadcast allow broadcast dtype value attr value pb2 attrvalue type tensor value tensor dtype anaconda3 envs bys lib python3 site package tensorflow core python framework tensor util py make tensor proto value dtype shape verify shape allow broadcast value none raise valueerror none value supported dtype provided force numpy array type valueerror none value supported handling exception another exception occurred valueerror traceback recent call last anaconda3 envs bys lib python3 site package tensorflow core python framework op def library py apply op helper op type name name keywords observed ops convert tensor value ref input arg ref dtype name except valueerror err anaconda3 envs bys lib python3 site package tensorflow core python framework ops py convert tensor value dtype name ref preferred dtype dtype hint ctx accepted result type ret none ret conversion func value dtype dtype name name ref ref anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant tensor conversion function v dtype name ref ref return constant v dtype dtype name name anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant value dtype shape name return constant impl value dtype shape name verify shape false allow broadcast true anaconda3 envs bys lib python3 site package tensorflow core python framework constant op py constant impl value dtype shape name verify shape allow broadcast value dtype dtype shape shape verify shape verify shape allow broadcast allow broadcast dtype value attr value pb2 attrvalue type tensor value tensor dtype anaconda3 envs bys lib python3 site package tensorflow core python framework tensor util py make tensor proto value dtype shape verify shape allow broadcast value none raise valueerror none value supported dtype provided force numpy array type valueerror none value supported handling exception another exception occurred valueerror traceback recent call last tt watch x loss g x jac tt gradient loss x hess gradient jac x anaconda3 envs bys lib python3 site package tensorflow core python eager backprop py gradient self target source output gradient unconnected gradient output gradient output gradient source raw flat source raw unconnected gradient unconnected gradient self persistent anaconda3 envs bys lib python3 site package tensorflow core python eager imperative grad py imperative grad tape target source output gradient source raw unconnected gradient output gradient source raw compat str unconnected gradient value anaconda3 envs bys lib python3 site package tensorflow core python eager function py backward function wrapper args break return backward call flat pylint disable protected access processed args remapped capture return backward function wrapper recorded output anaconda3 envs bys lib python3 site package tensorflow core python eager function py call flat self args captured input cancellation manager possible gradient type executing eagerly forward function args tangent forward backward forward executing eagerly flat output forward function call anaconda3 envs bys lib python3 site package tensorflow core python eager function py forward self builds retrieves forward function call forward function self function forward self inference args self input tangent return forward function self inference args self input tangent anaconda3 envs bys lib python3 site package tensorflow core python eager function py forward self inference args input tangent self forward self forward graph self backward self forwardprop output index self num forwardprop output self forward backward function inference args input tangent return self forward anaconda3 envs bys lib python3 site package tensorflow core python eager function py forward backward function self inference args input tangent output self func graph output self num inference output return self build function output output inference args input tangent anaconda3 envs bys lib python3 site package tensorflow core python eager function py build function output self output inference args input tangent self func graph input grad y gradient wrt output src graph self func graph capture forward anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py gradientshelper y x grad y name colocate gradient ops gate gradient aggregation method stop gradient unconnected gradient src graph function grad maybecompile grad scope op func call lambda grad fn op grad else function call ops add symbolicgradient anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py maybecompile scope op func grad fn xla scope op get attr xlascope decode except valueerror return grad fn exit early xla compile anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py function grad maybecompile grad scope op func call lambda grad fn op grad else function call ops add symbolicgradient anaconda3 envs bys lib python3 site package tensorflow core python ops v2 py whilegrad op grad body grad graph args create grad func y x non none grad cond graph body graph util unique grad fn name body graph name op maximum iteration body grad graph op need rewrite anaconda3 envs bys lib python3 site package tensorflow core python ops v2 py create grad func y x grad cond graph body graph name op maximum iteration func graph whilebodygradfuncgraph name cond graph body graph maximum iteration op body graph input body graph output update list output tensor corresponding captured anaconda3 envs bys lib python3 site package tensorflow core python framework func graph py func graph py func name python func args kwargs signature func graph autograph autograph option add control dependency arg name op return value collection capture value override flat arg shape converted func func output python func func args func kwargs invariant func output contains tensors compositetensors anaconda3 envs bys lib python3 site package tensorflow core python ops v2 py args grad func graph func graph module func graph py func name lambda args grad fn y x args body graph args func graph whilebodygradfuncgraph name cond graph body graph anaconda3 envs bys lib python3 site package tensorflow core python ops v2 py grad fn y x args func graph grad out gradient util gradientshelper y x grad y grad y src graph func graph unconnected gradient zero todo b handle case grad out none e g anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py gradientshelper y x grad y name colocate gradient ops gate gradient aggregation method stop gradient unconnected gradient src graph function grad maybecompile grad scope op func call lambda grad fn op grad else function call ops add symbolicgradient anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py maybecompile scope op func grad fn xla scope op get attr xlascope decode except valueerror return grad fn exit early xla compile anaconda3 envs bys lib python3 site package tensorflow core python ops gradient util py function grad maybecompile grad scope op func call lambda grad fn op grad else function call ops add symbolicgradient anaconda3 envs bys lib python3 site package tensorflow core python ops list ops py popbackgrad op dlist delement element shape gen list ops tensor list element shape op output shape type dtypes int32 return gen list ops tensor list push back dlist delement none anaconda3 envs bys lib python3 site package tensorflow core python ops gen list ops py tensor list push back input handle tensor name op output op def library apply op helper tensorlistpushback input handle input handle tensor tensor name name result output execute must record gradient anaconda3 envs bys lib python3 site package tensorflow core python framework op def library py apply op helper op type name name keywords raise valueerror tried convert tensor failed error input name err prefix input op type match input name op type name observed valueerror tried convert tensor tensor failed error none value supported,2020-03-02 12:43:36,1583153016,resolved fixed,cf09044d9e7b232080f95f0f910a6803904df1de,1585610529,tensorflow\python\eager\pywrap_gradient_exclusions.cc tensorflow\python\kernel_tests\list_ops_test.py tensorflow\python\ops\list_ops.py                                                        
220,37480,'third_party/tensorflow/compiler/aot:codegen_test' No such directory found,thank submitting tensorflow documentation issue per github policy address code doc bug performance issue feature request build installation issue github tensorflow doc open source get involved read documentation contributor guide url issue please provide link documentation entry example description issue need changing update golden file flip update golden true run following bazel test test strategy local third party tensorflow compiler aot codegen test clear description line wanted update golden file given directory present third party library example someone use method useful correct link link source code correct parameters defined parameter defined formatted correctly returns defined return value defined raises listed defined error defined example usage example usage example see api guide write testable usage example request visuals applicable currently visuals clarify content submit pull request planning also submit pull request fix issue see doc contributor guide doc api guide doc style guide,2020-03-10 14:31:49,1583850709,resolved fixed,282828af67de29d13dd2c69d96413c030b02543c,1585036808,tensorflow\compiler\aot\codegen_test.cc                                                            
221,37777,It seems that Tensorflow needs a check for the unreasonable parameter `input_dim=0` in the layer `Embedding`.,system information written custom code opposed using example directory os platform distribution e g linux ubuntu windows linux ubuntu tensorflow version cpu using pip install tensorflow download directly python version cuda cudnn version gpu model memory describe current behavior build model illogical parameter input dim layer embedding tensorflow us unreasonably parameter build even save model detailed performance building model shown following picture key insight sum input dim output dim unreasonable corner case tensorflow seems lack checking corner case may lead tensorflow user create even save wrong model bring potential risk subsequent usage code reproduce issue import numpy np import tensorflow kera layer l tensorflow kera import model input import tensorflow import o print tensorflow version kwargs input dim also set input dim test output dim mask zero true input np random random layer l embedding kwargs x input batch shape input shape layer x bk model model x model path o path join mode h5 bk model save model path bk model print finish,2020-03-21 10:12:31,1584785551,resolved fixed,f61175812426009a4c96e51befb2951612990903,1585247122,tensorflow\python\keras\layers\embeddings.py                                                            
222,37983,Calling next with a default value on an exhausted Dataset iterator raises an OutOfRangeError in graph mode,system information written custom code yes os platform distribution windows tensorflow installed binary describe current behavior next iterator default supposed give next element iterator value given default iterator end however using construction function tf function default value returned error tensorflow python framework error impl outofrangeerror produced trying call next iterator end running code eager mode default value returned expected describe expected behavior graph mode default value returned end iterator standalone code reproduce issue import tensorflow tf x tf convert tensor d tf data dataset tensor slice x dsi iter d tf function remove get expected behaviour def func range tf print next dsi func output see full stacktrace w tensorflow core common runtime base collective executor cc basecollectiveexecutor startabort range end sequence node iteratorgetnext expected output stacktrace txt,2020-03-27 18:02:30,1585332150,resolved fixed,95ea3404528afcb1a74dd5f0946ea8d17beda28b,1586647842,tensorflow\python\autograph\operators\py_builtins.py tensorflow\python\autograph\operators\py_builtins_test.py                                                          
223,3824,Unclear documentation and behavior for sampler in Tensorflow,sampler implemented tensorflow e g tf nn fixed unigram candidate sampler behavior well defined document instance would expect label specified true class excluded sampling pool sampling conducted batch according experiment neither true consider following code import tensorflow tf label matrix tf reshape tf constant dtype tf int64 sampled id tf nn fixed unigram candidate sampler true class label matrix num true num sampled unique true range max distortion unigrams range init tf initialize variable tf session sess sess run init print sess run sampled id output actually belongs set true class also output dimension basically mean sampling conducted batch someone help clarify,2016-08-15 18:34:24,1471286064,resolved fixed,71319c58a3436fbd7081e49c52878dd1ba1772b5,1493418838,tensorflow\core\ops\candidate_sampling_ops.cc tensorflow\python\ops\candidate_sampling_ops.py                                                          
224,38349,`nan` gradient when `tf.where` is used,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu debian gnu linux buster mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v2 rc2 ge5bf8de v1 g38797a1c8b dev20200407 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior well defined function tf nan gradient point tf inactive branch undefined describe expected behavior inactive branch ignored gradient calculation standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf ex range x tf convert tensor ex tf gradienttape g g watch x tf x x tf math log1p x tf x x tf math log x tf x x x dy dx g gradient x print f x dy dx x dy dx function well defined positive value used testing still show gradient point equal dy dx dy dx dy dx dy dx nan dy dx dy dx info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-04-08 09:30:26,1586338226,resolved fixed,d6c0858665de6036de24991b29d74b182cfcf5ae,1595662081,tensorflow\python\ops\array_ops.py                                                            
225,38403,model.reset_states() does not work for bidirectional-RNNs in tf.keras,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu lts tensorflow installed source binary binary tensorflow version use command tf tf nightly dev20200407 bug around issue different issue python version cuda cudnn version gpu model memory bug cpu gpu describe current behavior model reset state work bidirectional stateful recurrent layer bidi rnns tf model reset state nothing stateful bidi rnns tf nightly calling model reset state stateful bidi rnns cause crash reported bug tf model reset state nothing bidi rnns thought fixed tf nightly time returned tf model reset state standard rnns changed tf following behavior model stateful initial state input reset state zero model stateful initial state input reset state state input otherwise state carried form last call thus expected behavior stateful bidi rnns model stateful initial state input reset fwd bwd state zero model stateful initial state input reset fwd state fwd state input reset bwd state bwd state input otherwise fwd state bwd state carried form last call done stateful bidi rnns standalone code reproduce issue code show behavior state input import o o environ cuda device order pci bus id o environ cuda visible devices import numpy np tensorflow kera layer import input dense simplernn gru lstm bidirectional tensorflow kera model import model rec lstm sequence length feature dim feature input batch shape sequence length feature dim rnn bidirectional rec activation none use bias false return sequence true return state false stateful false feature stateless model model input feature output rnn stateful rnn bidirectional rec activation none use bias false return sequence true return state false stateful true feature stateful model model input feature output stateful rnn stateful model set weight stateless model get weight x np random normal sequence length x x reshape sequence length feature dim def print bidi non stateful stateful fb fwd bwd range print fb print f non stateful non stateful print f stateful stateful print f delta stateful non stateful non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful print n reseting states stateful model n stateful model reset state non stateful stateless model predict x reshape sequence length stateful stateful model predict x reshape sequence length print bidi non stateful stateful code demo initial state input import o o environ cuda device order pci bus id o environ cuda visible devices import numpy np tensorflow kera layer import input dense simplernn gru lstm bidirectional tensorflow kera model import model rec lstm sequence length feature dim feature input batch shape sequence length feature dim state h fwd input batch shape state h bwd input batch shape state c fwd input batch shape state c bwd input batch shape four state shape state h fwd state c fwd state h bwd state c bwd two state shape state h fwd state h bwd rec lstm rnn bidirectional rec activation linear use bias false return sequence true return state false stateful false feature initial state four state shape stateful rnn bidirectional rec activation linear use bias false return sequence true return state false stateful true feature initial state four state shape rnn input feature state h fwd state c fwd state h bwd state c bwd else rec simplernn rnn bidirectional rec activation linear use bias false return sequence true return state false stateful false feature initial state two state shape stateful rnn bidirectional rec activation linear use bias false return sequence true return state false stateful true feature initial state two state shape else rnn bidirectional rec activation linear use bias false return sequence true return state false stateful false feature initial state two state shape stateful rnn bidirectional rec activation linear use bias false return sequence true return state false stateful true feature initial state two state shape rnn input feature state h fwd state h bwd stateless model model input rnn input output rnn stateful model model input rnn input output stateful rnn toy weight np asarray dtype np float32 np asarray dtype np float32 np asarray dtype np float32 np asarray dtype np float32 stateless model set weight toy weight stateful model set weight toy weight stateful model set weight stateless model get weight stateful model save temp stateful h5 stateless model save temp stateless h5 x np random normal sequence length x np asarray x x reshape sequence length feature dim fwd initial h np asarray reshape fwd initial c np asarray reshape bwd initial h np asarray reshape bwd initial c np asarray reshape fwd initial h np asarray np random normal reshape fwd initial h np asarray np random normal reshape bwd initial h np asarray np random normal reshape fwd initial c np asarray np random normal reshape bwd initial c np asarray np random normal reshape rec lstm rnn input x fwd initial h fwd initial c bwd initial h bwd initial c else rnn input x fwd initial h bwd initial h def print bidi non stateful stateful fb fwd bwd range print fb print f non stateful non stateful print f stateful stateful print f delta stateful non stateful non stateful stateless model predict rnn input reshape sequence length stateful stateful model predict rnn input reshape sequence length print bidi non stateful stateful non stateful stateless model predict rnn input reshape sequence length stateful stateful model predict rnn input reshape sequence length print bidi non stateful stateful print n reseting states stateful model n stateful model reset state non stateful stateless model predict rnn input reshape sequence length stateful stateful model predict rnn input reshape sequence length print bidi non stateful stateful info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached sample output simplernn input state using tf fwd non stateful stateful delta bwd non stateful stateful delta fwd non stateful stateful delta bwd non stateful stateful delta reseting states stateful model fwd non stateful stateful delta bwd non stateful stateful delta crash using tf nightly traceback recent call last file temp bidi state py line stateful model reset state file home keith pyenv version tfn lib python3 site package tensorflow python kera engine network py line reset state layer reset state file home keith pyenv version tfn lib python3 site package tensorflow python kera layer wrapper py line reset state self forward layer reset state file home keith pyenv version tfn lib python3 site package tensorflow python kera layer recurrent py line reset state spec shape nest flatten self input spec shape attributeerror nonetype object attribute shape,2020-04-09 19:52:33,1586461953,resolved fixed,60b167181081c14ff88c77ae62049cab8a5ba4c7,1586884501,tensorflow\python\keras\layers\recurrent.py tensorflow\python\keras\layers\recurrent_test.py tensorflow\python\keras\layers\wrappers_test.py                                                        
226,38459,Both 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary tensorflow version use command dev20200411 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf tf describe current behavior instantiating batch norm layer like tf kera layer batchnormalization momentum center true scale false name bn1 get error mean variance must none training true exponential avg factor describe expected behavior always expected behavior consider meta learning example going see one batch training data want adapt mean variance batch mean momentum zero applying training iteration evaluate batch norm layer training false also work fine standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf import numpy np inp tf kera layer input shape dense tf kera layer conv2d activation none inp bn tf kera layer batchnormalization momentum center true scale false name bn1 dense rel tf kera layer relu bn flat tf kera layer flatten rel tf kera layer dense flat model tf kera model model input inp output model compile loss tf kera loss meansquarederror optimizer tf kera optimizers adam model fit x np random uniform size np random uniform size epoch model evaluate x np random uniform size np random uniform size model predict x np random uniform size info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-04-11 16:59:53,1586624393,resolved fixed,3cfba9571bcc4be237bfdfa3498c66073ae59280,1591641414,tensorflow\python\ops\nn_impl.py                                                            
227,38516,Cannot use set_visible_devices with mixed_precision,system information written custom code opposed using stock example script provided tensorflow kind combination example script os platform distribution e g linux ubuntu linux fedora mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary source tensorflow version use command v2 rc3 gaad398b5e9 rc3 python version bazel version compiling source gcc compiler version compiling source gcc gcc red hat cuda cudnn version cuda cudnn gpu model memory geforce rtx ti describe current behavior attempting use tf config set visible device conjunction tf python kera mixed precision experimental policy set policy tensorflow error runtimeerror tensorflow device gpu mapped multiple cuda device previously supported may result providing different gpu configuration configproto gpu option example different visible device list creating multiple sessions process currently supported see describe expected behavior error standalone code reproduce issue import tensorflow tf device tf config list physical device gpu tf config set visible device device gpu tensorflow python kera mixed precision experimental import policy mixed precision mixed precision set policy mixed precision policy mixed float16,2020-04-14 02:12:53,1586830373,resolved fixed,2730e4b0bcba80799ddc10f52081927848540f30,1586983469,tensorflow\python\keras\mixed_precision\experimental\device_compatibility_check.py                                                            
228,38640,"K.cast_to_floatx() will convert ""None"" to ""Nan"" and lead the ReLU to Nan output.",system information written custom code opposed using example directory os platform distribution e g linux ubuntu linux ubuntu tensorflow backend yes yes tensorflow version cpu python version cuda cudnn version gpu model memory describe current behavior found used relu threshold none tensorflow kera without error warning tensorflow return matrix nan detailed configuration code reproduction found following part reason investigation found parameter relu passed tensorflow python kera layer advanced activation py line near line k cast floatx incorrectly convert none parameter nan pas backend calculation refer figure figure nan none different meaning k cast floatx distinguish nan none calculation led usage nan parameter tensorflow calculation affect final output result make output nan operation may confuse user difference meaning none nan implementation k cast floatx judging current result meaning different issue affect relu also affect thresholdrelu leakyrelu operation using k cast floatx convert parameter code reproduce issue import o import numpy np import tensorflow tf import tensorflow kera layer l tensorflow kera model import load model root path path layer name relu kwargs max value negative slope threshold none input np random randn astype np float32 tensorflow kera import model input layer cl getattr l layer name layer layer cl kwargs x input batch shape input shape layer x bk model model x model path o path join root path model h5 bk model save model path bk model model load model model path output model predict input nanresult np isnan output print nanresult,2020-04-17 12:59:04,1587128344,resolved fixed,3db8df8ffafe5bcd83a12b92bc4c8287cd80237f,1588017695,tensorflow\python\keras\layers\advanced_activations.py                                                            
229,38906,MemoryOptimizer produces broken graph with AlreadyExistsError exception while running GRU layer on Tensorflow 2.2.0rc_3,system information custom model built using kera macbook pro core intel core i9 macos catalina tensorflow installed pip virtual environment tensorflow v2 rc2 gaad398b5e9 rc3 python running cpu describe current behavior code snippet listed output multiple tensorflow core framework op kernel cc op requires failed variable ops cc already exists resource warning finally exists tensorflow python framework error impl alreadyexistserror exception note code work correctly gru layer size decreased also work tensorflow downgraded version issue related issue reported issue offer code reproduce occurs latest version tensorflow describe expected behavior code work without exception standalone code reproduce issue import numpy np tensorflow kera model import sequential tensorflow kera layer import dense flatten bidirectional gru tensorflow kera layer import conv1d maxpooling1d x np random rand np random choice size model sequential model add conv1d filter kernel size activation relu input shape x shape model add maxpooling1d pool size stride model add bidirectional gru dropout recurrent dropout return sequence true model add flatten model add dense activation relu model add dense activation sigmoid model compile loss binary crossentropy optimizer rmsprop metric accuracy model summary model fit x x epoch verbose google colab notebook available error reproducible info log code generates following output model sequential layer type output shape param conv1d conv1d none max pooling1d maxpooling1d none bidirectional bidirectional none flatten flatten none dense dense none dense dense none total params trainable params non trainable params w tensorflow core framework op kernel cc op requires failed variable ops cc already exists resource per step gradient tape sequential bidirectional backward gru sequential bidirectional backward gru grad body gradient addn tmp var n10tensorflow19temporaryvariableop6tmpvare w tensorflow core framework op kernel cc op requires failed variable ops cc already exists resource per step gradient tape sequential bidirectional backward gru sequential bidirectional backward gru grad body gradient addn tmp var n10tensorflow19temporaryvariableop6tmpvare w tensorflow core framework op kernel cc op requires failed variable ops cc already exists resource per step gradient tape sequential bidirectional backward gru sequential bidirectional backward gru grad body gradient addn tmp var n10tensorflow19temporaryvariableop6tmpvare repeated multiple time w tensorflow core framework op kernel cc op requires failed variable ops cc already exists resource per step gradient tape sequential bidirectional forward gru sequential bidirectional forward gru grad body gradient addn tmp var n10tensorflow19temporaryvariableop6tmpvare traceback recent call last file alreadyexists err py line model fit x x epoch verbose file venv lib python3 site package tensorflow python kera engine training py line method wrapper return method self args kwargs file venv lib python3 site package tensorflow python kera engine training py line fit tmp log train function iterator file venv lib python3 site package tensorflow python eager def function py line call result self call args kwds file venv lib python3 site package tensorflow python eager def function py line call return self stateless fn args kwds file venv lib python3 site package tensorflow python eager function py line call return graph function filtered call args kwargs pylint disable protected access file venv lib python3 site package tensorflow python eager function py line filtered call self captured input file venv lib python3 site package tensorflow python eager function py line call flat ctx args cancellation manager cancellation manager file venv lib python3 site package tensorflow python eager function py line call ctx ctx file venv lib python3 site package tensorflow python eager execute py line quick execute input attrs num output tensorflow python framework error impl alreadyexistserror resource per step gradient tape sequential bidirectional backward gru sequential bidirectional backward gru grad body gradient addn tmp var n10tensorflow19temporaryvariableop6tmpvare node gradient tape sequential bidirectional backward gru sequential bidirectional backward gru grad body gradient addn tmp var op inference train function function call stack train function,2020-04-26 08:42:01,1587890521,resolved fixed,80a93674eafc224a45cbe96c65e993e9735634a3,1591288930,tensorflow\core\kernels\variable_ops.cc                                                            
230,38932,New TFLiteConverter not working with tf.complex64,system information os platform distribution e g linux ubuntu colab cpu tensorflow version use command rc3 describe current behavior new tfliteconverter working tf complex64 disabling new converter converter experimental new converter false work standalone code reproduce issue tf function def foo x return x x tf constant dtype tf complex64 tf constant dtype tf complex64 foo concrete foo get concrete function x converter tf lite tfliteconverter concrete function foo concrete foo tflite converter convert colab example thanks,2020-04-27 07:09:13,1587971353,resolved fixed,85c637969a25228065a276044691dab020984361,1590099653,tensorflow\compiler\mlir\lite\python\tf_tfl_flatbuffer_helpers.cc                                                            
231,39075,ForwardAccumulator fails with `experimental_run_functions_eagerly(True)`,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos catalina tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n running example tf forwardaccumulator doc fail running running example tf forwardaccumulator doc work way running standard example call added import tensorflow tf tf config experimental run function eagerly true v tf variable tf autodiff forwardaccumulator v vector hessian vector product tf constant acc tf gradienttape tape tf reduce sum v backward tape gradient v backward gradient backprop acc jvp backward forward backward hessian vector product info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached self push tape file users hartikainen conda envs policy evaluation lib python3 site package tensorflow python eager backprop py line push tape watch accessed variable self watch accessed variable file users hartikainen conda envs policy evaluation lib python3 site package tensorflow python eager tape py line push new tape return tape tape recursionerror maximum recursion depth exceeded,2020-05-01 09:54:27,1588326867,resolved fixed,3e6697b916c9e775dc61375b913d21ba9d22126f,1588705503,tensorflow\python\eager\forwardprop.py tensorflow\python\eager\forwardprop_test.py                                                          
232,39186,tf.data.experimental.make_csv_dataset modifies mutable variables passed to it,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information tensorflow installed source binary docker tensorflow version use command tf describe current behavior tf data experimental make csv dataset modifies passed variable place call variable changed line may happen variable passed specifically list sent replaced list index column file read describe expected behavior function never modify mutable object passed ever appropriate method class,2020-05-05 13:38:20,1588685900,resolved fixed,79acb0824b8bbb1fb887d2ff625f2f170d80fe1f,1588895675,tensorflow\python\data\experimental\kernel_tests\csv_dataset_test.py tensorflow\python\data\experimental\ops\readers.py                                                          
233,39222,Typos in source code docs,minor typo source code,2020-05-06 10:42:16,1588761736,resolved fixed,fe972004ab02ff454749bea5780e70d4a4633c3a,1588809091,tensorflow\python\eager\backprop.py                                                            
234,39462,ReduceLROnPlateau keeps executing lr reduction block of code after min_lr has been reached,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device none tensorflow installed source binary pip tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior reducelr execute part code reduces lr even lr equal min lr problem dealing lr since value technically never go min lr issue trying execution block code ie weight decay given min check block code assume intended u enter block code min lr already achieved either get rid min check care executing code reason make sure block code executed lr min lr issue clearly seems round precision related issue set lr k set value self model optimizer lr new lr next iteration fetch lr old lr float k get value self model optimizer lr get slightly different value old lr self min lr work yes way affect default code matter custom code still think bug really happen describe expected behavior code block supposed execute lr equal min lr execute lr equal min lr standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook x np random normal size np random normal size model sequential model add dense reduce lr reducelronplateau monitor loss min delta patience min lr verbose model compile loss mse optimizer sgd history model fit x epoch verbose shuffle true batch size callback reduce lr info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-05-12 15:20:32,1589296832,resolved fixed,b3461c38fd09abc6f31f69ade9bc632fabbdb73a,1589997894,tensorflow\python\keras\callbacks.py                                                            
235,39649,tf.math.reduce_mean takes too long and produces wrong result when input_tensor is uint32/64 and axis is array,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu macos mobile device e g iphone pixel samsung galaxy issue happens mobile device na tensorflow installed source binary binary tensorflow version use command v2 rc2 ge5bf8de410 v2 rc4 g2b96f3662b python version bazel version compiling source na gcc compiler version compiling source na cuda cudnn version na gpu model memory na collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior tf math reduce mean hang take forever compute certain input dtype uint64 uint32 axis array around slow occurs function produce incorrect result function affect function performance tf math reduce std call tf math reduce variance call tf math reduce mean describe expected behavior take forever compute produce incorrect result standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook example showed incorrect result import tensorflow tf import numpy np import time input tensor np arange astype uint64 also occurs uint32 range axis print axis axis start time time re tf math reduce mean input tensor axis axis end time time time diff end start print result re numpy print took sec time diff example became extremely slow produced incorrect result import tensorflow tf import numpy np import time magic number chosen illustration smaller number may cause slow could still show wrong result input tensor np arange astype uint64 also occurs uint32 range produce incorrect result slow occurs around axis print axis axis start time time re tf math reduce mean input tensor axis axis end time time time diff end start print result re numpy print took sec time diff info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-05-18 14:07:49,1589810869,resolved fixed,e972c5572634efd188696038e9241b75cdcd69bc,1592550741,tensorflow\core\framework\register_types.h tensorflow\core\framework\types.cc tensorflow\core\kernels\BUILD tensorflow\core\kernels\concat_lib_cpu.cc tensorflow\core\kernels\concat_op.cc tensorflow\core\kernels\constant_op.cc tensorflow\core\kernels\control_flow_ops.cc tensorflow\core\kernels\data\dataset_test_base.cc tensorflow\core\kernels\dense_update_ops.cc tensorflow\core\kernels\dynamic_partition_op.cc tensorflow\core\kernels\fill_functor.cc tensorflow\core\kernels\gather_op.cc tensorflow\core\kernels\identity_op.cc tensorflow\core\kernels\ragged_gather_op.cc tensorflow\core\kernels\ragged_tensor_from_variant_op.cc tensorflow\core\kernels\ragged_tensor_to_tensor_op.cc tensorflow\core\kernels\ragged_tensor_to_variant_op.cc tensorflow\core\kernels\resource_variable_ops.cc tensorflow\core\kernels\split_lib_cpu.cc tensorflow\core\kernels\split_op.cc tensorflow\core\kernels\strided_slice_op.cc tensorflow\core\kernels\strided_slice_op_impl.h tensorflow\core\kernels\topk_op.cc tensorflow\core\kernels\topk_op_gpu_uint32.cu.cc tensorflow\core\kernels\topk_op_gpu_uint64.cu.cc tensorflow\core\util\batch_util.cc tensorflow\core\util\saved_tensor_slice_util.h        
236,39718,"TF Lite nightly: Model with Fully Connected layer can't be converted, fully quantization, int8",system information os platform distribution e g linux ubuntu linux tensorflow installed source binary tf nightly tensorflow version github sha source tf nightly command used run converter code using python api possible please share link colab jupyter notebook import numpy np import tensorflow tf mnist tf kera datasets mnist train data test data mnist load data pre process lambda x x num calib calib data pre process train data num calib astype np float32 model tf kera sequential tf kera layer inputlayer input shape tf kera layer reshape target shape tf kera layer conv2d filter kernel size activation tf nn relu tf kera layer maxpooling2d pool size tf kera layer flatten tf kera layer dense activation tf nn softmax model summary train image pre process train data train label train data test image pre process test data test label test data train digit classification model model compile optimizer adam loss sparse categorical crossentropy metric accuracy model fit train image train label epoch validation data test image test label def get calib data func def representative data gen input value calib data input value np expand dims input value axis astype np float32 yield input value return representative data gen converter tf lite tfliteconverter kera model model converter representative dataset get calib data func converter target spec supported ops tf lite opsset tflite builtins int8 tflite model int8 converter convert runtimeerror max min dynamic tensor recorded calibration failed tensor sequential reshape shape empty min max tensor sequential reshape shape also please include link saved model graphdef failure detail conversion successful generated model wrong state wrong producing wrong result decrease accuracy producing correct result model slower expected model generated old converter rnn conversion support converting tf rnn tflite fused rnn ops please prefix rnn title info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-05-20 14:15:44,1589984144,resolved fixed,268a0ea1502532e0e127e71d0ad42cc4e8ad81c6,1591384423,tensorflow\lite\tools\optimize\quantize_model.cc                                                            
237,39756,problem running visualize.py at import flatbuffersn,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu mac os mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary source tensorflow version use command v1 g8670c85844 python version bazel version compiling source gcc compiler version compiling source apple clang version clang gcc version cuda cudnn version n gpu model memory n describe current behavior visualize py script fails error importerror import name flatbuffersn flatbuffers python private var tmp bazel jeremy execroot org tensorflow bazel darwin opt bin tensorflow lite tool visualize runfiles flatbuffers python init py running command top tensorflow source directory build phase seems work fine import error seems happen running visualize py full output attached file vi dump txt target tflite file downloaded think tflite file ever get loaded doubt specific file relevant directory trying import listed flatbuffersn file directory init py file empty l l private var tmp bazel jeremy execroot org tensorflow bazel darwin opt bin tensorflow lite tool visualize runfiles flatbuffers python total r xr xr x jeremy wheel may init py drwxr xr x jeremy wheel may pycache drwxr xr x jeremy wheel may flatbuffers describe expected behavior would expect dump html file tmp mobnet html containing visualization mobilenet model target tflite file standalone code reproduce issue command line info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-05-21 13:49:56,1590068996,resolved fixed,f9fb66cdb7419d2eadf7faea995f1aacb032104b,1590712450,third_party\flatbuffers\build_defs.bzl                                                            
238,39976,RandomContrast Layer - confusing __init__ error message,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu colab tensorflow installed source binary colab tensorflow version use command python version describe current behavior instantiating randomcontrast layer object value e g factor parameter valueerror raised following error message somewhat confusing scenario factor negative value got describe expected behavior valueerror raised appropriate error message something like factor greater got standalone code reproduce issue random contrast layer tf kera layer experimental preprocessing randomcontrast,2020-05-29 02:42:14,1590720134,resolved fixed,25213f58c433d3712931b4071d2498bb67f8c2ca,1591039308,tensorflow\python\keras\layers\preprocessing\image_preprocessing.py                                                            
239,40050,Unclear shape dependency of `value` in  `tf.keras.backend.moving_average_update` documentation,url issue description issue need changing clear description unclear shape dependency input value according document value shape variable unclear variable parameters defined yes returns defined yes raises listed defined,2020-06-01 14:37:30,1591022250,resolved fixed,cd3ed4fe8cfa83418ff5937cb52560013667cba4,1591220469,tensorflow\python\keras\backend.py                                                            
240,40103,Unclear type/dimension dependency of `filters` in  `conv1d/3d_transpose` documentation,url issue description issue need changing clear description unclear type dimension dependency input filter according document filter type value channel dimension must match value unclear value parameters defined yes returns defined yes raises listed defined yes raises list provided defined system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos mojave tensorflow installed source binary binary tensorflow version use command rc3 python version,2020-06-03 01:55:34,1591149334,resolved fixed,cef0c8cf713a718c01dd3da582c94d4e09a54753,1591594794,tensorflow\python\ops\nn_ops.py                                                            
241,40328,Subclassed model with ConvLSTM2D layer can't be saved as a SavedModel in TF2.2,system information written custom code opposed using stock example script provided tensorflow custom code extended example tf guide os platform distribution e g linux ubuntu ubuntu mac os mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior header state model build subclassing api convlstm2d layer inside saved savedmodel given kera h5 model format support saving subclassed model left option save model architecture file issue appears tf2 seems bug earlier version describe expected behavior code work without issue tf2 tf2 standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached import numpy np import tensorflow tf print tf version tensorflow import kera tensorflow kera layer import convlstm2d bidirectional lstm class custommodel kera model def init self hidden unit super custommodel self init self lstm bidirectional convlstm2d filter kernel size return sequence true return state true self dense layer kera layer dense u u hidden unit def call self input training none mask none x input x self lstm x layer self dense layer x layer x return x model custommodel build model calling input arr tf random uniform output model predict input arr model save model delete custom defined model class ensure loader access del custommodel loaded kera model load model model similar issue discussed stackoverflow,2020-06-09 18:21:05,1591726865,resolved fixed,47582983cb1064b5bb81233db4f0adeeaa10b74d,1592502041,tensorflow\python\keras\saving\saved_model\layer_serialization.py tensorflow\python\keras\saving\saved_model\saved_model_test.py                                                          
242,40839,"tf.io.decode_image(img, channels=3) outputs 4 channels when reading 4-channel BMP",attached sample bmp file rgb32 zip system information written custom code opposed using stock example script provided tensorflow os platform distribution windows tensorflow installed source binary binary pip tensorflow version python version describe current behavior reading channel bmp tf io decode image img channel give shape instead tf io decode bmp img channel give following error traceback recent call last file channel py line loop file channel py line loop img tf io decode bmp img channel file c users mattchee miniconda3 lib site package tensorflow python ops gen image ops py line decode bmp ops raise ok status e name file c users mattchee miniconda3 lib site package tensorflow python framework ops py line raise ok status six raise core status exception e code message none file line raise tensorflow python framework error impl invalidargumenterror channel attribute match bit per pixel file op decodebmp following guide load image efficiently option describe expected behavior inconsistent tf io decode image img channel tf io decode png img channel give shape reading channel png tf io decode image img channel tf io decode bmp img channel would expected give shape reading channel bmp standalone code reproduce issue img tf io read file img path img tf io decode image img channel print img shape print img tf io read file img path img tf io decode bmp img channel error print img shape,2020-06-26 16:24:28,1593188668,resolved fixed,0859ec0386ffa55739cbe831f38942c53027c12f,1594057842,tensorflow\core\BUILD tensorflow\core\kernels\decode_image_op.cc tensorflow\core\lib\bmp\testdata\grayscale_small.bmp tensorflow\core\lib\bmp\testdata\grayscale_small_3channels.bmp tensorflow\core\lib\bmp\testdata\grayscale_small_4channels.bmp tensorflow\core\lib\bmp\testdata\rgb_small.bmp tensorflow\core\lib\bmp\testdata\rgb_small_255.bmp tensorflow\core\lib\bmp\testdata\rgba_small.bmp tensorflow\core\lib\bmp\testdata\rgba_small_255.bmp tensorflow\python\ops\image_ops_impl.py tensorflow\python\ops\image_ops_test.py                                        
243,4084,Process hanging when using TF_SessionRun with multiple times the same input,seems input appears multiple time input argument tf sessionrun c api h tf sessionrun call never return issue reproduced modifying c api test cc replacing line csession setinputs feed int32tensor csession setinputs feed int32tensor feed int32tensor according gdb process waiting mutex runstate destructor directsession related github issue stackoverflow thread found searching web problem none environment info operating system linux installed version cuda cudnn none installed source provide commit hash git rev parse head output bazel version build label build target bazel local fastbuild bin src main java com google devtools build lib bazel bazelserver deploy jar build time fri jul build timestamp build timestamp int possible provide minimal reproducible example usually time read hundred line code see attempted solution tried logs output would helpful log large please upload attachment provide link,2016-08-28 20:58:19,1472417899,resolved fixed,c35e69c56941d79163dc9f054f57c199b1a4cc44,1472689875,tensorflow\core\common_runtime\direct_session_test.cc tensorflow\core\graph\subgraph.cc                                                          
244,40895,nested gradients for convolution layer fail under tf.function,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary pip tf nightly tensorflow version use command v1 gcbb94efa58 dev20200628 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory geforce gtx ti max q gb describe current behavior code work eager mode fails following error using tf function traceback recent call last file bugreport py line value func x file home abdo tmp venv lib python3 site package tensorflow python eager def function py line call result self call args kwds file home abdo tmp venv lib python3 site package tensorflow python eager def function py line call self initialize args kwds add initializers initializers file home abdo tmp venv lib python3 site package tensorflow python eager def function py line initialize args kwds file home abdo tmp venv lib python3 site package tensorflow python eager function py line get concrete function internal garbage collected graph function self maybe define function args kwargs file home abdo tmp venv lib python3 site package tensorflow python eager function py line maybe define function graph function self create graph function args kwargs file home abdo tmp venv lib python3 site package tensorflow python eager function py line create graph function capture value self capture value file home abdo tmp venv lib python3 site package tensorflow python framework func graph py line func graph py func func output python func func args func kwargs file home abdo tmp venv lib python3 site package tensorflow python eager def function py line wrapped fn return weak wrapped fn wrapped args kwds file bugreport py line func grad tape gradient loss variable file home abdo tmp venv lib python3 site package tensorflow python eager backprop py line gradient unconnected gradient unconnected gradient file home abdo tmp venv lib python3 site package tensorflow python eager imperative grad py line imperative grad compat str unconnected gradient value file home abdo tmp venv lib python3 site package tensorflow python eager backprop py line gradient function return grad fn mock op grad file home abdo tmp venv lib python3 site package tensorflow python ops nn grad py line conv2dbackpropinputgrad stride op get attr stride file home abdo tmp venv lib python3 site package tensorflow python eager backprop py line get attr raise keyerror attr keyerror stride describe expected behavior would expect code work eager mode wrapped tf function standalone code reproduce issue import tensorflow tf shape init tf random normal shape shape dtype tf float32 weight tf variable initial value init trainable true shape shape dtype tf float32 def conv x kernel tf reshape tf eye dtype x dtype shape x tf reshape x shape x tf nn conv2d x kernel stride padding data format nchw x tf reshape x shape w tf reshape weight shape w tf transpose w perm w tf reshape w shape tf linalg matmul w x transpose true tf reshape shape tf square return def func flat x flat x unflat tf reshape x flat shape tf gradienttape tape tape watch x unflat conv x unflat u tf reduce sum axis u tf reshape u shape jac tape batch jacobian u x unflat return jac variable weight tf function autograph false def func x tf gradienttape tape tape watch weight flat func flat x loss tf reduce sum tf square flat grad tape gradient loss variable return tf reduce sum grad x tf random normal shape dtype tf float32 value func x print value info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-06-28 17:24:03,1593365043,resolved fixed,3d1f1b062dafc5cea4561d0a48538c60aef5aa5e,1604103429,tensorflow\python\eager\backprop_test.py tensorflow\python\ops\parallel_for\pfor.py                                                          
245,41270,"GPU delegate library is libtensorflowlite_gpu_delegate.so, not libtensorflowlite_gpu_gl.so.",thank submitting tensorflow documentation issue per github policy address code doc bug performance issue feature request build installation issue github tensorflow doc open source get involved read documentation contributor guide url issue please provide link documentation entry example description issue need changing bazel build c opt config android arm64 tensorflow lite delegate gpu gl delegate static library bazel build c opt config android arm64 tensorflow lite delegate gpu libtensorflowlite gpu gl dynamic library changed bazel build c opt config android arm64 tensorflow lite delegate gpu delegate static library bazel build c opt config android arm64 tensorflow lite delegate gpu libtensorflowlite gpu delegate dynamic library gl delegate gpu delegate runtime library opengl delegate right clear description example someone use method useful correct link link source code correct parameters defined parameter defined formatted correctly returns defined return value defined raises listed defined error defined example usage example usage example see api guide write testable usage example request visuals applicable currently visuals clarify content submit pull request planning also submit pull request fix issue see doc contributor guide doc api guide doc style guide,2020-07-10 08:43:59,1594370639,resolved fixed,052d45f39a62f4684801ca29ad6b6a593ce4a8fa,1594700626,tensorflow\lite\g3doc\performance\gpu_advanced.md                                                            
246,4131,reduce_max and maximum give different results for negative infinity,using tf maximum negative inf input follows tf maximum math inf math inf eval give expected result inf however tf reduce max input tf reduce max math inf math inf eval give min float32 positive infinity input function result inf related github issue stackoverflow thread found searching web problem posted question first environment info operating system ubuntu installed version cuda cudnn rw r r root root may usr local cuda lib64 libcudadevrt lrwxrwxrwx root root may usr local cuda lib64 libcudart libcudart lrwxrwxrwx root root may usr local cuda lib64 libcudart libcudart rw r r root root may usr local cuda lib64 libcudart rw r r root root may usr local cuda lib64 libcudart static lrwxrwxrwx root root jul usr local cuda lib64 libcudnn libcudnn lrwxrwxrwx root root jul usr local cuda lib64 libcudnn libcudnn rwxr xr x root root jul usr local cuda lib64 libcudnn rw r r root root jul usr local cuda lib64 libcudnn static installed source commit hash bazel build label build target bazel local fastbuild bin src main java com google devtools build lib bazel bazelserver deploy jar build time fri jun build timestamp build timestamp int,2016-08-31 17:26:25,1472664385,resolved fixed,fadc1f3c869c15b1890221bb6dfb0f7bd0f7c23d,1472858263,tensorflow\core\kernels\constant_op_gpu.cu.cc tensorflow\workspace.bzl                                                          
247,41674,TensorFlow Lite for Microcontrollers sigaborts with a MobileNetV2 alpha=0.1 model,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu macos linux gcc compiler version compiling source apple clang version clang c describe current behavior using tensorflow lite microcontrollers commit trained two mobilenetv2 model keras input size single input channel converted int8 quantized attempting run model using tensorflow lite microcontrollers x86 built clang macos gcc ubuntu first model mobilenetv2 filter scaling factor model run perfectly second model scaling factor model sigaborts invoke call strangely model run perfectly executed openmv h7 arm cortex m7 smaller model run perfectly h7 might worth noting openmv device model stored dynamic memory said tried declaring model without static x86 impact attached zip containing model file plus example program exhibit sigabort build run example empty input make f makefile tflite build edge impulse standalone within example code call invoke line edge impulse sdk classifier ei run classifier h switch model sigabort replace tflite model model parameter edge impulse sdk directory version contained within grayscale zip describe expected behavior model run successfully x86 standalone code reproduce issue example code example standalone inferencing zip model file located model zip,2020-07-23 20:04:14,1595534654,resolved fixed,dd918be82cb9702cc9ca022179629fbd8c6d3ed9,1595636078,tensorflow\lite\kernels\internal\reference\integer_ops\add.h                                                            
248,41712,"Conv1DTranspose Dilation support - Might be a bug, IDK.",thank submitting tensorflow documentation issue per github policy address code doc bug performance issue feature request build installation issue github tensorflow doc open source get involved read documentation contributor guide url issue please provide link documentation entry example description issue need changing conv1dtranspose dilation inform us dilation work value dilation implemented yet clear description currently documentation say integer specifying dilation rate use dilated convolution currently specifying dilation rate value incompatible specifying stride value may implemented yet newest nightly build tf nightly build work fear updating new nightly build case break research code relies nightly build conv1dtranspose released supported build invalidargumenterror current libxsmm customized cpu implementation yet support dilation rate larger node test1 ae decoder conv1d transpose conv1d transpose defined users username desktop libs python nn4n autoencoder4 py op inference train function function call stack train function stride correct link parameters defined yes setting dilation get rid issue returns defined necessary sure asking define return code code return defined value documentation claim return something raises listed defined invalidargumenterror current libxsmm customized cpu implementation yet support dilation rate larger node test1 ae decoder conv1d transpose conv1d transpose defined users username desktop libs python nn4n autoencoder4 py op inference train function function call stack train function usage example nightly build request visuals applicable submit pull request test code note built tf nightly removed pypi archive unknown reason note model fit must called error occur simpy constructing compiling network enough reproduce error import tensorflow tf import tensorflow kera kr import numpy np train data np random uniform input kr input x input x kr layer conv1d stride padding dilation rate activation relu x x kr layer flatten x x kr layer dense activation relu x x kr layer dense activation relu x x kr layer dense activation relu x x kr layer dense activation relu x x kr layer reshape target shape x x kr layer conv1dtranspose stride dilation rate padding activation relu output padding x output kr layer flatten x model kr model input output name test model compile optimizer adam loss mse model summary model fit train data train data,2020-07-24 21:08:42,1595624922,resolved fixed,75801da4cd321aabbf79e78da1e5de1a10ba4c2a,1595875715,tensorflow\python\keras\layers\convolutional.py                                                            
249,42217,Typo in TFLite CoreML framework build command example,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary tensorflow version use command python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior single typo build command example tensorflow tensorflow lite experimental io build apple lines bazel build c opt config io fat tensorflow lite experimental io tensorflowliteccoreml framework tflite io static framework name tensorflowliteccoreml framework hdrs coreml delegate h allowlist symbol file allowlist tensorflowliteccoreml txt bundle name tensorflowliteccoreml minimum o version tfl minimum os version deps tensorflow lite experimental delegate coreml coreml delegate introduce bazel build fails newbie error skipping tensorflow lite experimental io tensorflowliteccoreml framework target tensorflow lite experimental io tensorflowliteccoreml framework target tensorflowliteccoreml framework declared package tensorflow lite experimental io mean tensorflowliteccoreml framework defined users mumu hpcnt tensorflow tensorflow lite experimental io build warning target pattern parsing failed error target tensorflow lite experimental io tensorflowliteccoreml framework target tensorflowliteccoreml framework declared package tensorflow lite experimental io mean tensorflowliteccoreml framework defined users mumu hpcnt tensorflow tensorflow lite experimental io build info elapsed time info process failed build complete successfully package loaded describe expected behavior line tensorflowliteccoreml framework fixed tensorflowliteccoreml framework standalone code reproduce issue info log include log source code would helpful,2020-08-11 04:00:22,1597118422,resolved fixed,916bd91c2bc1ded18ca460520e922a71c3033418,1597206254,tensorflow\lite\experimental\ios\BUILD.apple                                                            
250,42281,tf.nn.ctc_beam_search_decoder crashes(bad_alloc) when top_paths is large,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior tf nn ctc beam search decoder crash bad alloc top path extremely large describe expected behavior expect crash standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf tf nn ctc beam search decoder input tf one sequence length top path info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached std bad alloc aborted core dumped,2020-08-12 20:06:58,1597262818,resolved fixed,7bd42cf6ba061ba7c06c072c9d962abe331461eb,1603757914,tensorflow\core\framework\node_def_util.cc tensorflow\core\framework\node_def_util_test.cc tensorflow\python\eager\pywrap_tfe_src.cc tensorflow\python\eager\pywrap_tfe_test.py tensorflow\python\tfe_wrapper.cc                                                    
251,42331,tf.nest.flatten crashes (abort) when expand_composites's constraints are violated,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device n tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source n gcc compiler version compiling source n cuda cudnn version n gpu model memory n collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior tf nest flatten crash abort expand composite boolean violated describe expected behavior expect crash standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf import numpy np tf nest flatten structure np zero expand composite tf one info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached terminate called throwing instance pybind11 error already set systemerror returned result error set root miniconda3 lib python3 site package numpy core arrayprint py array repr implementation root miniconda3 lib python3 site package tensorflow python util nest py flatten aborted core dumped,2020-08-13 19:11:01,1597345861,resolved fixed,35c2a97ddca6da7d5a21d5ee3e2869eec68299f9,1598036412,tensorflow\python\util\nest.py                                                            
252,42364,`tf.data.experimental.snapshot()` hangs when using GCS paths,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu debian stretch mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command python version bazel version compiling source na gcc compiler version compiling source na cuda cudnn version cuda gpu model memory nvidia tesla t4 collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior tf data experimental snapshot hang using google storage path describe expected behavior tf data experimental snapshot work standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf tf data dataset range apply tf data experimental snapshot g bucket path break hang using local path tf data dataset range apply tf data experimental snapshot g bucket deleteme break work expected info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-08-14 12:52:54,1597409574,resolved fixed,532966cad34471bded2b0483737e8e8d23bc4720,1598997099,tensorflow\core\kernels\data\experimental\snapshot_dataset_op.cc tensorflow\core\platform\cloud\gcs_file_system.cc tensorflow\core\platform\cloud\gcs_file_system_test.cc                                                        
253,42386,GradientTape.gradient needs to check target type.,tensorflow tensorflow python eager backprop py line b36436b target list nested structure tensors variables recently wrote code simple tape gradient loss model trainable variable raise typeerror convert value none tensorflow dtype turn custom loss function returning none yes know dumb check related tensorflow code line find dumb problem suggest type checking block inside code think suggestion helpful fool like thanks advance,2020-08-15 06:55:39,1597474539,resolved fixed,f25125e50bab365642335413356466883bf7f361,1609701163,tensorflow\python\eager\backprop.py                                                            
254,42458,CosineSimilarity documentation range incorrect,url issue description issue need changing clear description note negative quantity changed note negative quantity correct link parameters defined returns defined raises listed defined usage example request visuals applicable submit pull request plan submit pull request,2020-08-18 12:08:10,1597752490,resolved fixed,7e7641d95c6c9b7e46b129c10ec7a965fb2f848d,1597814448,tensorflow\python\keras\losses.py                                                            
255,43449,tf.autodiff.ForwardAccumulator fails for Embedding layer,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu windows mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary pip tensorflow version use command dev20200813 python version bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory geforce gtx collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior calculating jacobian vector product embedding layer produce attributeerror indexedslices object attribute tf output describe expected behavior error like dense lstm convolutional layer see notebook link show error related embedding layer standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook import tensorflow tf class rnn model tf kera model def init self super rnn model self init self embed tf kera layer embedding self d2 tf kera layer dense self tf constant initialize tf function def call self x x self embed x return self d2 x model rnn model v tf one w shape w model trainable variable tf autodiff forwardaccumulator primals model trainable variable tangent v acc loss tf reduce sum tf constant model tf constant training true acc jvp loss see complete example notebook info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-09-22 04:59:17,1600750757,resolved fixed,79fce11a6cc8c3d9fd85e9a04b596fd4ea4d7b79,1600824361,tensorflow\python\eager\forwardprop_test.py tensorflow\python\eager\function.py tensorflow\python\keras\integration_test\forwardprop_test.py                                                        
256,43529,'tf.TensorScatterUpdate' Conversion to tflite,system information os platform distribution e g linux ubuntu window tensorflow installed source binary python binary tensorflow version github sha source provide text output tflite convert error tf tensorscatterupdate op neither custom op flex op im already using tf ops copy paste standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook also please include link graphdef model possible info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-09-24 08:14:32,1600935272,resolved fixed,8dbab4f830b2f77199c22e7c1763bea8e523079b,1600997356,tensorflow\lite\delegates\flex\allowlisted_flex_ops.cc                                                            
257,4358,Wrong example script in the docs for preprocessing data,reading doc preprocessing small paragraph linking cifar network example however script perform preprocessing better example illustrating preprocessing step like data normalization distorting image etc,2016-09-13 17:59:22,1473789562,resolved fixed,345132fb42c05807206e892a3cb497c0bcd58af1,1474328257,tensorflow\g3doc\how_tos\reading_data\index.md                                                            
258,4361,Update tf.contrib.layers.batch_norm() docs,tensorflow version use pip package took heavy use tf contrib layer batch norm last week facing problem use correctly figured many devs confused well would suggest following improvement make clear update example doc string example tell case use update collection default include update ops tf get collection tf graphkeys update ops update ops update tf group update ops total loss control flow ops dependency update total loss actually working deprecated throw error instead tiny change would suggest update doc follows tensorflow python import control flow ops update ops tf get collection tf graphkeys update ops update ops update tf tuple update ops total loss control flow ops dependency update total loss side question apply total loss train op directly described doc string text added dependency total loss work grouping train op would make example clear opinion batch statistic update training update ops combination reuse varscope related question let say model reuses convolutional encoder also batch norm layer several time even reuse layer update operation batch statistic added update ops nevertheless personally sure bug really done required filter update ops collecting update ops tf get collection tf graphkeys update ops one executed sum wrong line executed reuse true changing reuse collect update computed later ops add collection update collection update moving mean ops add collection update collection update moving variance case using conv lstm conv tp architecture reuse conv conv tp timestep increase number timesteps lstm number update ops increase proportionally number model parameter stay constant get reused currently getting update ops calling tf get collection tf graphkeys update ops performance feel super slow use batch norm guess high number update ops right handling training parameter seen lot example people something like code handle training parameter def batch norm layer x train phase scope bn bn train batch norm x decay center true scale true update collection none training true bn inference batch norm x decay center true scale true update collection none training false bn tf cond train phase lambda bn train lambda bn inference return bn far know really required past training boolean since param bool tensor well required anymore since many devs still ding workaound added comment doc string required anymore could helpful usage multi gpu configuration optimize code multi gpu system cifar10 example number update ops increase factor num gpus might related b use tf contrib batch norm within multi gpu system get error like invalidargumenterror assign device node tower inference convstack x bn moment sufficient statistic sparsetodense could satisfy explicit device specification device gpu supported kernel gpu device available hence wrap evey batch norm call tf device cpu guess might bad impact performance right thanks ps sorry case question would fit better stackoverflow combination suggested improvement question let know,2016-09-13 18:43:34,1473792214,resolved fixed,a6e6d0aa2cad5e1d50b4f5cbed427a5df9267098,1474067794,tensorflow\contrib\layers\python\layers\layers.py                                                            
259,43781,[MLIR] TFlite contains unused file,tensorflow compiler mlir lite transforms load quantization recipe cc called via tf opt allow unregistered dialect tfl load recipe filecheck however according commit allow unregistered dialect disabled way call file deprecated hence removed involved mlir tfl pass,2020-10-05 07:35:40,1601883340,resolved fixed,1831af3c012643a5d61012bf71b653e075dcfd22,1601941598,tensorflow\compiler\mlir\lite\BUILD                                                            
260,43816,"TypeError in ""Bidirectional.compute_output_shape""",hello analyzing tensorflow sonarcloud saw look like error tensorflow python kera layer wrapper py see issue sonarcloud reviewing code indeed see state shape type tuple using operator list tuple fail exception typeerror concatenate list tuple list flow lead issue output shape tuple output shape list output shape tuple self return state state shape output shape state shape tuple return output shape state shape copy copy state shape expression output shape state shape fail case question suggestion see false positive sonarcloud reach sonarsource community forum note case want use sonarcloud currently testing python analyzer project sonarcloud show python issue sonarcloud also analyze c c code language sonarcloud also import pylint issue case want use rule sonarcloud already provide note however pylint rule sonarcloud rule implemented differently might see new issue sonarcloud le issue case try avoid false positives much possible free open source project,2020-10-06 12:19:08,1601986748,resolved fixed,5a8b0d3e80cef5ffba362d747a0f449c90862b5d,1606761729,tensorflow\python\keras\layers\wrappers.py tensorflow\python\keras\layers\wrappers_test.py                                                          
261,43998,Update BatchNormalization documentation,thank submitting tensorflow documentation issue per github policy address code doc bug performance issue feature request build installation issue github tensorflow doc open source get involved read documentation contributor guide url issue description issue need changing clear description document mention axis take list integer integer tested already implemented tensorflow aware used reshape transpose inefficient correct link link source code correct parameters defined parameter defined formatted correctly axis list integer returns defined return value defined raises listed defined error defined example usage example usage example see api guide write testable usage example request visuals applicable currently visuals clarify content submit pull request planning also submit pull request fix issue see doc contributor guide doc api guide doc style guide,2020-10-14 06:43:09,1602657789,resolved fixed,9318f787e6d33adabc5c1b18c6663d1432f646f9,1602713980,tensorflow\python\keras\layers\normalization.py                                                            
262,44011,ops defined inside tf.while_loop's cond/body or tf.cond's true_fn/false_fn functions ignore their enclosed tf.device if the tf.while_loop/tf.cond itself is inside a tf.device,please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu macos catalina mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary binary tensorflow version use command v2 rc2 gb36436b087 python version python bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory collect information using environment capture script also obtain tensorflow version tf python c import tensorflow tf print tf git version tf version tf python c import tensorflow tf print tf version git version tf version version describe current behavior tf print print specified device using tf device inside loop graph mode initially though autograph issue trace graph inspect tensorboard color device graph printv2 placed supposed sure happening yet verify happens across ops tf print waiting team let know check next describe expected behavior tf print print specified device using tf device everything work fine using tf loop instead seen sample code standalone code reproduce issue provide reproducible test case bare minimum necessary generate problem possible please share link colab jupyter notebook snippet correct anymore please read couple comments import tensorflow tf assume tf distribute server running rpi local tf config experimental connect cluster tf train clusterspec worker dhruvins macbook air local rpi local job name worker task index laptop job worker task rpi job worker task tf function def test tf device rpi tf range tf print rpi tf device laptop tf print laptop tf function def test def cond return def body tf device rpi tf print rpi tf device laptop tf print laptop return tf loop cond body parallel iteration test test info log include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached,2020-10-14 12:46:16,1602679576,resolved fixed,1ce28a3f8a7670eda543176c7fe3a78b5db11a1e,1608080341,tensorflow\core\common_runtime\function_test.cc tensorflow\core\common_runtime\inline_function_utils.cc tensorflow\python\kernel_tests\cond_v2_test.py                                                        
263,44278,Unexpected `snapshot` behaviour with `flat_map` in tf-nightly,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary pip tensorflow version use command dev20201023 python version describe current behavior dataset formed flat mapping multiple snapshotted datasets iterated individually thus producing file disk result dataset seemingly use file disk different behaviour cache tf tf nightly snapshot tf describe expected behavior snapshot work equivalently tf nightly similarly cache colab import o tempfile import temporarydirectory import numpy np import tensorflow tf def numpy d tf data dataset return np array x numpy x d def get data num repeat snap false preprocess early false preprocess late false del rng false get numpy result data pipeline pipeline look like range add stateful random noise create num repeat cache snapshot ted version flat map num repeat args num repeat number duplicate created step snap use snapshot otherwise use cache preprocess early true iterate individually cached snapshotted datasets prior flat mapping preprocess late true iterate flat map ped dataset del rng true delete rng responsible generating random noise step cause error map function called rather using cached snapshotted file disk returns two iteration repeated dataset rng tf random generator seed dataset tf data dataset range map lambda x tf cast x tf float32 rng uniform temporarydirectory tmp dir path o path join tmp dir f repeat range num repeat snap datasets dataset apply tf data experimental snapshot path path path else datasets dataset cache path path path preprocess early iterate datasets individually force saving file d datasets numpy d num repeat dataset datasets else dataset tf data dataset tensor slice datasets flat map lambda x x preprocess late iterate concatenated dataset force saving file numpy dataset del rng cause error original mapped dataset called del rng return numpy dataset numpy dataset class snapshottest tf test testcase def test consistent self base0 base1 get data np testing assert equal base0 base1 def test reproducible self base0 get data s0 s1 get data np testing assert equal s0 s1 np testing assert equal s0 base0 def test snapshot self base0 get data s0 s1 get data snap true np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess late self base0 get data s0 s1 get data snap true preprocess late true np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess late del rng self base0 get data s0 s1 get data snap true preprocess late true del rng true np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess early self base0 get data s0 s1 get data snap true preprocess early true np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess early del rng self base0 get data s0 s1 get data snap true preprocess early true del rng true np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess repeat self preprocess early equivalent preprocess late base0 get data num repeat s0 s1 get data snap true preprocess early true num repeat np testing assert equal s0 s1 np testing assert equal s0 base0 def test preprocess del rng repeat self preprocess early equivalent preprocess late base0 get data num repeat s0 s1 get data snap true preprocess early true num repeat del rng true np testing assert equal s0 s1 np testing assert equal s0 base0 name main tf test main info log failed test output error test preprocess early del rng main snapshottest snapshottest test preprocess early del rng traceback recent call last file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python eager context py line execution mode yield file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python data ops iterator ops py line next internal output shape self flat output shape file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python ops gen dataset ops py line iterator get next ops raise ok status e name file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python framework ops py line raise ok status six raise core status exception e code message none file line raise tensorflow python framework error impl notfounderror resource localhost anonymousvar6 n10tensorflow3vare exist node stateful uniform statefuluniform op iteratorgetnext handling exception another exception occurred traceback recent call last file foob py line test preprocess early del rng s0 s1 get data snap true preprocess early true del rng true file foob py line get data return numpy dataset numpy dataset file foob py line numpy return np array x numpy x d file foob py line return np array x numpy x d file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python data ops iterator ops py line next return self next internal file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python data ops iterator ops py line next internal return structure compatible tensor list self element spec ret file home jackd anaconda3 envs tf nightly lib python3 contextlib py line exit self gen throw type value traceback file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python eager context py line execution mode executor new wait file home jackd anaconda3 envs tf nightly lib python3 site package tensorflow python eager executor py line wait pywrap tfe tfe executorwaitforallpendingnodes self handle tensorflow python framework error impl notfounderror resource localhost anonymousvar6 n10tensorflow3vare exist node stateful uniform statefuluniform fail test preprocess early main snapshottest snapshottest test preprocess early traceback recent call last file foob py line test preprocess early np testing assert equal s0 base0 file home jackd anaconda3 envs tf nightly lib python3 site package numpy testing private utils py line assert equal return assert array equal actual desired err msg verbose file home jackd anaconda3 envs tf nightly lib python3 site package numpy testing private utils py line assert array equal verbose verbose header arrays equal file home jackd anaconda3 envs tf nightly lib python3 site package numpy testing private utils py line assert array compare raise assertionerror msg assertionerror arrays equal mismatched element max absolute difference max relative difference x array dtype float32 array dtype float32 ran test failed failure error skipped,2020-10-24 03:59:35,1603511975,resolved fixed,cbc7f31b7d6aac81158be084201d3b3e8e346907,1604433587,tensorflow\core\kernels\data\experimental\snapshot_dataset_op.cc tensorflow\core\kernels\data\experimental\snapshot_dataset_op.h tensorflow\core\ops\experimental_dataset_ops.cc tensorflow\python\data\experimental\kernel_tests\snapshot_test.py tensorflow\tools\api\golden\v1\tensorflow.raw_ops.pbtxt tensorflow\tools\api\golden\v2\tensorflow.raw_ops.pbtxt                                                  
264,44646,Bug when a custom tf.keras.models.Model has multiple class inheritance,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu windows linux ubuntu tensorflow installed source binary pip tensorflow version use command python version conda env python cuda cudnn version gpu model memory geforce rtx super max q design describe current behavior creating custom model inherit least one class tf kera model model following exception raised file c users snake miniconda3 envs transformer lib site package tensorflow python training tracking base py line method wrapper result method self args kwargs file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line init inject functional model class self class file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line inject functional model class cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line inject functional model class cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line inject functional model class cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line cl base tuple inject functional model class base file c users snake miniconda3 envs transformer lib site package tensorflow python kera engine training py line inject functional model class cl base tuple inject functional model class base typeerror set attribute built extension type object describe expected behavior able create custom model different mixins standalone code reproduce issue simple piece code reproduce issue import tensorflow tf class printmixin def custom print self print hello world class custommodel tf kera model model printmixin def init self args kwargs input tf kera layer input shape dense tf kera layer dense activation relu output dense input output output output super init input input output output args kwargs model custommodel info log apparently giving input output parameter tensorflow try inject attribute class super class reaching tf kera model model piece code file training py line def inject functional model class cl inject functional hierarchy class needed tensorflow python kera engine import functional pylint disable g import top tensorflow python kera engine import training v1 pylint disable g import top cl model cl training v1 model return functional functional cl base tuple inject functional model class base base cl base trigger new class swapping needed happen functional functional class hierarchy cl new cl return cl try check superclass mixin class object error raised saying add attribute object type following update method fix issue def inject functional model class cl inject functional hierarchy class needed tensorflow python kera engine import functional pylint disable g import top tensorflow python kera engine import training v1 pylint disable g import top cl model cl training v1 model return functional functional cl object return cl cl base tuple inject functional model class base base cl base trigger new class swapping needed happen functional functional class hierarchy cl new cl return cl return object class know proper fix bring another error elsewhere first wanted know really bug could proper custom model mixin class input output yes fix proposed ok needed open pr thanks,2020-11-06 12:26:32,1604665592,resolved fixed,8f68aad1107df679843da96a990773e9fc30201c,1605831670,tensorflow\python\keras\engine\functional_test.py tensorflow\python\keras\engine\training.py                                                          
265,44983,tf.image.per_image_standardization unexpected behavior with unsigned integer input,system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu linux ubuntu tensorflow installed source binary pip tensorflow version use command v2 g25fba035f3 python version cuda cudnn version gpu model memory nvidia tesla v100 dgxs describe current behavior tf image per image standardization special handling unsigned integer still convert back unsigned returning thus uint input get saturated zero fully half data maximum value currently explanation uint behavior given docstring warning indication behavior might unexpected shown describe expected behavior previous version tensorflow believe changed per image standardization returned float rather converting back original datatype problem would expect something safe like leaving developer decide want conversion handled least warning printed event uint input given documentation specifying uints handled differently saturated might nice colab notebook link info log tracebacks log throw error would call failure mode fails silently suspect edge case tested,2020-11-18 15:52:14,1605714734,resolved fixed,b6be9714e878a7dd0d1405bd7a83e021ba4b561a,1608498939,tensorflow\python\ops\image_ops_impl.py tensorflow\python\ops\image_ops_test.py                                                          
266,45054,"Concatenating sparse keras input layers results in None shape, preventing use in Dense layer",system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu colab mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary colab tensorflow version use command python version bazel version compiling source none gcc compiler version compiling source none cuda cudnn version none gpu model memory none describe current behavior using keras functional api concatenating together multiple instance tensorflow kera layer input sparse true resulting sparsetensor none shape even batch size specified feeding merged layer shape none dense layer result error valueerror last dimension input dense defined found none describe expected behavior concatenating non sparse instance tensorflow kera layer input e sparse false result tensor defined shape batch size specified fed dense layer successfully additionally single sparse input layer shape fed dense layer would expect concatenated sparse input layer act similarly dense shape merged sparse tensor already known set shape individual input layer standalone code reproduce issue sp tf kera layer input shape batch size sparse true sp b tf kera layer input shape batch size sparse true sp merged tf kera layer concatenate input sp sp b axis print sp merged shape print none none sp result tf kera layer dense activation relu name dense1 sp merged fails valueerror also tried concatenating tf kera layer concatenate tf sparse concat instead result reproduced success non sparse input failure sparse input case colab,2020-11-21 02:00:20,1605924020,resolved fixed,8438d59abbd7a2c3d1c48bfd91b118aae53bbb14,1610050649,tensorflow\python\keras\layers\BUILD tensorflow\python\keras\layers\merge_test.py tensorflow\python\ops\sparse_ops.py tensorflow\python\ops\sparse_ops_test.py                                                      
267,45113,Documentation for using a private CocoaPod spec for TensorFlow Lite is not correct,url issue description issue need changing clear description documentation linked say change following line tensorflowlitec podspec file source http file asks follow instruction creating private cocoapod repo use pod project guide asks run following pod repo push tfliteswift tensorflowlitec podspec get error message podspec line error installing tensorflowlitec tensorflowlitec error ios unknown encountered unknown error usr local anaconda3 bin curl f l var folder wwtlv8lx0m5fmhc3hy5w5 d20201123 file zip file tensorflow bazel bin tensorflow lite experimental io tensorflowlitec framework zip create dirs netrc optional retry cocoapods cocoapods downloader curl url using bad illegal format missing url believe http file line make sense specifying local file path http key clearly http url therefore believe documentation incorrect incomplete yet get app compiling custom build tensorflowlite know solution help appreciated,2020-11-23 18:35:07,1606156507,resolved fixed,cfe685d8127222d01125893909be092b4dd7ae89,1606309270,tensorflow\lite\g3doc\guide\build_ios.md                                                            
268,45195,//tensorflow/lite/python:lite_v2_test failed,current master branch commit test tensorflow lite python lite v2 test failed bazelisk test tensorflow lite python lite v2 test error mirror tensorflow tensorflow lite python build deps attribute py test rule tensorflow lite python lite v2 test tenso rflow lite kernel hashtable hashtable op kernel mandatory provider py pyinfo error analysis target tensorflow lite python lite v2 test failed build aborted analysis target tensorflow lite python lite v2 test failed,2020-11-26 07:49:51,1606376991,resolved fixed,077fe29d9d1f2149dd8c74bcd2f99de7b5fd1506,1607038987,tensorflow\lite\kernels\hashtable\BUILD tensorflow\lite\kernels\hashtable\hashtable_ops_wrapper.cc tensorflow\lite\python\BUILD tensorflow\lite\python\lite_v2_test.py                                                      
269,45243,tf.keras.applications.mobilenet_v3.preprocess_input documentation not according source code,said preprocessed numpy array tf tensor type float32 input pixel value scaled sample wise however source code github find kera export kera application mobilenet v3 preprocess input def preprocess input x data format none pylint disable unused argument return x check notebook see source code state nothing scale change dtype float32 input,2020-11-28 09:54:36,1606557276,resolved fixed,52cdef300393aa1e2a4220030f77839edbae8bd3,1607458341,tensorflow\python\keras\applications\mobilenet_v3.py                                                            
270,45662,Wrong device returned for GPUCompatibleFIFOQueueTests.testEnqueueDequeue test,system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu centos tensorflow installed source binary source tensorflow version use command python version bazel version compiling source gcc compiler version compiling source gcc cuda cudnn version gpu model memory v100 describe current behavior tensorflow python kernel test fifo queue test target gpucompatiblefifoqueuetests testenqueuedequeue return wrong device job localhost replica task device cpu v job localhost replica task device gpu see log standalone code reproduce issue run bazel test info log fail testenqueuedequeue main gpucompatiblefifoqueuetests gpucompatiblefifoqueuetests testenqueuedequeue traceback recent call last file tmp bazel tf execroot org tensorflow bazel ppc opt bin tensorflow python kernel test fifo queue test runfiles org tensorflow tensorflow python framework test util py line decorated run eagerly self kwargs file tmp bazel tf execroot org tensorflow bazel ppc opt bin tensorflow python kernel test fifo queue test runfiles org tensorflow tensorflow python framework test util py line run eagerly f self args kwargs file tmp bazel tf execroot org tensorflow bazel ppc opt bin tensorflow python kernel test fifo queue test runfiles org tensorflow tensorflow python kernel test fifo queue test py line testenqueuedequeue self assertequal elems device dequeued tensor device assertionerror job localhost replica task device cpu job localhost replica task device gpu,2020-12-14 17:00:46,1607965246,resolved fixed,671c78343c3427858bd5674baab80c3c8c429815,1609885398,tensorflow\python\kernel_tests\fifo_queue_test.py                                                            
271,45894,tf.data.experimental.assert_cardinality incompatible with INFINITE_CARDINALITY,system information written custom code yes os platform distribution ubuntu tensorflow installed binary tensorflow version v1 gec43aacb56f dev20201219 python version describe current behavior tf data experimental assert cardinality used fix dataset cardinality instance inferred situation cardinality infinite raise error describe expected behavior d d base apply tf data experimental assert cardinality tf data infinite cardinality error raised d base stop producing element opposed first element produced notebook code notebook import tensorflow tf d tf data dataset range repeat flat map lambda tf data dataset range print d cardinality tf data infinite cardinality false d d apply tf data experimental assert cardinality tf data infinite cardinality print d cardinality tf data infinite cardinality true example d take pas tensorflow python framework error impl failedpreconditionerror input dataset expected contain element contained least element,2020-12-21 00:47:02,1608511622,resolved fixed,59f5abfbc8dc5559c361f80f4fa4a006db825e40,1609189795,tensorflow\core\kernels\data\experimental\assert_cardinality_dataset_op.cc tensorflow\python\data\experimental\kernel_tests\assert_cardinality_test.py                                                          
272,46020,Common location for portable bash helper functions / aliases,tensorflow micro pr fix use compatible mac already using additional place get merged would better common location helper function alias imagine collecting common helper script example micro tool bash helper sh something like uname uname uname linux alias tflm md5sum md5sum else uname darwin alias tflm md5sum md5 r fi would need change different download script determine directory script life something like tensorflow tensorflow lite micro tool ci build test bluepill sh lines script dir cd dirname bash source pwd root dir script dir cd root dir source tensorflow lite micro tool bash helper sh,2020-12-28 21:50:28,1609192228,resolved fixed,c5ce162da8efb465e2ba8a8825049614813892a9,1609918407,tensorflow\lite\micro\tools\make\bash_helpers.sh tensorflow\lite\micro\tools\make\ext_libs\cmsis_download.sh tensorflow\lite\micro\tools\make\ext_libs\cmsis_nn.inc tensorflow\lite\micro\tools\make\flatbuffers_download.sh tensorflow\lite\micro\tools\make\renode_download.sh tensorflow\lite\micro\tools\make\targets\apollo3evb_makefile.inc tensorflow\lite\micro\tools\make\targets\bluepill_makefile.inc tensorflow\lite\micro\tools\make\targets\stm32f4_makefile.inc tensorflow\lite\micro\tools\make\third_party_downloads.inc                                            
273,46128,"This throws ERROR: features = tf.io.parse_example(..., features=make_parse_example_spec(columns))",please make sure bug per github policy address code doc bug performance issue feature request build installation issue github tag bug template system information written custom code opposed using stock example script provided tensorflow os platform distribution e g linux ubuntu mobile device e g iphone pixel samsung galaxy issue happens mobile device tensorflow installed source binary source tensorflow version use command latest week python version x bazel version compiling source gcc compiler version compiling source cuda cudnn version gpu model memory describe current behavior trying code throw exception valueerror attempt convert value ellipsis unsupported type tensor full code page behavior cell feature column may depend whether training inference mode e g applying dropout training true rating sequence numeric column rating watch sequence categorical column identity watch num bucket watch embedding embedding column watch dimension column rating watch embedding sequence input layer sequencefeatures column feature tf io parse example feature make parse example spec column sequence input sequence length sequence input layer feature training training sequence length mask tf sequence mask sequence length rnn cell tf kera layer simplernncell hidden size training training rnn layer tf kera layer rnn rnn cell training training output state rnn layer sequence input mask sequence length mask,2021-01-04 05:04:06,1609736646,resolved fixed,2cc955f533a9ba70512cf4a07024aaf65708e103,1610993694,tensorflow\python\keras\feature_column\sequence_feature_column.py                                                            
274,46423,writer_test of serialization failed for squeeznet,system information os platform distribution linux ubuntu tensorflow installed source tensorflow version use command python version python bazel version compiling source build label gcc compiler version compiling source gcc ubuntu describe current behavior download squeezenet squeezenet tflit build write test serialization bazel build c opt tensorflow lite tool serialization writer test bazel bin tensorflow lite tool serialization writer test model folder squeezenet tflite error tensorflow lite kernel reshape cc num input element num output element error node number reshape failed prepare allocatetensors failed round tripped model describe expected behavior pas write test standalone code reproduce issue download squeezenet squeezenet tflit build write test serialization bazel build c opt tensorflow lite tool serialization writer test bazel bin tensorflow lite tool serialization writer test model folder squeezenet tflite info log include log source code would helpful error tensorflow lite kernel reshape cc num input element num output element error node number reshape failed prepare allocatetensors failed round tripped model proposal fix,2021-01-14 08:38:05,1610613485,resolved fixed,f12082d7af509e9549d8e8fb2b514ccd0db0e84e,1610678871,tensorflow\lite\tools\serialization\option_writer_generator.cc tensorflow\lite\tools\serialization\writer_lib_test.cc                                                          
275,4861,Example mnist_rnn Not Working with Docker Image,issue example mnist rnn run docker image importerror traceback recent call last future import print function sklearn import metric preprocessing import tensorflow tf importerror module named sklearn related github issue stackoverflow thread found searching web problem example code base work docker image opinion filer example run without need configuration docker image project control installed docker image environment info operating system docker run p gcr io tensorflow tensorflow installed version cuda cudnn none cpu based container installed binary pip package provide output python c import tensorflow print tensorflow version python c import tensorflow print tensorflow version installed source provide installed source possible provide minimal reproducible example usually time read hundred line code example given beginning ticket attempted solution tried removed reference sklearn application work useful scale ensure stochastic gradient descent right thing scaler preprocessing standardscaler x train scaler fit transform x train x test scaler fit transform x test logs output would helpful log produced,2016-10-09 18:36:02,1476038162,resolved fixed,7c79d528f43c69b6719da0c7846cd3aa56df57ef,1476396393,tensorflow\tools\docker\Dockerfile tensorflow\tools\docker\Dockerfile.devel tensorflow\tools\docker\Dockerfile.gpu                                                        
276,5115,timeout breaks FIFOQueue,ubuntu lts using timeout notebook useful case dequeue empty queue enqueue full one problem timeout occurs enqueue dequeueop throw error import tensorflow tf tf device cpu ph tf placeholder tf float32 q tf fifoqueue tf float32 enq q enqueue ph deq q dequeue timeout option tf runoptions timeout m sess tf session sess run deq option timeout option get usual timeout error problem run sess run enq feed dict ph option timeout option get error cancellederror traceback recent call last sess run q option timeout option usr local lib python2 dist package tensorflow python client session pyc run self fetch feed dict option run metadata try result self run none fetch feed dict option ptr run metadata ptr run metadata proto data tf session tf getbuffer run metadata ptr usr local lib python2 dist package tensorflow python client session pyc run self handle fetch feed dict option run metadata final fetch final target result self run handle final target final fetch feed dict string option run metadata else result usr local lib python2 dist package tensorflow python client session pyc run self handle target list fetch list feed dict option run metadata handle none return self call run fn self session feed dict fetch list target list option run metadata else return self call prun fn self session handle feed dict usr local lib python2 dist package tensorflow python client session pyc call self fn args except keyerror pas raise type e node def op message def extend graph self cancellederror dequeue operation cancelled node fifo queue dequeue queuedequeue class loc fifo queue component type dt float dt int64 dt float timeout m device job localhost replica task cpu fifo queue node placeholderwithdefault recv client terminated false recv device job localhost replica task gpu send device job localhost replica task cpu send device incarnation tensor name edge placeholderwithdefault tensor type dt float device job localhost replica task gpu caused op u fifo queue dequeue defined file line file home cgel local lib python2 site package ipython kernel zmq kernelapp py line main app start file home cgel local lib python2 site package ipython kernel zmq kernelapp py line start ioloop ioloop instance start file usr lib python2 dist package zmq eventloop ioloop py line start super zmqioloop self start file home cgel local lib python2 site package tornado ioloop py line start handler func fd obj event file home cgel local lib python2 site package tornado stack context py line null wrapper return fn args kwargs file usr lib python2 dist package zmq eventloop zmqstream py line handle event self handle recv file usr lib python2 dist package zmq eventloop zmqstream py line handle recv self run callback callback msg file usr lib python2 dist package zmq eventloop zmqstream py line run callback callback args kwargs file home cgel local lib python2 site package tornado stack context py line null wrapper return fn args kwargs file home cgel local lib python2 site package ipython kernel zmq ipkernel py line dispatcher return self dispatch shell stream msg file home cgel local lib python2 site package ipython kernel zmq ipkernel py line dispatch shell handler stream idents msg file home cgel local lib python2 site package ipython kernel zmq ipkernel py line execute request shell run cell code store history store history silent silent file home cgel local lib python2 site package ipython core interactiveshell py line run cell interactivity interactivity compiler compiler file home cgel local lib python2 site package ipython core interactiveshell py line run ast node self run code code file home cgel local lib python2 site package ipython core interactiveshell py line run code exec code obj self user global n self user n file line input state action q dequeue file usr local lib python2 dist package tensorflow python ops data flow ops py line dequeue self queue ref self dtypes name name file usr local lib python2 dist package tensorflow python ops gen data flow ops py line queue dequeue timeout m timeout m name name file usr local lib python2 dist package tensorflow python framework op def library py line apply op op def op def file usr local lib python2 dist package tensorflow python framework ops py line create op original op self default original op op def op def file usr local lib python2 dist package tensorflow python framework ops py line init self traceback extract stack,2016-10-21 13:48:48,1477057728,resolved fixed,f46fe646a26f0514fdfbfcea3882fd0120f24388,1478728132,tensorflow\core\common_runtime\direct_session.cc tensorflow\core\common_runtime\direct_session.h tensorflow\python\kernel_tests\fifo_queue_test.py                                                        
277,5380,'tensorflow/core/public/session.h' file not found,find anything problem creating python package source bazel command used official guide section create pip package file whl generated working include file use new op created c missing file session option h session h however present official whl tensorflow download binary package pre compiled add file insert requirement tensorflow core build tensorflow core build file changed insertion diff git tensorflow core build b tensorflow core build index tensorflow core build b tensorflow core build cc library platform strong hash h platform thread annotation h platform type h public version h public session h public session option h visibility visibility public deps tf cuda library framework type trait h framework type h public version h public session h public session option h util bcast h util cuda kernel helper h util device name utils h normal missed configuration building could fix without addition environment info operating system macos sierra installed version cuda cudnn cuda source commit hash eaa9dde98d95f843ad1d3d0f5956693991372e4a bazel version build label homebrew build target bazel local opt bin src main java com google devtools build lib bazel bazelserver deploy jar build time sat oct build timestamp build timestamp int example test try import graph see guide need require header logs output would helpful fatal error tensorflow core public session h file found include tensorflow core public session h error generated make error,2016-11-03 15:25:32,1478186732,resolved fixed,b725df4aaf4fde1139f7204bae31650a25348e0f,1478202319,tensorflow\tools\pip_package\BUILD                                                            
278,5543,Constant folding doesn't remove control edges,believe constant folding take place section graph replaced constant data output edge replaced node removed believe see graph node ending div part gradient generation bit replaced const output div go mul changed new const correctly however control output div going const sure changed div replacement consequently dead node pruning remove original div trace constant folding graph node edge graph constant graph node edge constant foldable replacing name gradient mean grad truediv id op device job localhost replica task device ipu def gradient mean grad truediv div dt float device job localhost replica task device ipu gradient mean grad tile gradient mean grad cast constant replacing edge gradient square grad mul post constant folding pruning pruneforreversereachability gradient square grad mul gradient mean grad truediv cf pruneforreversereachability gradient square grad mul x gradient mean grad truediv pruning graph constfolding node edge graph passed device contains node gradient square grad mul x constdtype dt float value tensor device job localhost replica task device ipu,2016-11-11 11:50:59,1478865059,resolved fixed,73bc428901dfd6507bbea1315c8813f2048233ff,1484517706,tensorflow\core\common_runtime\simple_placer.cc tensorflow\core\common_runtime\simple_placer_test.cc                                                          
279,5652,cifar10_multi_gpu_train.py breaks with more than 1 GPU,environment info operating system ubuntu installed version cuda cudnn commit hash git rev parse head output bazel version build label build target bazel local fastbuild bin src main java com google devtools build lib bazel bazelserver deploy jar build time fri oct build timestamp build timestamp int possible provide minimal reproducible example usually time read hundred line code python cifar10 multi gpu train py num gpus cifar10 train py cifar10 multi gpu train py without specifying num gpus running single gpu work logs output would helpful tensorflow stream executor dso loader cc successfully opened cuda library libcublas locally tensorflow stream executor dso loader cc successfully opened cuda library libcudnn locally tensorflow stream executor dso loader cc successfully opened cuda library libcufft locally tensorflow stream executor dso loader cc successfully opened cuda library libcuda locally tensorflow stream executor dso loader cc successfully opened cuda library libcurand locally filling queue cifar image starting train take minute filling queue cifar image starting train take minute traceback recent call last file cifar10 multi gpu train py line tf app run file data github tensorflow python build tensorflow python platform app py line run sys exit main sys argv flag passthrough file cifar10 multi gpu train py line main train file cifar10 multi gpu train py line train loss tower loss scope file cifar10 multi gpu train py line tower loss loss average op loss average apply loss total loss file data github tensorflow python build tensorflow python training moving average py line apply self average var var decay zero debias zero debias file data github tensorflow python build tensorflow python training moving average py line assign moving average update delta zero debias variable value decay file data github tensorflow python build tensorflow python training moving average py line zero debias trainable false file data github tensorflow python build tensorflow python ops variable scope py line get variable custom getter custom getter file data github tensorflow python build tensorflow python ops variable scope py line get variable custom getter custom getter file data github tensorflow python build tensorflow python ops variable scope py line get variable validate shape validate shape file data github tensorflow python build tensorflow python ops variable scope py line true getter caching device caching device validate shape validate shape file data github tensorflow python build tensorflow python ops variable scope py line get single variable varscope name valueerror variable tower tower conv1 weight loss avg biased exist created tf get variable mean set reuse none varscope,2016-11-16 23:32:51,1479339171,resolved fixed,1b531b9d88361a3b8506399d5edae155125c5371,1479503250,tensorflow\models\image\cifar10\cifar10_multi_gpu_train.py                                                            
280,6602,fatal error: tensorflow/stream_executor/lib/status.h: No such file or directory,try write op installed tensorflow gpu support linux code fails include tensorflow core platform stream executor h error fatal error tensorflow stream executor lib status h file directory file exists include file seem missing grepping devicememory include path file find include tensorflow core util stream executor util h,2017-01-02 16:04:51,1483373091,resolved fixed,02d2385b8c33e89b53e49bc89e646b54de920bad,1483572522,tensorflow\tools\pip_package\setup.py                                                            
281,6717,Incorrect gradient for categorical distribution entropy,categorical distribution class provides awesome entropy operator apparently gradient calculation w r input operator work logits tf variable initial value probability tf nn softmax logits log probability tf nn log softmax logits entropy tf reduce sum probability log probability axis using actual distribution would nicer gradient seem buggy categorical distribution tf contrib distribution categorical p probability categorical distribution entropy categorical distribution entropy initialize init tf global variable initializer sess tf session sess run init work print sess run entropy print sess run tf gradient entropy logits apparently loses gradient information print sess run categorical distribution entropy print sess run tf gradient categorical distribution entropy logits output see entropy calculation work gradient somehow lost obviously also work try maximize entropy using optimizer array dtype float32 array dtype float32,2017-01-08 00:29:44,1483835384,resolved fixed,b39773478542bf812a12715f7f753f9a88e5e86c,1484783431,tensorflow\contrib\distributions\python\kernel_tests\categorical_test.py tensorflow\contrib\distributions\python\ops\categorical.py                                                          
282,6738,How to train Multibox object detector included in the TF Detect Android demo,way train custom model multibox object detector included tf detect android demo,2017-01-09 12:01:43,1483963303,resolved fixed,53aabd5cb0ffcc1fd33cbd00eb468dd8d8353df2,1502328124,WORKSPACE tensorflow\core\framework\register_types.h tensorflow\examples\android\BUILD tensorflow\examples\android\README.md tensorflow\examples\android\download-models.gradle tensorflow\examples\android\src\org\tensorflow\demo\DetectorActivity.java tensorflow\examples\android\src\org\tensorflow\demo\TensorFlowMultiBoxDetector.java tensorflow\examples\android\src\org\tensorflow\demo\TensorFlowObjectDetectionAPIModel.java tensorflow\examples\android\src\org\tensorflow\demo\tracking\MultiBoxTracker.java                                            
283,6766,"softmax_cross_entropy_with_logits aborts the process, if a tensor with zero first dimension is passed as an argument",environment info operating system ubuntu installed version cuda cudnn cuda cudnn tensorflow version installed reproduced also using tf cuda cudnn minimal reproducible example import tensorflow tf tf placeholder int64 none one hot tf one hot ce tf nn softmax cross entropy logits one hot one hot sess tf session sess run ce result gpu e tensorflow core common runtime bfc allocator cc tried allocate byte w tensorflow core common runtime allocator retry cc request allocate byte f tensorflow core common runtime gpu gpu device cc eigenallocator gpu ran memory allocating see error log detailed info aborted core dumped result cpu array dtype float32,2017-01-10 12:06:06,1484049966,resolved fixed,07e6ca0ac7cdfcb6105fb3410fc68355c04df1d5,1516741960,tensorflow\core\kernels\xent_op.cc tensorflow\python\kernel_tests\xent_op_test.py                                                          
284,6823,Upgrade HighwayHash,highwayhash module downloaded external dependency tensorflow produce different hash result big endian little endian architecture cause test fail big endian raising issue highwayhash community added change make hash value consistent across architecture commit possible pick higher commit highwayhash tensorflow,2017-01-13 08:40:52,1484296852,resolved fixed,6ed5eaaac13540c1b9d5a7549b2c82aac91ba318,1485370128,tensorflow\workspace.bzl third_party\highwayhash.BUILD                                                          
285,7025,"Getting ""Dst tensor is not initialized."" when really the problem is out of GPU memory",stack trace sometimes get trying use tensorflow gpu occupied another process would help debugging error said something memory zheng xq tf version g27fca7d dirty nightly last week w tensorflow core platform cpu feature guard cc tensorflow library compiled use sse4 instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use avx instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use avx2 instruction available machine could speed cpu computation w tensorflow core platform cpu feature guard cc tensorflow library compiled use fma instruction available machine could speed cpu computation tensorflow core common runtime gpu gpu device cc found device property name titan x pascal major minor memoryclockrate ghz pcibusid total memory free memory tensorflow core common runtime gpu gpu device cc dma tensorflow core common runtime gpu gpu device cc tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name titan x pascal pci bus id traceback recent call last file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line call return fn args file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line run fn status run metadata file home yaroslav conda envs tim jan17 lib python3 contextlib py line exit next self gen file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python framework error impl py line raise exception ok status pywrap tensorflow tf getcode status tensorflow python framework error impl internalerror dst tensor initialized node zero const dtype dt float value tensor device job localhost replica task gpu handling exception another exception occurred traceback recent call last file memory test py line profile densenet false file memory test py line profile densenet sess run net initializer net x init trainx init batch size file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line run run metadata ptr file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line run feed dict string option run metadata file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line run target list option run metadata file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl internalerror dst tensor initialized node zero const dtype dt float value tensor device job localhost replica task gpu caused op zero defined file memory test py line profile densenet false file memory test py line profile densenet net densenet lib densenet init batch size batch size layer per block filter per layer save memory save memory file home yaroslav openai git densenet densenet py line densenet optimizer nn adamax update params loss lr tf lr file home yaroslav openai git densenet nn py line adamax update mg tf variable tf zero int shape p p name adamax mg file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python ops array ops py line zero output constant zero shape shape dtype dtype name name file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python framework constant op py line constant attrs value tensor value dtype dtype value name name output file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python framework ops py line create op original op self default original op op def op def file home yaroslav conda envs tim jan17 lib python3 site package tensorflow python framework ops py line init self traceback extract stack internalerror see traceback dst tensor initialized node zero const dtype dt float value tensor device job localhost replica task gpu,2017-01-23 23:39:53,1485214793,resolved fixed,0a9b39caefd437fec742ae48b25061abd6e2699b,1493427864,tensorflow\core\common_runtime\gpu\gpu_device.cc                                                            
286,7065,pytorch 2.5x faster on VGG16,related github issue stackoverflow thread found searching web problem started told post post environment info operating system ubuntu maxwell titan x installed version cuda cudnn cuda cudnn l l usr local cuda lib64 libcud rw r r root root jan usr local cuda lib64 libcudadevrt lrwxrwxrwx root root jan usr local cuda lib64 libcudart libcudart lrwxrwxrwx root root jan usr local cuda lib64 libcudart libcudart rwxr xr x root root jan usr local cuda lib64 libcudart rw r r root root jan usr local cuda lib64 libcudart static lrwxrwxrwx user jul usr local cuda lib64 libcudnn libcudnn lrwxrwxrwx user jul usr local cuda lib64 libcudnn libcudnn rwxrwxr x user jul usr local cuda lib64 libcudnn rw rw r user jul usr local cuda lib64 libcudnn static installed binary pip package anaconda distribution output python c import tensorflow print tensorflow version tensorflow stream executor dso loader cc successfully opened cuda library libcublas locally tensorflow stream executor dso loader cc successfully opened cuda library libcudnn locally tensorflow stream executor dso loader cc successfully opened cuda library libcufft locally tensorflow stream executor dso loader cc successfully opened cuda library libcuda locally tensorflow stream executor dso loader cc successfully opened cuda library libcurand locally possible provide minimal reproducible example usually time read hundred line code using following code forward pas pretrained vgg16 import tensorflow tf tensorflow contrib import slim tensorflow contrib slim import net tf reset default graph use rng avoid feed dict argument input image tf random uniform maxval preds net vgg vgg input image training false saver tf train saver config tf configproto log device placement true sess tf interactivesession config config saver restore sess vgg ckpt jupyter notebook magic timeit sess run preds compared pytorch version machine import numpy np import torch import torchvision model model torch autograd import variable torch backends cudnn benchmark true net model vgg16 net cuda variable torch numpy np random randn astype np float32 cuda jupyter notebook magic timeit net get following result comparing framework surprisingly small difference complicated resnet get huge gap vgg16 architecture almost us convolution model tf pytorch vgg16 resnet,2017-01-25 18:40:58,1485369658,resolved fixed,0318cf082ee88ff0e226a5bf7da0487f44d82182,1485809353,tensorflow\core\kernels\conv_grad_filter_ops.cc tensorflow\core\kernels\conv_grad_input_ops.cc tensorflow\core\kernels\conv_grad_ops_3d.cc tensorflow\core\kernels\conv_ops.cc tensorflow\core\kernels\conv_ops_3d.cc tensorflow\core\kernels\conv_ops_using_gemm.cc tensorflow\python\kernel_tests\conv_ops_3d_test.py tensorflow\python\kernel_tests\conv_ops_test.py                                              
287,7077,TensorBoard ImportError: No module named werkzeug,using current head tensorflow bumped issue execute tensorboard version reported head git rev parse head a12c7dc linux linux tensor generic ubuntu smp fri dec utc x86 x86 x86 gnu linux tensorflow stream executor dso loader cc successfully opened cuda library libcudnn locally tensorflow stream executor dso loader cc successfully opened cuda library libcufft locally tensorflow stream executor dso loader cc successfully opened cuda library libcuda locally tensorflow stream executor dso loader cc successfully opened cuda library libcurand locally traceback recent call last file usr local bin tensorboard line load entry point tensorflow console script tensorboard file home greg local lib python2 site package pkg resource init py line load entry point return get distribution dist load entry point group name file home greg local lib python2 site package pkg resource init py line load entry point return ep load file home greg local lib python2 site package pkg resource init py line load return self resolve file home greg local lib python2 site package pkg resource init py line resolve module import self module name fromlist name level file home greg tensorflow python build tensorflow tensorboard tensorboard py line werkzeug import serving importerror module named werkzeug see werkzeug build file system sure found,2017-01-25 22:09:43,1485382183,resolved fixed,bc72653cf7968115fe9f714d7d2bc63004524479,1485491819,tensorflow\g3doc\get_started\os_setup.md                                                            
288,7088,Running optimized graph with two output nodes on android gives Session was not created with a graph before Run() error.,hi please would please kind help one issue prevents moving forward graph two output layer final result orig basically coming form retraining example final result added custom layer unable strip optimize inference order run android device pc run fine run bazel bin tensorflow python tool optimize inference input tmp output pb output tmp optimized pb input name mul output name final result orig final result added android application get session created graph run error final result orig final result added found run bazel bin tensorflow python tool optimize inference input tmp output pb output tmp optimized pb input name mul output name final result orig work fine final result orig available work correctly however final result added obviously found available app use run bazel bin tensorflow python tool optimize inference input tmp output pb output tmp optimized pb input name mul output name final result added work well session created graph run error final result orig final result added found understand wrong could wrong final result added work fine pc android thank much related github issue stackoverflow thread found searching web problem environment info ubuntu android,2017-01-26 10:34:02,1485426842,resolved fixed,c3df5d40ef8240ede980ccb740d6af87837d8eef,1485558751,tensorflow\core\kernels\BUILD                                                            
289,7186,missing fclose,contrib pi example label image label image cc line missing fclose infile,2017-02-01 10:55:36,1485946536,resolved fixed,82a0f347baf7284345cbf9e830310604da9b1b73,1487267452,tensorflow\contrib\pi_examples\label_image\label_image.cc                                                            
290,7300,"API documentation ""Core graph data structures""",thing wrong documentation around near end tf graph name scope line valueerror incomplete paragraph end tf graph name scope tf graph add collection tf graph add collection tf graph add collection plural exist,2017-02-06 19:49:07,1486410547,resolved fixed,dfe3bb7cdc888767c2fff32efea405c8d6aa5c88,1486511163,tensorflow\python\framework\ops.py                                                            
291,7404,No attribute 'outer_context' when calculating gradient from imported graph,seems import graph loop calculate gradient could original graph e g import tensorflow tf tf constant name input tf loop lambda tf le lambda tf add name output graph def tf get default graph graph def g tf graph g default tf import graph def graph def tf session graph g imported g get tensor name import input imported g get tensor name import output exit tf gradient imported imported attributeerror traceback recent call last tf gradient imported imported users malmaud anaconda lib python2 site package tensorflow python ops gradient impl pyc gradient y x grad y name colocate gradient ops gate gradient aggregation method pending count loop state pendingcount ops get default graph ops ops colocate gradient ops iterate collected ops users malmaud anaconda lib python2 site package tensorflow python ops gradient impl pyc pendingcount graph ops ops colocate gradient ops loop state none loop loop state control flow ops maybecreatecontrolflowstate op list ops colocate gradient ops initialize pending count ops users malmaud anaconda lib python2 site package tensorflow python ops control flow ops pyc maybecreatecontrolflowstate op list ops colocate gradient ops loop state addwhilecontext op op list ops else loop state addwhilecontext op op list ops return loop state users malmaud anaconda lib python2 site package tensorflow python ops control flow ops pyc addwhilecontext self op op list ops grad state none new loop create grad state outer forward ctxt forward ctxt outer context outer forward ctxt outer forward ctxt outer forward ctxt getwhilecontext attributeerror nonetype object attribute outer context,2017-02-10 03:14:10,1486696450,resolved fixed,1d7c2fa60f717dea7239970d96f7d4bf96842039,1522347115,tensorflow\python\ops\control_flow_ops.py                                                            
292,7406,Should check whether n_class is zero before calling sample_n() in mixture.py,problem description mixture model first use categorical sample much sample need mixture component variable line actually mean pas problem could pas used beta distribution see line mixture py possible provide minimal reproducible example usually time read hundred line code easy reproduce create mixture beta uniform probability half time sample uniform half time sample beta usr bin python import tensorflow tf d tf contrib distribution create mixture distribution beta uniform component d beta d uniform b cat d categorical p mix d mixture cat cat component component get sample x mix sample n tf session sess sess run tf global variable initializer repeat crash range print sess run x attempted solution tried two possible solution add conditional branch mixture py like tested script instead sample class c self component c sample n n class seed seed sample class c control flow ops cond math ops equal n class lambda array ops zero self component c dtype lambda self component c sample n n class seed seed create zero tensor shape n class let reshape operator line worry shape support shape random gamma shape alpha personally think bad idea already caused invalidargumenterror exception mean one implemented might already considered problem logs output would helpful log large please upload attachment provide link tensorflow stream executor dso loader cc successfully opened cuda library libcublas locally tensorflow stream executor dso loader cc successfully opened cuda library libcudnn locally tensorflow stream executor dso loader cc successfully opened cuda library libcufft locally tensorflow stream executor dso loader cc successfully opened cuda library libcuda locally tensorflow stream executor dso loader cc successfully opened cuda library libcurand locally tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name titan x pascal major minor memoryclockrate ghz pcibusid total memory free memory w tensorflow stream executor cuda cuda driver cc creating context one currently active existing tensorflow stream executor cuda cuda gpu executor cc successful numa node read sysfs negative value must least one numa node returning numa node zero tensorflow core common runtime gpu gpu device cc found device property name geforce gtx ti major minor memoryclockrate ghz pcibusid total memory free memory tensorflow core common runtime gpu gpu device cc peer access supported device ordinal tensorflow core common runtime gpu gpu device cc peer access supported device ordinal tensorflow core common runtime gpu gpu device cc dma tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc n tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name titan x pascal pci bus id tensorflow core common runtime gpu gpu device cc creating tensorflow device gpu device name geforce gtx ti pci bus id w tensorflow core framework op kernel cc invalid argument input shape non zero element count got node beta sample n random gamma randomgamma randomgamma dt int32 dt float seed seed2 device job localhost replica task cpu beta sample n random gamma shape beta sample n random gamma add traceback recent call last file bug py line print sess run x file usr local lib python2 dist package tensorflow python client session py line run run metadata ptr file usr local lib python2 dist package tensorflow python client session py line run feed dict string option run metadata file usr local lib python2 dist package tensorflow python client session py line run target list option run metadata file usr local lib python2 dist package tensorflow python client session py line call raise type e node def op message tensorflow python framework error impl invalidargumenterror input shape non zero element count got node beta sample n random gamma randomgamma randomgamma dt int32 dt float seed seed2 device job localhost replica task cpu beta sample n random gamma shape beta sample n random gamma add caused op u beta sample n random gamma randomgamma defined file bug py line x mix sample n file usr local lib python2 dist package tensorflow contrib distribution python ops distribution py line sample n x self sample n n seed condition kwargs file usr local lib python2 dist package tensorflow contrib distribution python ops mixture py line sample n sample class c self component c sample n n class seed seed file usr local lib python2 dist package tensorflow contrib distribution python ops distribution py line sample n x self sample n n seed condition kwargs file usr local lib python2 dist package tensorflow contrib distribution python ops beta py line sample n seed distribution util gen new seed seed beta file usr local lib python2 dist package tensorflow python ops random ops py line random gamma seed2 seed2 beta file usr local lib python2 dist package tensorflow python ops gen random ops py line random gamma seed seed seed2 seed2 name name file usr local lib python2 dist package tensorflow python framework op def library py line apply op op def op def file usr local lib python2 dist package tensorflow python framework ops py line create op original op self default original op op def op def file usr local lib python2 dist package tensorflow python framework ops py line init self traceback extract stack invalidargumenterror see traceback input shape non zero element count got node beta sample n random gamma randomgamma randomgamma dt int32 dt float seed seed2 device job localhost replica task cpu beta sample n random gamma shape beta sample n random gamma add p variable name n class confused,2017-02-10 04:31:14,1486701074,resolved fixed,3116fa80450735e907907bc57a6834e9e212570a,1490201654,tensorflow\core\kernels\random_op.cc                                                            
293,7906,Erroneous number of channels in the Guide to TF Layers tutorial.,tutorial guide tf layers building convolutional neural network seems wrong number channel tensor dimension given end paragraph convolutional layer output tensor produced conv2d shape batch size width height dimension input channel holding output filter consistent rest tutorial probably say shape batch size since rightmost dimension denotes number channel,2017-02-26 22:21:45,1488147705,resolved fixed,4e63540076921d2c08d03aa9efb76fd483920593,1488336551,tensorflow\docs_src\tutorials\layers.md                                                            
294,8011,TypeError: Fetch argument None has invalid type &lt;class 'NoneType'&gt;,feature request better error description better summary handling following code work fine summary defined ops ops tf summary merge session run ops however summary get typeerror fetch argument none invalid type really saying one session run ops empty forbidden alternatively let merge return noop summary,2017-03-02 13:59:38,1488463178,resolved fixed,cffd79f4b102c2082cbcc258abf7ed06df8c141c,1512159736,tensorflow\core\kernels\slice_op.cc tensorflow\core\kernels\slice_op.h tensorflow\core\kernels\slice_op_gpu.cu.cc tensorflow\core\kernels\strided_slice_op_impl.h tensorflow\core\kernels\strided_slice_op_test.cc tensorflow\python\kernel_tests\slice_op_test.py                                                  
295,8364,Documentation formatting broken,see source code formatting leak general text returns raises get folded parameter either doc generator need understand python doc comment better doc comment need updated work better markdown extra newlines etc think thanks andreas,2017-03-13 17:27:43,1489426063,resolved fixed,4b86783ac6c3af9c35d3af36d4db0e9bc11f21c0,1490231267,tensorflow\contrib\copy_graph\python\util\copy_elements.py tensorflow\tools\docs\parser.py                                                          
296,8718,Incorrect reference for tf.learn in Linear Model tutorials,page mention multiple time however looking link source code believe actually either guess tf learn old name got renamed tutorial still outdated,2017-03-25 18:04:17,1490465057,resolved fixed,4f52ce514bc83c5adbfdcd8a342a0fa0f42e55d0,1497372380,tensorflow\docs_src\tutorials\linear.md tensorflow\docs_src\tutorials\wide.md tensorflow\docs_src\tutorials\wide_and_deep.md                                                        
297,8809,an update for the tf.contrib.learn Quickstart example is needed,hi tried start script found one issue python3 user import urllib raw urllib urlopen iris training url read return attributeerror traceback recent call last raw urllib urlopen iris training url read attributeerror module urllib attribute urlopen solution import urllib request ur raw ur urlopen iris training url read main reason issue ticket warning message like warning tensorflow users vadimborisov anaconda lib python3 site package tensorflow contrib learn python learn estimator head py scalar summary tensorflow python ops logging ops deprecated removed instructions updating please switch tf summary scalar note tf summary scalar us node name instead tag mean tensorflow automatically de duplicate summary name based scope created also passing tensor list tag scalar summary op longer supported warning tensorflow calling baseestimator fit tensorflow contrib learn python learn estimator estimator x deprecated removed instructions updating estimator decoupled scikit learn interface moving separate class skcompat arguments x batch size available skcompat class estimator accept input fn example conversion est estimator est skcompat estimator warning tensorflow calling baseestimator fit tensorflow contrib learn python learn estimator estimator deprecated removed instructions updating estimator decoupled scikit learn interface moving separate class skcompat arguments x batch size available skcompat class estimator accept input fn example conversion est estimator est skcompat estimator like warning tensorflow users vadimborisov anaconda lib python3 site package tensorflow contrib learn python learn estimator head py scalar summary tensorflow python ops logging ops deprecated removed instructions updating please switch tf summary scalar note tf summary scalar us node name instead tag mean tensorflow automatically de duplicate summary name based scope created also passing tensor list tag scalar summary op longer supported info tensorflow starting evaluation info tensorflow evaluation info tensorflow finished evaluation info tensorflow saving dict global step accuracy auc global step loss warning tensorflow skipping summary global step must float np float32 believe introduction tutorial free warning try fix warning someone interesting using python anaconda x86 default jul,2017-03-29 15:41:30,1490802090,resolved fixed,0c08c585591152046ca1e6781d1f2fa573427dfc,1493400529,tensorflow\docs_src\deploy\distributed.md tensorflow\docs_src\programmers_guide\reading_data.md tensorflow\docs_src\tutorials\deep_cnn.md tensorflow\docs_src\tutorials\word2vec.md                                                      
298,9047,beta2_power is applied incorrectly in Adam optimizer,adam py applyadam op denominator effectively tf sqrt v epsilon tf sqrt beta2 power however appears incorrect per paper correct ema adjustment give tf sqrt v beta2 power epsilon otherwise epsilon large relative tf sqrt v effective epsilon used denominator also scaled correction factor match paper seem right missing something,2017-04-07 16:08:11,1491581291,resolved fixed,1926b9d3b91375f5a4433303a27b49b4da53f64e,1492034693,tensorflow\python\training\adam.py                                                            
299,9089,cpp protobuf instructions out-of-date for MacOS,instructions upgrade cpp protobuf implementation mac work work make tf fails following stacktrace traceback recent call last file kronecker benchmark py line import tensorflow tf file users yaroslav anaconda envs mar1 lib python3 site package tensorflow init py line tensorflow python import file users yaroslav anaconda envs mar1 lib python3 site package tensorflow python init py line tensorflow core framework graph pb2 import file users yaroslav anaconda envs mar1 lib python3 site package tensorflow core framework graph pb2 py line google protobuf import descriptor descriptor file users yaroslav anaconda envs mar1 lib python3 site package google protobuf descriptor py line google protobuf pyext import message importerror dlopen users yaroslav anaconda envs mar1 lib python3 site package google protobuf pyext message cpython darwin library loaded usr local lib libprotobuf dylib referenced users yaroslav anaconda envs mar1 lib python3 site package google protobuf pyext message cpython darwin reason image found work around use older link pip install upgrade check work python c google protobuf internal import api implementation print api implementation default implementation type macos tensorflow latest nightly today installed pip install upgrade,2017-04-09 19:07:13,1491764833,resolved fixed,3dc4907a0d7ae113547fcf716f618e3c8e1b9c77,1491860084,tensorflow\docs_src\install\install_mac.md                                                            
300,9103,BUG: tensorflow.placeholder shape does not serialize with protobuf,profobuf serialization json attr dtype type dt float shape shape name x op placeholder tensorflow code x tf placeholder tf float32 shape none name x,2017-04-10 13:04:15,1491829455,resolved fixed,24a95ae389e1c76e771ac33d66e0ec40a236260f,1491868229,tensorflow\cc\client\client_session_test.cc tensorflow\cc\framework\cc_op_gen.cc tensorflow\core\framework\partial_tensor_shape.cc tensorflow\core\framework\partial_tensor_shape.h tensorflow\core\ops\array_ops.cc tensorflow\core\ops\array_ops_test.cc tensorflow\core\public\version.h tensorflow\python\kernel_tests\constant_op_test.py tensorflow\python\ops\array_ops.py                                            
301,9136,Issues when using Queues + tf.train.Server,note issues bug feature request closed please ask usage question stackoverflow must complete information else issue closed written custom code opposed using stock example script provided tensorflow yes tensorflow installed source binary binary tensorflow version cpu cpu gpu enabled cpu bazel version compiling source cuda cudnn version n gpu model memory n exact command reproduce cf problem reproduced linux various mac os machine describe problem clearly seem experience issue using queue tf train server executed simple python console following script hang import tensorflow tf import time cluster tf train clusterspec cpu1 localhost server tf train server cluster job name cpu1 task index tf graph default graph queue input queue tf train input producer tf constant dtype tf float32 useless variable variable tf variable dtype tf float32 trainable false name variable session queue runner session tf session target server target session run tf global variable initializer tf train start queue runner session print session run variable work print session run tf assign variable also work called directly pause creating running session break time sleep print session run variable retrieving variable still work print session run tf assign variable assigning variable make program hang output hang forever problem vanishes either commenting input queue line writing session tf session instead passing server target problem seems happen variable assignment also saving model using tf train saver save session model instance possibly operation note reading variable work fine example script time sleepcommand simulates pause creating session running set variable effect achieved example splitting session creation running code across two jupyter notebook cell executing whole code one cell work fine source code logs source code reproduce problem displayed attached traceback using gdb show program hanging trying acquire lock tf issue gdb bt txt tf issue gdb stack thread txt,2017-04-11 12:47:39,1491914859,resolved fixed,1f210ad7c2a81fe27196dd1a85c9bb92f19bc94a,1492623098,tensorflow\core\distributed_runtime\master_session.cc tensorflow\core\distributed_runtime\master_session.h tensorflow\python\training\server_lib_test.py                                                        
302,9161,"Hi, I am unable to access the documentation",note issues bug feature request closed please ask usage question stackoverflow must complete information else issue closed written custom code opposed using stock example script provided tensorflow tensorflow installed source binary tensorflow version bazel version compiling source cuda cudnn version gpu model memory exact command reproduce describe problem clearly source code logs include log source code would helpful diagnose problem including tracebacks please include full traceback large log file attached try reproducible test case code bare minimum necessary generate problem,2017-04-12 12:03:39,1491998619,resolved fixed,9cc21f04ed051d6a6d3a21e909aa547110aa8b0d,1492015964,tensorflow\python\debug\examples\README.md                                                            
303,9312,Typo in seq2seq.attention_wrapper.py,hi think small typo contrib seq2seq attention wrapper py would someone like check code url guess rather checked thanks,2017-04-19 13:59:31,1492610371,resolved fixed,0557e8f90c1a2f027f4561c70558c6c836138058,1492660603,tensorflow\contrib\seq2seq\python\ops\attention_wrapper.py                                                            
304,9633,SIGSEGV with sparse_add and broadcasting,system information written custom code opposed using stock example script provided tensorflow yes enclosed os platform distribution e g linux ubuntu ubuntu tensorflow installed source binary binary via pip tensorflow version use command v1 g4763edf dirty bazel version compiling source n using pip installation cuda cudnn version n cpu gpu model memory none exact command reproduce future import print function import numpy np import tensorflow tf dense sz dense tf constant shape dense sz dtype tf float32 sparse sz nnz nz ind np random choice np prod sparse sz size nnz replace false nz ind np unravel index nz ind dims sparse sz nz ind np array nz ind assert np nz ind np array sparse sz none ensure canonical ordering ind np lexsort nz ind flatten reversed range nz ind shape nz ind nz ind ind print nz ind n nz ind sparse plc tf sparse placeholder tf float32 sparse sum tf sparse add dense sparse plc init tf global variable initializer tf session sess sess run init print init re sess run sparse sum feed dict sparse plc tf sparsetensorvalue nz ind np one nnz sparse sz print sum n re describe problem running code result init process finished exit code interrupted signal sigsegv lower value nnz nnz finish fine quite often init sum process finished exit code source code log see,2017-05-03 15:49:22,1493826562,resolved fixed,50b836addfed6b49fc823987e9301f1b6eeef90c,1493926204,tensorflow\core\kernels\sparse_tensor_dense_add_op.cc tensorflow\python\ops\sparse_ops.py                                                          
305,9931,Go: SIGSEGV when using int32 instead of int64 and missing error in Resize functions,problem go operation cause sigsegv using int32 instead int64 reason believe happen using float instead double vice versa resize operation define output shape correctly input batch let dimension undefined instead raising error test commented hope enough let understand problem source code log package poc test import fmt tf github com tensorflow tensorflow tensorflow go github com tensorflow tensorflow tensorflow go op testing func testresizewithoutbatchisnosense testing create root scope root op newscope define graph read image content imagepath test jpg content op readfile root subscope readfile op const root subscope filename imagepath decode jpeg value op decodejpeg root subscope decodejpeg content op decodejpegchannels like add noise image like define nose tensor shape image sure image shape fully defined resize resize1 op resizenearestneighbor root subscope resizearea value op const root subscope size int32 int32 int32 size parameter int32 error raised operation sense return instead reason taht resize method requires batch image raise error fmt println shape int32 resize1 shape string dims64 err resize1 shape toslice err nil fmt println dims64 else error error err error expect fully defined shape resize1 shape isfullyspecified error defined shape create batch see thing change batch op expanddims root subscope expand value op const root subscope axis int32 resize1 op resizenearestneighbor root subscope resizearea batch op const root subscope size int32 int32 int32 fmt println shape int32 input batch resize1 shape string dims64 err resize1 shape toslice err nil fmt println dims64 else fmt println error err error thing sense shape defined equal func testresizewithin64shapesigsegvs testing defer func r recover r nil error panic create root scope root op newscope define graph read image content imagepath test jpg content op readfile root subscope readfile op const root subscope filename imagepath decode jpeg value op decodejpeg root subscope decodejpeg content op decodejpegchannels however changing int32 int64 break everyting matter use batch value resize2 op resizearea root subscope resizearea2 value op const root subscope size2 int64 int64 int64 operation cause sigsegv fmt println shape value resize2 shape fmt println shape int64 resize2 shape string short chaning int32 int64 cause sigsegv look like kernel registered handle type bring code mess debug like example add noise image generate set value shape input image using one defined shape batch like use output shape toslice func testgeneratenoisewithint32shape testing defer func r recover r nil error panic create root scope root op newscope define graph read image content imagepath test jpg content op readfile root subscope readfile op const root subscope filename imagepath decode jpeg value op decodejpeg root subscope decodejpeg content op decodejpegchannels batch op expanddims root subscope expand value op const root subscope axis int32 resize1 op resizenearestneighbor root subscope resizearea batch op const root subscope size int32 int32 int32 fmt println shape int32 input batch resize1 shape string dims64 err resize1 shape toslice err nil fmt println dims64 else fmt println error err error dims64 resize1 shape toslice noise op parameterizedtruncatednormal root subscope parameterizedtruncatednormal op const root subscope shape dims64 op const root subscope mean op const root subscope stddev op const root subscope minvals op const root subscope maxvals fmt println noise operation cause sigsegv convert dims64 slice int32 operation work func testgeneratenoisewithint64shape testing create root scope root op newscope define graph read image content imagepath test jpg content op readfile root subscope readfile op const root subscope filename imagepath decode jpeg value op decodejpeg root subscope decodejpeg content op decodejpegchannels batch op expanddims root subscope expand value op const root subscope axis int32 resize1 op resizenearestneighbor root subscope resizearea batch op const root subscope size int32 int32 int32 fmt println shape int32 input batch resize1 shape string dims64 err resize1 shape toslice err nil fmt println dims64 else fmt println error err error dims64 resize1 shape toslice var dims int32 make int32 len dims64 dim range dims64 dims int32 dim noise op parameterizedtruncatednormal root subscope parameterizedtruncatednormal op const root subscope shape dims64 op const root subscope mean op const root subscope stddev op const root subscope minvals op const root subscope maxvals fmt println noise shape string system information written custom code opposed using stock example script provided tensorflow yes os platform distribution e g linux ubuntu archlinux tensorflow installed source binary source tensorflow version use command rc2 bazel version compiling source cuda cudnn version cuda cudnn gpu model memory geforce gtx exact command reproduce go test,2017-05-16 08:52:31,1494924751,resolved fixed,fe41d05e7c8343ed53fc788d6c312792b390f679,1494965496,tensorflow\go\graph.go tensorflow\go\op\op_test.go tensorflow\go\operation.go                                                        
