# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UcrdG_S7ztc960Bjj-nzdL8lyD5IATnT
"""

import os
import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def calculate_accuracy(predictions, labels):
    """
    Calculate accuracy by comparing predictions to true labels.
    :param predictions: Predicted labels (torch.Tensor)
    :param labels: Ground truth labels (torch.Tensor)
    :return: Accuracy (float)
    """
    preds = predictions.argmax(dim=1).cpu().numpy()
    true_labels = labels.cpu().numpy()
    return accuracy_score(true_labels, preds)

def calculate_mrr(predictions, labels):
    """
    Calculate Mean Reciprocal Rank (MRR).
    :param predictions: Predicted scores (torch.Tensor)
    :param labels: Ground truth labels (torch.Tensor)
    :return: MRR score (float)
    """
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    ranks = []
    for i in range(len(predictions)):
        ranked = np.argsort(-predictions[i]
        rank = np.where(ranked == labels[i])[0][0] + 1
        ranks.append(1 / rank)

    return np.mean(ranks)

def calculate_map(predictions, labels, top_k=10):
    """
    Calculate Mean Average Precision (MAP) at top k.
    :param predictions: Predicted scores (torch.Tensor)
    :param labels: Ground truth labels (torch.Tensor)
    :param top_k: Consider top-k predictions (default 10)
    :return: MAP score (float)
    """
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    avg_precisions = []
    for i in range(len(predictions)):
        ranked = np.argsort(-predictions[i])[:top_k]
        relevant = np.where(ranked == labels[i])[0]

        if len(relevant) > 0:
            avg_precisions.append(1 / (relevant[0] + 1))
        else:
            avg_precisions.append(0)

    return np.mean(avg_precisions)

def calculate_precision_recall_f1(predictions, labels):
    """
    Calculate precision, recall, and F1 score.
    :param predictions: Predicted labels (torch.Tensor)
    :param labels: Ground truth labels (torch.Tensor)
    :return: Precision, Recall, F1 score (floats)
    """
    preds = predictions.argmax(dim=1).cpu().numpy()
    true_labels = labels.cpu().numpy()

    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds, average='weighted')
    return precision, recall, f1

def load_data_from_files(bug_report_path, source_code_path, label_path):
    """
    Load bug reports, source code, and labels from files.
    :param bug_report_path: Path to bug reports file
    :param source_code_path: Path to source code file
    :param label_path: Path to labels file
    :return: Lists of bug reports, source code, and labels
    """
    with open(bug_report_path, 'r') as bug_file:
        bug_reports = bug_file.readlines()

    with open(source_code_path, 'r') as source_file:
        source_code = source_file.readlines()

    with open(label_path, 'r') as label_file:
        labels = [int(label.strip()) for label in label_file.readlines()]

    return bug_reports, source_code, labels

def save_model(model, path):
    """
    Save a PyTorch model to the specified path.
    :param model: PyTorch model
    :param path: File path to save the model
    """
    torch.save(model.state_dict(), path)
    print(f"Model saved to {path}")

def load_model(model, path):
    """
    Load a PyTorch model from the specified path.
    :param model: PyTorch model to load the state dict into
    :param path: File path to load the model from
    :return: Model with loaded state dict
    """
    model.load_state_dict(torch.load(path))
    print(f"Model loaded from {path}")
    return model

def load_embeddings(embedding_path):
    """
    Load pre-trained word embeddings (e.g., GloVe) from a file.
    :param embedding_path: Path to the embeddings file
    :return: Embeddings dictionary {word: vector}
    """
    embeddings = {}
    with open(embedding_path, 'r') as f:
        for line in f:
            values = line.split()
            word = values[0]
            vector = np.asarray(values[1:], dtype='float32')
            embeddings[word] = vector
    print(f"Loaded {len(embeddings)} word vectors.")
    return embeddings

def pad_sequences(sequences, max_length):
    """
    Pad or truncate a list of sequences to a fixed length.
    :param sequences: List of lists (sequences)
    :param max_length: The desired fixed length
    :return: Padded or truncated sequences (numpy array)
    """
    padded_sequences = np.zeros((len(sequences), max_length), dtype=int)
    for i, seq in enumerate(sequences):
        if len(seq) > max_length:
            padded_sequences[i] = seq[:max_length]
        else:
            padded_sequences[i, :len(seq)] = seq
    return padded_sequences

def create_dataloader(dataset, batch_size, shuffle=True):
    """
    Create a PyTorch DataLoader from a dataset.
    :param dataset: PyTorch Dataset
    :param batch_size: Batch size
    :param shuffle: Whether to shuffle the data
    :return: DataLoader
    """
    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)